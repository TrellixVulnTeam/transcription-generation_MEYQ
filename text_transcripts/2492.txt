Transcription: Microsoft has built a suite of Technologies on top of it as your infrastructure-as-a-service today we discussed azure-stream-analytics a real-time event processing engine developed at Microsoft Azure streaming allows for constant clearing of incoming data stream and my guest santosha Bala subramanian discusses Azure and the movement from batch processing to stream processing before we get to this episode I want to mention that software weekly is our newsletter that we put out every Sunday evening to condense what happened in the world of software and you can sign up for software weekly or join our black community at software engineering daily calm also looking for sponsors so if you want to advertise your product on the show or if you're looking for engineers for your company is offering daily is a great place to get your messaging out there send me a message at software engineering daily at gmail.com if you're interested in that after a quick message from today sponsored we will get to this episode podcasting full time is it
career but if I ever return to the normal World of Warcraft hired.com is where I will start my job hunt hired.com removes the frustration of searching for a job you just fill out your profile and the jobs come to you Facebook Uber and stripe are a few of the companies that are hunting for engineers on hired go to hired.com se daily to try it out and get an extra $1,000 signing bonus just for using the URL for software engineering daily listeners which is hired.com SE daily if you want to try it out go to hired.com se daily the demand for engineers is higher than the supply and on hired.com that translates to higher salaries and happier careers for the engineers who find a job on hired I used tire to find a job before I became a full-time podcaster and the experience was so good because hired connected me with a talent Advocate who work with
need to find a job it was a good fit and the town Advocate answered my questions about negotiating salary and finding remote work which is which was something that was really important to me at the time so check out hired.com SE daily and get a $1,000 signing bonus upon finding a job which will be a great job that will give you the respect and the salary that you deserve as a great engineer so check out hired.com SE daily it would support the show and now let's get on with today's episode of software engineering daily
azure-stream-analytics is a real-time event processing engine developed at Microsoft Santosh Bala subramanian is a program manager for azure-stream-analytics Santos welcome to software engineering daily
 thank you very much Jeff how you doing I'm doing great so what is azure-stream-analytics
 I just female lyrics is a fully managed real-time stream processing solution that enables developers to get and businesses to get insights from the dealer in motion live streaming data immediately if you want I can give you some examples of what I mean to have a bunch of different sensors that should be doing some form of building monitoring we actually have a customer called Honeywell that we just did a study but what they did is they want to build solutions for building monitoring they want to basically say whenever my cooling system is starting to fail then I want to send somebody immediately to fix it I want to know very quickly when my cooling system is feeling sensors like temperature sensors all over this building they have sensors in their cooling units and things like that
 what they need to do is collect real-time information from the sensors run rules or Logic on top of this in order to detect and homeless and then kick off business workflows of from the results of personal beliefs
 that is where the string processing solution comes into play because what they will do is first of all they will
 collect their sensors to the cloud and they will stream all the real-time data and I believe that it comes at a frequency of a second from the thousands of sensors right once a stream does data then they need to have some place where they put the logic we're all of these thousands of sensors if one of the sensors cause a particular threshold let's say 85Â° I'm just making up the special but I have one chance I would just crossing 85 degrees and it's saying sustained that about 85 degrees for 5 minutes right they need some way to run the logic witches on this continuous incoming stream of data stream processing solution allows you to do how can I run a query how can I run a logic which is always running because data is always moving its own bong the data right and once I find this anomaly
 I can take an action based on that show The Stream processing solution and able to do connect to this incoming Source run all of your logic and then the result is piped what I can get into more details of what people and talk about the end-to-end flow so you got all this information coming off of sensors where does that information get routed to
 okay so what's Honeywell is doing is all of the senses are connected to a single Gateway or a set of gateways which is there an on-premise in that building this Gateway is streaming the data to a service call Asher eventhubs I believe you had a session with the folks from the eventhubs earlier so once this data is streamed pleasure eventhubs then they have set up jobs are what we call logic that you're running on this incoming streaming data using azure-stream-analytics
 the result of these jobs goes into the outputs and the output is dependent on what they want to do for example in one of the use cases they want to do live monitoring of what is the real time status sticks of sensory information which is coming from my center but they have a job instrumental lyrics which just some aggregations overtime which is the results to the real-time Dashboard Light for Pia in cases where they won't be able to figure out what are the enemies in the data which is coming they have a job instrumental lyrics which looks at what are the the thresholds Bing Crosby specific sensors send the results to another event hub from where they have that can processes which pick up their business work clothes so. It's basically the end-to-end which is created
 okay and let's go through some of the integration points in this workflow so the information comes in it gets aggravated or perhaps buffered at the point of the event hubs and what happens next event hubs allows you to do is event Hub allows you to connect a bunch of readers are to the incoming stream one of the readers when a customer goes and creates a stream analytics job is stream on Netflix to stream has basically this process now which is running we just seeing I know what logic you want to run let's let's get more specific right I cannot talk about exactly the same but let's see one of the logic they want to run is I want to get the average temperature over every 5 minutes and write it to a bi dashboard right
 show The Logical just running in stream analytics is a logic which computes the average temperature of at least $1,000 sensors which is coming every second and aggregated in a five minute window
 what happens it when eventhub is sending when the customer sending this lady to event Hub in real-time streaming lyrics pipelines read this data automatically from Evan top computes the logic when it's maintaining the state in order to actually compute the average temperature over a five minute window and every 5 minutes it writes the results to the output such as Barbie I
 the real value here is as a customer what Honeyville had to do all they did was right there logic everything else things such as provisioning of the service I don't have to care about setting up load automatically we actually probation the service on behalf of the customer the way I write my logic I write my laundry in a very simple sequel like language in order to write this competition of average temperature were 5 minutes literally the customer Road select average temperature
 from your input source goodbye tumbling window of 5 minutes that's like 5 lines of logic and behind this logic
 this is a query which always runs resilient is built into the system you can easily scale this out we can talk about all of these aspects a little later and just call if you want but hope this explains exactly what's going on yeah so would you describe this as a standing temporal query
 that's exactly what it is it is a standard temporal standing Temple quarry on data in motion what is data in motion how would you define data in motion
 any scenario where dealers continuously being generated and what you're trying to do is do computation on this date of which is being generated before it is written to some store origin to summon point right now I am doing real-time computations on the stator let me take a step back right electric plane it in a very different way dude in motion was a speed headrest there is a there's a parking lot with a bunch of cars in the parking lot okay you want to ask a very simple question how many red cards are in this parking lot you can basically go and say select count star from parking lot better car colors equals read the credit unions
 did I dressed for the concert rest gives you an answer and then Aquarius completed right now let's ask the same question in a different scenario let's say you're standing at a particular point on a freeway and cars are continuously moving you want to ask the same question but just tell me the number of red cars which across this point in the last one hour what is happening is the score to continuously moving this data in motion and something is Computing what is the counts star of all the cars which have been Crossing this point and every organ gives a result
 that is fundamental difference between data at rest and in motion
 so you have a standing temporal query from stream analytics sitting on top of an event Hub the event Hub is throttling and buffering giant volumes of data and the stream analytics can aggregated into standing temporal queries
 give me an idea of some of the patterns that you can utilize with different Technologies to take advantage of that standing temporal query great question the three common patterns that we see from customers and generally menu for customers on the iot like scenario is I am getting the data from the sensors are devices and I want to take this data and create aggregate this information on a temporal window and create some kind of dashboards on top of it right so if I am a person who is doing process control engineering and I'm sitting in front of this dashboard to see what is the real time status tips of my building I can actually get that information immediately another pattern let me see is
 detecting issues in the incoming stream of data so the companies like a Honeywell or Eric Wright Motor Company I'll talk about later what they are doing is there in sending data from the senses are devices and what they are trying to see is in case a condition happens the condition can be anything like a particular property processor threshold or in case of the Honeywell T could do something like if the average temperature in the last 5 Seconds was 20% greater than the average temperature in the previous one are Saudis of conditions are in only switch happen then I want to take an action on top of it right so I detect this condition on this incoming stream of Tater and I pushed to something like a service bus topic you or another event Hub in the output like that an anomaly as happen so then a business process can be fit into that
 the third pattern the PC very commonly is I take all of this incoming data which is coming to my stream and I basically archived the data by augmenting does incoming data with certain information right so what I mean by this is we have a customer who is bringing an extra Lehman trillions of IP address for day one says IP address comes in there actually doing some kind of an IP location mapping so they each IP address with what is that location information reaches their from an IV medication nothing that they have and then be archived the data in blondes so then they can actually do some post-processing on top of it this explains the street but he can only go back inside PC heart warm and cold pack analysis from the Team Stream So I want to get into the example where maybe you need to have
 Saint Paul query and something happens like you know let's say the temperature in a year your aggregating the the temperature across if you know the average temperature across a 5-minute rolling window and you know that temperature passes a hundred degrees and you want to kick something off or pass a signal to a broader system would this be a case where you would want to take off something in in something like storm or kick off a machine learning process what are some common larger-scale workflows that you could kick off under certain conditions that you broke your business has a great example you brought up the machine learning example right
 acting which customers are doing is they're bringing the sensor data they are creating the temporal windows are anomalies that you detect on top of it and then they are doing things such as I
 going to be able to get a ticket in my service you account correct so they're basically connecting it to a complete third-party solution for things
 additional to this what they can do is the right this dealer to blobs and they run predictive maintenance models machine learning models that enable them to learn what are the issues that could actually happen in future other things that customers are doing is I actually am bringing this data in motion we are actually in in private preview on one of these pictures and I want to be able to call a machine learning model on the fly on the steering motion to score it and then I want to take some action offer it to be very very to give another example for this for example you can bring tweets from Twitter and I will I want to get the sentiment for each of these tweets once I get the sentiment for the trees then I want to take an action on that for example if I get something like
 hundred tweets which have negative sentiment in a five minute window so I'm actually calling a machine learning model on this incoming data and then I'm running a temporal query on the result of this machine learning model workflow update my CRM saying I think it needs to be create does not make sense all these things type again if I'm correct what you're saying would be you have a Twitter firehose connected to the event Hub you have the event Hub feeding into a machine learning process and you have stream analytics reading off of the machine learning process and then it is that accurate just like you different
 stream on Linux job is created by the customer when it is reading the tweets from that event up then from within stream lyrics I am calling a machine learning process to get each of the Peace Corps get the results back into my stream lyrics process and run the temporal Kodi on top of it so when I'm only getting the meter but I'm scoring the deal with the machine learning model and running my temperature to find anomalies right you can do things like this and stream processing other things you can do is I can actually make a history of data calling machine learning and all the detection model to anything that I want to do on top of this is real-time data I can actually do that you some stream and lyrics
 are you saying that is stream analytics really like the lens that you want to look at your data through you want to pull the data off of the event Hub and read read that data through the lens of stream analytics or are there cases where you would want to pull data directly off of eventhubs into a machine learning module or a storm module is great yes so and there's actually one of the powers of azure but as your is providing is streaming on Linux as one of the first Body Solutions that you're providing which has all the resiliency in stop that we'll talk about what are the same time if you want to take that same data and you want to call a machine learning model you can actually do that as well you can just write some custom logic which takes the data run it on some VMR talk Services something like that cause a machine learning model gets the results of it
 escorted I can connect actually we also have things like a HDI HD inside storm and HD inside spark which can connect to the same event Hub and processing on top of this right all of these which I'm saying where extreme Athletics can connect to the same event up Storm can connect to the same event helped spark and connect to it or I can write custom cordage connect to this event have all of these are different ways for the customer to be able to customize their own work out right it depends on what
 what is the skill set of one of the requirements of the customer that I sure as providing you this flexibility in example if you ask about what's the difference between HD inside store most Humble close by itself and stream and lyrics for example if I am a company which already has an on-premise stormed apology or I have a bunch of w i will basically can take my coat go to the 16th right side and say employers don't apology for me and I can take the third shift my code to it right but if I'm a company who does not want to get a whole cluster and I basically have some songs small Trooper jobs
 I want to use the Simplicity of a sequel like language where I can do all of my temporal aggregations and 5 minutes in Empire lines of code I will use something like stream Olympics
 okay so I like to get a better idea of the integration between Windstream analytics is pulling data off of an event Hub you know we did do a show about eventhubs recently to talk about it here about eventhubs but from the stream analytics point of view what is going on under the hood when the so you know obviously from the user's point of view the user is just writing some standing temporal query that is aggravating for example a five-minute rum rolling window of the information but obviously under the hood there's a lot more complexity going on so what kinds of things are going on under the hood that's great question so let's take a step back and see if I want to actually run at Temple Quarry like what you had mentioned one of the things I need to do right one I need to have a service which is able to
 next all the time to distinguish source which is even tub and continuously will the state of which is coming to even talk right so real time I'm pulling the date as soon as it comes into my second I need to have things such as the ability to scale up or skin down the service I need to build things like resiliency into the service are we talked about window imagine you had A1 hour window and it'll be all known machines crash things happen you have to build recovery into the system I need to be able to do things such as ordering the events in a particular order these are all the things that he needs to do including management and deployment and things where you go and try to set up a streaming solution
 only after you do these things are you at your car or riding the logic is just a part of doing these things right up what stream and lyrics enables you to do it doesn't fully managed solution platform-as-a-service solution where we actually take care of everything from the blowing the service for you building in resilience into this during the helping you with the scaling of this and also like things like reordering of events which is very important for temporal use cases the only thing we want to do is come and write your temporal logic in a simple sequel like garbage right the thing which I talked about the Tweet being scored correct where I take it over just coming from Twitter and I score to the machine learning model and then I push it to bi dashboard which shows my real-time Analytics
 the only thing I wrote to do that was one I love sequel select like text which is basically coming from my Twitter sentiment of text sentiment goes to machine learning model and write it to a bi dashboard
 so now think about that Vantage to fight developer has been successful me for customer who's using stream Athletics is I am able to set up a streaming pipeline energy actually I want to send 10 minutes but I'm just going to be modest and I'll see you today because you have a lot of things but if he doesn't take that long it is removing those complexities of doing temporal processing and putting it and then when I see the sequel what we did is we basically took those parts of sequels like projections aggregation functions of temporal nature to it we gave new functions such as helping Windows sliding Windows Cloud tumbling windows
 n&b Shakira tukdo sequin semantics and put it on top of a stream processing solution right so I hope that explains yeah no absolutely and I think the sequel discussion is interesting because when we think of of sequel we tend to think of how do we write a query that is going to assess a large volume of just data in the database what changes when we think about how are we wearing this moving did because you know conceptually an event Hub that is constantly being updated with new information and buffering that information that seems somewhat different so if we're thinking about writing a fish aquariums or even just the types of queries that we could write which could potentially be joining different eventhubs
 as if their database tables what are some things that we need to keep in mind the most important thing I would say I mean having being in the space with some time now and talk to a bunch of different customer
 this this temporal data which comes into the system under which is coming into even have the temporal nature of it is very very very important
 events which are pushed either to event Hub have time which is associated in the payload of the event which is most associated on when that eventually reaches event Dennis time associated with what is the order of events that is coming into the system right so
 understanding like what is stream processing solution really does is it takes a stream of data and gives you a result in stream update right when I'm doing an aggregator work. Pretty good point of a window I'm writing a new stream every 5 minutes for example and I and writing a new data results when I'm basically saying I wanted detecting normally but it only can be detected every second or it could be detected once everyday I'm in the incoming stream I'm running some logic and my output stream is coming everything that I mentioned to you has a temporal nature which is embedded in it starts with the event which is being pushed to event up
 already up and we can talk whenever you're writing a temporal query or whenever you're writing a stream processing pretty understanding what time stamp you want a use for that Corey is a very important aspect of an example I will give you this from one of our customers
 we we added the functionality into the system what does system does is because thousands of sensors from a building can be connected to a Gateway and this Gateway is sending the data to even job you never have consistency on Rent-A-Center is actually sending the dealer to the Gateway right so some sensors might be sending it much faster than other sensors but each repeating as a timestamp associated with
 in order to find things such as patterns in the data or aggregations overtime or anything in the temporal nature the first thing you want to do if you want to reorder those events and make sure all the pieces thousands of sensory language is coming is is ordered by a particular time stamp and then I run my Logic on top of it right so you have to stop thinking about how do I deal with this concept of time before I do a stream processing Logic the other things that you have to do is you really have to figure out what is it logic that I want to write write not everything is on the waste of time but most of them are on the basis of this time stamp pictures associated with a pillow so
 call Hope how fast do I want my logic to be am I taking multiple streams of data and I'm joining them together am I trying to find patterns of the lack of Packers in the state of how do I think about doing management of state and when I say state is stayed within the temporal Cody that I'm running out of things that have to think about when I write a stream processing logic and any platform-as-a-service solution like you have other things the customer I mean what I'm saying a customer can go and do all these things in Java RC shop by custom coating this whole thing right but video providing this platform-as-a-service thing what is that least amount of thing that you make a customer think about how do I scale up or do I scale down things like this you need to actually provide in the string for 6
 okay so as we're talking about the issue of time I think it's worth trying at the issue of a latency you know if if we if we have a stream analytics standing query on top of an event Hub you know event for listeners you're more familiar with massive stream of data and the stream analytics you're doing something like joining across to eventhubs it could be a potentially time-consuming query it's not just like a magical constant time filter show what kinds of latency should users expect for a complex query comp Xtreme alloy square acres is this query is going to be delivered potentially to somebody on power bi or on Excel who is maybe looking at a dashboard and inch
 everything that dashboard is being real time when in fact there is some degree of latency explain a little more about the details of the system right
 what is the things that the two knobs that we give to the customer or actually more importantly the single knob in this particular case that you want to think about is a concept of a streaming unit when you go and set up a stream Alex Cody you set up say how many streaming units do you want for the credit okay I streaming unit is fundamentally the amount of processing power that you give to diabetic liquidy
 so we have a scale tab if you go to the skin tab you can select how many streaming units I want
 no in order to determine how many streaming units you need to give or how much processing power you need to give for your query it really depends upon what is it Korea running so let me give you some basic examples if I am doing some basic filtering like I only want on signals and I don't want to start off signatures or I only want to eat and some one second window right what we see and what we measure is for one second that you're pushing through the system
 we will process the data within the second so it is real time that you get the data so I believe event up and and please do not hold me to this event Hub basically says things are just from when you push the data to event up to when a reader like stream on lyrics can redo that that's a maximum of a write up what we say is if you push a megabyte into eventhub to when you do your processing and these basic qualities that I'm talking to you about witches aggregations filtering I just passed through it could be done within that second right and then you can get the result so listen to Second latency for this happening building a megabyte per streaming unit once you start adding complexity into the system into the credit where let's take a Aquarian put it in the real example I have two streams coming in
 I want to be able to join these two streams on on on a particular field and I want to have this feel to be in a window of a minute so just to be more accurate we had a customer who basically bought to Twitter feeds together and then logic was something like if a user on a particular topic changes their sentiment from positive to negative negative to positive within one minute I want to know who is the user and whose atopic what is the topic from a set of topics
 arbitrary complicated because you're pulling in multiple stream you're basically checking every tweet which is coming in with every other to eat in a one minute window to see other users and the topics the same and when the sentiment has been flipped in that minute right
 when are you going to such complex queries and the more complexity you add to the queries you need to look at what is the amount of processing power which is being used in your system by the issues that you have selected what we have done is been given you some metrics and dashboard which tells you how much processing memory and resources is being used for your stream and lyrics once you cross 80% we recommend that you actually increase the stream main units that you give to that credit and one other thing I want to add I'm talking about one megabyte per second right I just want to quantify what that one megabyte per second actually means an unqualified to a real life example have you heard of this website which went by the last year in May I think call how old.net
 Kentucky actually one of my colleagues and I actually built this thing because stream Athletics West GA so this was built for showcasing how you do real-time processing on Azure along with some pussy actually pees and things like that so just to let you know what scale it hit it hit 50 million users within like 5 or 6 days go faster than Angry Birds just to be honest and it's Max it was having 1.2 million users who were saying hey look at this photo and tell me what is my age and gender right so what we were doing just to go into the internals of that will help with understanding what happens is when you uploaded a picture of menu selected a picture that was some good we just running which basic call the perceptual API Wichita Oxford api's the machine learning part of things with said what is the age of gender of the face which was detected
 we basically to North store in Hilltop orders always say there's this age and gender comes with a patina Jason payload with your web statistics like web server logs and we send it to even say every time anybody went to the webpage selected a picture all it did was a gender of the face detected which I send messages on a Droid Maxx with 1.2 million users per hour we were sending 9 gigs of data every hour for the event.
 This was less than 3 megabytes per second
 right so now you can start seeing that it is the skin that I'm talking about is not just about the number of events but it's the number of events plus the size of the pillow the customer I mention who's bringing in IP addresses is bringing around 9,000 IP addresses per second is less than 1 megabytes per second so now you can start thinking about how I need to scale up number of events plus the the size of the event that I need to think about
 are we supposed to talk about costs if you're interested yes let's the end so you're talking about a little more of the application side of things so you know I'm going to take him to a show with with your colleague about this I think I saw it the managed Insight hdinsight storm or spark story so how do storm and Spark finding this conversation obviously you know you are on the stream analytics side of things but I assume you know some about the use cases and we've done a lot of shows about spark so I'm curious how you were seeing from customers what customers want out of spark and perhaps out of storm is important because this is exactly why
 we are not only saying we have stream inside but also we are saying that we have our own manage storm we have our own manage part customers can come and use our is pouring storm and spot right it just goes down to use cases it goes down to how much to put on bringing to the system it goes down to what is the developer capabilities that we want to bring into the system and these are the things that go into the decision-making on what system that you select for example
 install I can write my code in Java and. Net I have to manage some of my apologies I The Residency I like to figure out how to actually write code for that there's a bunch of things that I can do it is pretty flexible but I need those kind of developer so you can write the code right we did some compete studies through complete external company and we noticed that what took five lines of Sequel and a lot like everything was written in 1 900 did writing the same code in Java right and and it's not like it cannot be done but it again comes back into how can I manage it pretty easily the other thing that you have to think about when I get storm I'm getting faster
 right and so what is the cost of that's why I mentioned a little bit about cost what is it cost that I'm actually paying for the cluster versus something like stream on lyrics I am basically paying for usage for Rupert 4S you is how we actually charged us right so for my work clothes I actually asked what I use I don't have to buy a whole cluster for my maximum throughput usage and then only pay for pay for the whole cluster the other thing is things such as
 does the reordering of Avenge the bunch of the resiliency so we actually automatically checkpoint for you internally so you get the fastest recovery things like this needs to be coded into the storm topologies right no even spark spark is coming out with spark streaming and Scala and other things but again if you take a step back and look at what can be done with the sequel versus POTUS done with this color part of things right you have the flexibility you go and ask the developer what are you most comfortable with things like if I want to use the application payloads timestamp right which is basically the timestamp of North when the deer came into cop car event about the timestamp of when it was generated in the device
 something like stream analytics all I have to do is be happy when you always such as timestamp by the timestamp that you want to use and all the applications are now done on this time stamp the device and not when it comes into the system in something like Spock you might have to write the code and build it into the system instrumental like you have a sequel which is essentially like a domain specific language that makes it easier perhaps put some restrictions on the types of things that you can do but the types of things that you can do are made really easy or at least less of her both then they would be in store Morse Park jacket and the other respect for this this even though the two decorated secret language of if you see some of the things that we have done with the machine learning integration right what we have done is we have
 allowed you Virginia stream processing query for calling that sentiment anomaly detection will allow you to call a machine learning model which is hosted somewhere else so this is a web service called be due to a machine learning model so I can write my custom code posted in this machine learning in point of our first integration has been with the machine gun again point we are looking at how to be extended to other places where I'm running my custom code python are code I can basically go to Azure machine learning right my battery code operationalize my endpoint and then I can call that endpoint from within my secret by creating what is called a user-defined function ticket info
 right so you can get that flexibility by hosting it somewhere else
 okay so let's talk a little bit more about cost obviously twin when people hear the term managed I think the first thing that they think is this cost money and
 that's obviously true platform-as-a-service you know it's an addition it's going to be an additional cost on top of what would be the cost of infrastructure-as-a-service with perhaps some roll-your-own Solution on top of that infrastructure but of course often times the platform-as-a-service like it like this man extreme analytics platform the Azure can provide you know you can often time save time and time is obviously money so there is a sense of trade-offs here so talk some about the the cost of these platforms one of the main things that we went after when we build I just remembered one developer productivity to set up the pipeline faster than anything else right that's why we did the line the second thing that we realized it was in streaming scenarios
 the two Port is very variable we have some customers big customers were bringing in 2 and 1/2 terabytes of data every day but that's around 30 megabytes per second so we ended up building a multi-tenant solution so if I am doing one megabyte per second processing continuously you basically pay $25 a month
 because we build a multi-tenant solution we were able to build one of the cheapest room processing Solutions in the world right now so when I talk about how old.net right and how old.net Boat Line Gates of the United snacks
 if if we were having 9 gigs of data continuously flowing through the whole month because I was just doing a basic aggregation Korean I had only one issue that I needed to use actually for how long can I use three issues for using three issues for the whole month it would have actually costed me $75 a month
 imagine doing a fully managed solution which has everything from Brazilian TV just built into ordering which is being built in to ability to use different time stamps to Nikita scale up and down very easily and all you're doing is writing your Korean sequel you basically pay $25 per month for doing one megabyte per second processing on One S you up I will tell you this I have gone for dinners when I have paid more than $75 a month just between me and my wife and imagine running something at the skill of how old.net at its Max through that system that's why that's why I kept on saying like it really comes down to what your customer wants to do
 and that's very interesting I'd like to zoom out some and talk about the the Azure platform as a whole and where things are going to be as I've been doing different shows with people from different cloud service providers or people who are familiar with different cloud service providers you know people who have used AWS or digitalocean wear Azure the story that I seem to get is that cloud is so big it's such a big shift that there are all these different pockets of micro market so it's not like this it's not like this winner-take-all Market where one company is going to win the entire Cloud business going to dominate the entire Cloud business one-size-fits-all for cloud computing give me an idea of how you see the the cloud infrastructure and platform
 service Market evolving and what is Asher's place in it
 Joe I mean this is just great actually I have being I'll give you a little bit of background to I before I came to work on 300EX I actually work in msrn Sequel product so release some box products which is called Always On which is the higher availability solution from sickle cell
 what I have noticed from just two customers that I used to speak for years back when I released always on to now I'm seeing the tendency of these customers to say I am more open to move my work clothes to the cloud right so what is happening is people are seeing the advantage of not having to manage my own data center not having to manage my own resources and when I say resources I actually mean Hardware resources more importantly the people resources in order to manage your assets right
 Book value benefit of this is coming up so much more right now that people are more open to come to the club and when they come into a bunch of different use cases I mean I know that I O T and an analytics use cases lot better than that I'm in Greenland background who is you do this for me to sit in my house and I want to launch a web page for my my brother actually asked me this a few weeks back and he's like dude I want to just launchers web page for for something personal that he's doing sitting in my house while I was on the phone with him and I just went to the Portland said alright here it is so it's not just his company's but there's a shifting how do people start doing business then there is another shift which is happening with
 coyote and devices which are actually Cloud connected devices weather data is being generated in the top right shelf right show all of these things are moving and shifting with bringing data making it easier to bring it if the cloud compute on the cloud and this is where the whole cloth Market is exploding and this is where if you look at what companies does Market what they're doing is investing equally in different parts of it then resting and compute resources we are investing in storage resources right I mean good example is Microsoft came out with the cable store near Computing and more and more data management platform resources great examples of things like you can actually go to and I can talk more about I sure but I'll talk about the little bit of History I can go to answer and I can probation things like mongodb on is boxes but it does
 we will come out with push Party Services like Doc TV which gives you a lot more performance and efficiency on top of it right so you know I only have Bush party things would you give you efficiency resourcing things like jockey Beastie magnetic said I said look out and help each other the combination of what we're doing with infrastructure-as-a-service Computer Resources data platform analytics platform sepia building is really making it easy I'm giving the flexibility of customers to bring their own solution or part of the solution to the club the other thing which is happening is people are realizing that pay alot of data is really being generated and there's a bunch of different analytics I want to run on this data
 how can I use the flexibility of cloud Solutions in order to do and lyrics on demand for me right one of those things right lyrics but I want to do it only on 3 megabytes per second so I just want to be my $75 per month or I want to be able to start up a secret date of their house and use the resources of The Secret of our house only when I actually need to run my job once every day and I don't want to pay for any other time for it so these are those flexibility that cloud service providers have to stop thinking about more and more the more you make it easier to bring it up to the cloud into and lyrics now you're just thinking about user experiences
 choke the more we do with things like machine running very give you Studios where you don't people like me who actually I don't know much about machine learning just because I am out of this machine learning organization I've learned a little bit but if I want to do my sentiment analytics or if I want to do some anomaly detection there are API switch are available in the marketplace when I can really get easily and do it as a data developer in the workflow what I do right so don't think about I'll give you a very off the cuff example right we have from streaming one of the use cases and customers wanted hey when I detect an issue of whether this issue is over social media or seven $30 service data I want to get a text or an email from it
 we kept on thinking you like to drink when building output to Trillium you so you can get a text message or should we build an output for some SMTP server so I could actually send me some things then what happened was we stuck to another team which is called there's a service which came up on Azure Cloud call logic apps allows you to build your business work clothes in the club so all we have to do is we have to figure out ways to die these two pipelines together so no I can bring him streaming data to even top do my real-time analytics you sing dream and write the result to something called a service bus queue which is not picked up by Logic apps and I can send an email I can send a bunch of different text so that flexibility provided by the setup Services is something that you think about
 interesting not to open a can of worms but
 it sounds like the the future in in your perspective is kind of a a polyglot cloud with like multiple you know you you're not just using one Cloud as a walled-garden you're using multiple cloud services inmate paying multiple Cloud providers what I'm saying is I'm actually just kept reading this Cloud providers from the service so what I'm saying is
 us too successful cloud provider will give the set of services which an enabler customer scenario to be completed right so as I talked about the logic apps you can lyrics machine learning why don't I just bring up a bunch of different things I can two names but it is more about what is a business use case which proper way they can provide I sell or lease business use keys and help me Stitch this together right one of the things I would love for us to do more and actually what we ended up doing with the iot suite solution that he gave out so what does when the wind is moving a little more like moving from just passed services to Star services that peace out right I don't want you going and saying I want to do device management so go set up your iot Hub stream on Lenox dog TV blah blah blah like $20,000 Services what is a single button that you press
 and all you see is all your devices connected you seen your life dashboard in the end you see or your logic app accounts in the end right so I would see more in the future things moving from this Individual Services to Solutions which are being solved which is oppositional be services to complete a use case
 fast Nanny Santosh that sounds like a good place to stop this has been a super interesting conversation and I look forward to continuing to talk to your Microsoft colleagues to get a better picture of the Azure stack and where things are going thank you very much this is very entertaining
