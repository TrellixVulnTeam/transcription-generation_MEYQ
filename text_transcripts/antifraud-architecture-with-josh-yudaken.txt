Transcription: social networks and online marketplaces often have a trust and safety team the trust and safety team helps protect the platform from scams fraud and malicious actors to detect these Bad actors at scale requires Building A system that classifies every transaction on the platform as either safe or potentially malicious since every social platform has to build some sort of trust and safety system Smite decided to engineer trust and safety as a service Josh Utica and joins the show today to discuss house might engineered its platform to provide machine learning models for any organization that wants to take advantage of smite for its trust and safety the tools we discussed include kubernetes rocksdb and Kafka to this a great episode for anyone interested in data engineering or fraud detection or how to use cloud services and open source Tools in unique ways to is really a cutting-edge infrastructure episode and I hope you enjoy it
so you've got a bacon delivery service and you need to notify your customers when they're bacon has arrived at their doorstep twilio helps you make sure your customers get the bacon while it's hot twilio's programmable API let you build SMS or voice alert easily in the programming language of your choice all in under 5 minutes with only a few lines of code now your customers get a text or a call the instant their bacon is ready if your customers want to see the bacon frying on a hot pan twilio has video API dies and SD case for the platforms that you know and love learn more It Go. Twilio.com podcast and get an additional $10 when you sign up an upgrade your account that's go. Twilio.com podcast you will only pay for what you use and it cost less than a penny to send a text get started at go
twilio.com podcast get your bacon delivery service cooking with twilio's API for Voice SMS and video
 Joshua Daikin works on infrastructure at Smite Josh welcome to software engineering daily your co-founder Pete hunt came on the show to talk about trust and safety challenges for software platforms and how to solve those at a high level of product level in the show I want to talk more in terms of the architecture how you build a software architecture that supports the requirements for a scalable trust and safety system with anti-fraud and other kinds of policing elements can you start by explaining how it works from the point of view of customer like that mean I know this will be rehashing some of the stuff that he talked about last time but for people who didn't hear that episode you know what is a customer due from the stamp from the user's point you on Smite how do they feed their data into Smite what is their experience and then we'll talk about what happens on Smite side around the initial customer
 will hook up till API endpoint usually which is just a simple Jason pushed to a low APR. Smythe. Comm server they can push kind of any payload they once generally they will send a username user ID at whatever information IP address headers usually in whatever format they want to us and then an outside we hook it up so internal kind of the layout and then send that throughout data pipeline we also offer them a front end piece of JavaScript which they can throw on the website that records directly to us and we also have Cline library's for IOS and Android and on the back end once Smite is sending you their data herbs are wants customers are sending Smite their data Smite consists of three parts of high-level there's a real-time classifier there's a historical classifier and there is a manual review Q why are these
 three components together a useful high-level system for preventing fraud in depending on what the client actually needs they can listen for responses in line so that is they send us an action such as a sign up and before writing that information to that database they chocolate Smite to see whether we will accept all the time to sign up on a variety of rules they can set up besides that there is the the slow one which we will process in the background over the next five to thirty seconds and then send them a webhook with the response which might be allow block or any number of labels which we have labeled that's simple action from gnats they can use that to stop kind of real-time a text but once you get a much larger scale attack or something that you didn't manage to block we offer car
 a later stage investigate your data view top users view basically / anything and kind of scan through looking for malicious activity the real-time classifier acts on the data stream immediately the historical classifier runs some more copy tationil intensive analysis in the background can you explain the two of us a call that real time I mean that God will be done within 5 to 30 seconds okay alright so what is the difference between the types of analysis that the real-time classifier is running versus the historical classifier I mean so usually retire respond to the customer within kind of 500 many seconds would be even sometimes too slow so that ready restricts what we can do so we expect kind of as much information but we intend to do outbound hdb calls on that I will look up a bunch of counters
 cameras all of that and use any rules that can take those pieces of data slow one will then maybe go up and if there's an email address it will check that the domain name that was mentioned exists that's running the mail server and then check not like 15,000 deference that'll services that we were on so I think that a good way to ease into the architectural discussion for house might works is this blog post you wrote about counting at Smite why is counting fundamental to spam fraud fighting all the things that you're trying to police at Smite yes I mean I come from a general kind of infrastructure background and I haven't specifically dealt with span before but when we was starting to build the system we chatted to a lot of people from Facebook
 from Google that I boil cooking systems and the thing we heard time and time again is that Isle Maine cost is going to be keeping all these counters which kind of makes sense because if you want to know how many times you've seen that said give an IP address in the last hour we have to maintain that counts of pretty much every RP address obviously leaving out the ones we've never seen but for all very very big customers that can add up to huge amounts of different counters and we need to find ways to do that as efficiently as possible from those consoles obviously we can start riding rules saying if you seen this user from IP addresses in different countries that's pretty suspicious especially if we see them in America and then less than 2 hours later in Europe because you can't even travel that fast do you usually need exact counts or can you just get like fuzzy counts so we have a whole lot of different counts for different purposes the one the blog post
 is about is about exact count so that is exactly how many times have we seen this IP address in the last hour in the last day week month the other something called a sliding hyperloglog that gives us a proximate set counts so we can say how many different IP addresses have we seen this user on without having to store every single IP address that's surprisingly accurate and it also gives us how many times in the last hour day week month we don't use count men's schedule yet but we will be that gives us kind of the same as before but approximate counselor and then exact with much much faster much Louis storage all of that your solution to Counting is evolving and it's always been evolving what was your earliest solution to counting the earliest I mean this was kind of like they are of the company as we were getting everything up but we kind of just threw all the data in redis
 so we had we went to to find out how many times we had seen this in IP address in the last day we would create our pockets in redis increments it when we see it and then we keep the last 24 hour buckets summing them every time we want to get the contest overtime reddish began to Creek it did not work and you decide to switch to rocksdb why did you make that switch switch was made for variety of reasons I mean redis is very fast very efficient but its own in memory so there's no way that's going to be as cheap as it could be a rock I mean the actual selection of Rocks TV was kind of just briefly browsing around you know you're a bunch of Facebook people we know Rocks TV is a solid product are we tried it out and it works fantastically well some of the advantages we didn't ask you realize we were getting from day one it's kind of its key prefix compression so if you counting as I meant out
 the IPA example but if you're counting IP addresses a lot of IP addresses start with the same couple blocks and Rocks TV won't stall those parts over and over again where is redis would talk more about Roxy because I have not done any shows on it I have been hearing about it more and more especially in regards to Facebook I hear it's such a crucial component of Facebook's architecture what differentiates rocksdb from other databases and how does it work I'm not an expert on rock CD so I'm pretty sure the details I'm giving you a correct it's based on the Google level TV product essentially it's divided into two pots there's an in-memory table for kind of usually the last 15 minutes of data which is also sync to desk with a rod ahead log which insurance once around is committed it will stay around forever that table is then
 pressed into
 I guess levels in the level TV time I actually can't remember what rocks calls them right now and then they're kind of phone is a tree of all the date of slowly moving down the levels which get low get larger as they get bigger and so the memories slowly moves down each level as it gets as the latest get compressed together a multi-layer lru cache kind of an age difference is too that right interesting in and show at the the the higher up in the layers the less compressed it is so it's faster to access but it's bigger excess the files of it snowing but yeah it just allows a way of kind of compressing the data it also it's called compassion sorry I was just messing that would each level as they contacted at provides a solution for when you wanted to meet so for instance out counters for
 counter that we only storing for the first day we don't automatically deleted picturing the compaction step when the joints multiple of these letters that's when we say we'll just leave this record out since the account is no longer useful for us and compression compression is taking a piece of data and storing it in less space idd than it used before the compaction basically will take two layers which are somewhat overlapping enjoying them into a single layer found the other key is does Leia files are unique and will never change all the time they static so when you backing up it's very easy to backup individual files and confirm that they've been backed up successfully which creates future backups won't be much faster is rocksdb has become a crucial component of your architecture the the other crucial part of your of your data infrastructure
 do you write about in that Blockbuster Kafka and kubernetes can you talk more about the interaction between these three components why they make up your core infrastructure why it's so useful May particularly for the domain specific database counting infrastructure Asad component as compared to cap gun Rocks TV which we have kind of tightly integrated the way so kefka's very very useful cuz it's kind of a rat head login itself so in the counter example we will pipe data updates to casca those will be sent directly to the database which will then commits on its own schedule but if at any point that database crashes or gets moved to another host and it loses a chunk of data it is very very simple for her to just catch that data up from capca capca has stored offset
 Tampa tent and it just it will no weight loss committed go back to the tap the database and read from that once that's up and running the side component which I mentioned kubernetes helps us in Chinese database is always up and running so when a database crashes on machine crashes kubernetes will detach the persistent discs so these machines run on be on Google Cloud at the moment and they run on Google Cloud to system disks which allow us to move them from machine to machine sew the disc will automatically be removed it will be attached to another machine the Pod or the database will come up on that new machine with the existing data now keep in mind this sometimes takes up to 10 to 15 minutes to the date of will be a bit late to that point but then it will connect to casca and then redownload and reprocess the last 15 minutes a day.
 software engineering daily has 20,000 Engineers listening Monday through Friday if you are hiring or if you have a product that you would like to get into the hands of Engineers send me an email Jeff at software engineering daily.com this podcast is sustained by the advertisers and if you would like to become one or even if you're just curious and you want to learn more send me an email Jeff at software engineering daily.com thanks for listening
 did you get that level of functionality base can you get distributed buffering out of Kafka you get teared database architecture out of rocks TV and you get like up time management through kubernetes 5 years ago you would be inconceivable do you get all those things out of three components only one part of kubernetes called the services which is actually it's also kind of unbelievable and when I first saw it I didn't trust it very much cuz it's kind of Magic on 30 centrally they give us one IP address which references to be run to replicas of each database and kubernetes services give us one IP address which references both of the databases or whichever one is up and running if one of them crashes also very importantly which we haven't implemented yet but during that catch up. We want to make it to kubernetes does not register that database is ready
 so that if one database goes down for 15 minutes we don't serve the stale data wow okay yeah so the services thing that's that's interesting it mention that I am doing a show soon on mesos and kubernetes and serve like their differences and you know why that's why it's not a conversation of Mason vs kubernetes but more like why they are kind of contrasting they solve different problems like some overlap but the big topic will the big differentiator for kubernetes have to ask the person interviewing but seems to be the the services aspect of it like the fact that services are baked into it and yeah maybe I think is better for data infrastructure workloads but kubernetes is really well as the right abstractions kind of minimal abstractions for conducting your service
 that's an accurate or maybe you didn't even look at me so I know I'll be honest in the early days be committed to kubernetes failure without too much discussion around it it seems that the correct product we don't actually use much of the whole who do Java situation not for any particular reason just the components me use didn't need them and it's a big setup yeah well I think this is just from like my talking to people but couldn't seem to have like the same kind of feel as like react you know where you just have this huge amount of people that are really excited about it for one reason or another and I don't know if it's if that's like Google drumming up the doorways artificially but I don't think it is it I think it's like people are really legitimately excited about kubernetes and so for whatever reason I'm still not a hundred percent sure why it's so popular why it's so awesome
 what two shows about it but there is like the network effects in like people are really excited about Nick contributing lot to it I mean I just from using that I guess it kind of feels like magic I mean you mentioned what we doing now wouldn't be possible five years ago and I was so I'm from a Facebook history and just seeing the tools for automatic the containerization fixing things automatic he dealing with problems that all would have been kind of a nightmare to try those myself but it's all built into kubernetes I said earlier that I didn't expect it to work out of the box and the tree as we turned it on very cheap didn't use Services be kind of we had a solution that was a little bit cranky but kind of work and as a as time went on that started failing and we just kind of looked at community services and they sold all of the problems we needed today I think most of us are using
 containers for the computer substrate they are managing but there is work being done to make core OS just as usable as the container technology I think where are you following the area closely like the what the compute layer that you can use is we don't following too closely we have had quite a lot of issues with the DACA computer I'm some very happy they're all competitors and the other people trying to solve the problems in different ways as soon as it gets the point where it's kind of stable enough for us to investigate will definitely look into it. Cuz also finally gotten to a point at least for us where it's most stable Dacono bugs we were heading in earlier on seem to have mostly been sold and it seems to basic it stable enough for us to be confident running all databases in it which I guess is a pretty big deal how do you feel about Docker cuz I hear some people say
 Pacho they Dockers like Reckless and they are over aggressive with pushing out breaking changes and I don't know if this is like a small loud group of people or fish is actually the case what's your sense of that I mean I don't actually know about the internal development system haven't dug into that so much I can say the Lost couple versions of what is not the latest but the two or three before that were fairly buggy the recommended using Docker 1.8 to 1.0 right I'm not too sure which was about a year old at that time just because every version off to that had some other significant folk which didn't ready work well with kubernetes the same time it is a very very new product the whole containerization Solutions thing is also failing you so I'm pretty happy they're moving fast it is unfortunate that it comes with
 but I guess that's one of the reality is we have discussed this Kafka kubernetes rocksdb the interaction that forms the backbone of your accounting databases can you give me the bigger picture of the architecture kefka's so the counting databases and Rocks TV one component but basically everything runs on top of Kafka so as one of these API requests comes in with one or more payloads of actions that immediately gets routed to alpaca role actions topic and we respond to the client with a 200 okay if they want to the classification it get sent off at the same time to SFI the service and wheel weights on that response before responding to them but once it's plugged into the role actions topic it starts on all kind of data processing pipeline the road
 oceans topic will then get picked up by election workers which use it turns out to be fetty difficult to load balance capca Topix if you have way more consumers than the number of partitions and also if those consumers are very slow so capca consumers usually you have I don't know like 20 to 100 topics you have maybe 15 to 20 consumers processing messages very very quickly I'll problem is some of the messages may take up to a minute to process and while your processing goes you want to be able to come its other messages that are processed on the same topic or maybe divide those between lots of different processes so we kind of have a middle piece in there that grabs a couple hundred calf Action Accents from the roller auctions topic been served them out election workers does Action workers do all the price of saying make any necessary request usually to a whole lot of micro
 services that we have running on kubernetes and then most of the output from that produce the same gets written back to Casta so this output could be increments of different counters it could be labeled as applied to that action we also one of the things we dumped is just a mess of blob of features that then goes into a carnival historical views and into big query just a whole lot of different steps subjective architectural decisions you made like you describe a lot in that explanation just now what are the things where you what is an example of something what you made a decision you're like not totally sure about the decisions I still panning out in your like noticing the trade-offs in architecture
 we use miasma sequel pretty heavily which I guess it made sense we also used react as a database and as a search engine which basically we needed a good key value store in the fact that they had a search engine built in made it almost perfect for one of our use cases the thing we slowly realizing and chatting to the Facebook and Google Glass has reiterated that point is that moving data between databases is very very expensive so even though react kind of magic key scales for you you don't always want that it's death I mean we actually one of our huge costs is between zones of the same day two cents into a cloud they charge the traffic between the zones you need to be in multiple zones for reliability but you really want to control when they the moves between them in order to cut down on that cost and so we've kind of migrated away from these magic Auto
 databases into a system of shorting that we can kind of dynamically update so as weeks especially with that mean go back to the concert cuz kind of everything centers around that but especially with the counters we have this way of saying okay we have 20 shots now but maybe starting from tomorrow right the data are the study shots and so any old counts will still stick to the original 20 but any IP addresses that we haven't seen before will be divided over the new 10 as well
 so why is that what does it yield savings versus the magical react database model I mean the easiest explain saving is just in that into the transfer so we pay per gigabyte send data over Google's Network in the same Zone it's free but between two separate zones it's not and if you want to Reliable react service you can keep it all in one zone cuz that's a single failure in since I guess so you went around where I can multiple zones but then you going to be paying every time it decides to move a segment of where is the skeletal system the data stays where to put originally I think so so are you saying that you don't rep you don't need to replicate the shards between datacenters replicate its sir the counselors Rhythm to casca and then we have two different databases in two different zones which then pick up the updates five to one side piece of data is
 we never going to move it to another server if the server it's on dies we will create a new server with the same ID with and we got that all the data out of long-term storage in the standard running without any machines dying we are not moving date around so you write the updates to your database replicas instead of having react take care of a replica of take care of it take care of updating its its interzone replicas so whenever we get an IP address we convert that to one of out internal IDs which is a 64-bit number but the important part there is that 64-bit number includes the time so now when we see a new IP address that we've never seen before we can know that we haven't seen him before A and B we know exactly the the timestamp where we see it first
 will always be the same and then we can actually saw it based on that time step so I can say anything that comes off the February 1st 2017 ride it to ease a child's birth is everything before that Radha to these different shots and so kind of dynamically as all systems running we can change out shotting schema which means even though we're not moving data around we can ensure that all Charles never gets old to that special very interesting example of a complex Distribution Systems decision that you made basically because of cost you any other examples like that where you realize like the economics if something were off and you want to make an adjustment based on that completely kind of feels like my job these days is kind of balancing cost reliability and speed and obviously can't take all three and surplus
 call processing into a single zone which is definitely kind of a reliable introduces reliability and little bit we do have a full back that if that isn't izone comes out goes down it'll be very very easy for us to spend up same processing in and I design but that does give us huge cost-savings especially on that as I mentioned earlier that inches are in transfer cost when you're talking about processing what is that look like are using distributed data processing framework Sykes Park Lane court is it much too much simpler work that you're doing we sent me nuts I guess another kind of architecture decision that we decided not to use Sparkle Flink early days with an investigator that and it turned out to be kind of just too much work to get up and running originally and we just need to get something off the door but as we got out solution
 adult kind of made more sense just keep with what we doing essentially all it's worth what it started out with is one giant monolithic Noche SF action comes in it's got a ton of my for services but they were all built into the same app and now kind of as time has gone on we started pulling up a bunch of those in two separate microservices and we are also looking at splitting up the main processing part into a much faster cplusplus or python server wow so JavaScript is beginning to seem too slow for you want me in this there's a whole bunch I mean besides the things people usually hate about JavaScript especially with kind of spam fighting just the fact that it's stores such those its strings as UTF 16 which means every time we speaking to a database that's just one small conversion to utf-8 and back but that happens it's over and over again throttle code base and that actually at
 that's up to cost Riley and it's a list of different things like that that JavaScript as I I mean will probably always have no j s as I'll call system and I really do love it for its use of you sand the speed at which you can develop but in order to save costs we are going to have to move some of those components to cplusplus are we are looking at pipes and also for the easier to write but still faster in summer God's the words machine learning can mean a lot of things can you describe what machine learning means in the realm of Spike and how that what that machine learning architecture looks like we also beginning to reinvent that piece of El Paso essentially but from day one we were not a strictly machine Running Company which I guess a lot of smite a lot of spam companies are I'll system
 is primarily rule-based it's actually we starting to develop one of our own kind of rule languages for variety of reasons but most of the spam fighting that happens on Smite happens with this language and written in simple rules we do use machine learning to identify text and as kind of a reputation system so we can get IP addresses that have low and high reputation and we are starting to develop a machine learning Pipeline with tensorflow and Jupiter notebooks to build models into the system but so far the models kind of result in additional features that you can then write rules on so you can write the rules saying if this IP address looks like a bad IP address according to the machine learning models and they making a purchase over $300 then sad
 when I'm choosing the tools for my side projects the first thing that I look for is ease-of-use that's why I love mongodb it is the most popular non-relational database and it is super easy to use at the beginning of a project I often don't know the shape of my objects and Mongo makes it easy to evolve the database schema as I like overtime overtime as my project gets popular I'm going to need to scale and thankfully mongodb has built-in horizontal scalability but configuration and database maintenance aren't really what I want to spend my time on thankfully mongodb Atlas was released in 2016 mongodb Atlas is the easiest way to get access to mongodb without having to run the database yourself you pay only for what you use for small projects all the way up to large production deployments to try mongodb Atlas today go to mongodb. Com
 daily and get a free $25 in credit use promo code go Atlas 25 to get that $25 in free credit Atlas is the only hosted mongodb service built by the engineers behind the database the company mongodb with Atlas you get end-to-end encryption you get VPC peering you get access to the latest release and for a limited time you can go to mongodb. Com SE daily enter promo code go Atlas 25 and get that $25 in credit and get started with mongodb Atlas thanks to mongodb for being a new sponsor of software engineering daily and thanks for being the database behind a lot of my favorite side projects in the past we're really happy to have mongodb as a new sponsor software engineering daily
 much of the appeal of smite from my perspective is the idea that it's this product for developers at a company to use like meet up for example uses it and as I understand at least they have developers in the mix who are using it so and so it sounds like they need a simplified consistent API that that they can interact with to Define rules and understand how they are going to be having you know how their trust and safety infrastructure is going to work so how does that translate to design decisions on on your side like I guess maybe that's is that is that why you started with the more simple rule base model cuz really want to to simplify the communication between you and the clients
 platform kind of muddled off to the things we've seen and heard about at Facebook and Google where when you get an attack you want a human in the loop to say okay I can see that this attack has these features going on let me ride a simple rule and just stop locking those actions from my days at Instagram you can kind of look in the car device and there's a lot of evidence of the earth spend fighting that went on saying things like if an email address starts and queues dead and ends in at hotmail.com just block the comments for that and that's what a lot of kind of website and to do when they getting this attack they just want to ride a simple rule but they don't have this kind of extracted system in which to put the rule so just lands up in their main purpose so we're trying to build this additional system where you can write these rules very easily they can do whatever you want but they are kept in a separate repository so what we have to give to these customers is a good trip
 the tree of their rules on I mentioned briefly the language but it's written in something that looks a lot like Sequel and as soon as they get pushed that to all servers within a couple seconds will process those rules and start running them on their live action's the kind of stuff I talked about this too but how he was the first engineer to join Instagram from Facebook once Instagram was purchased by Facebook and he described like looking through the Instagram code base and being like what is all this if then stuff and it was all like I mean everyone has it yeah that's so interesting and I guess that's just a low-hanging fruit of spam-prevention if these companies you know they do they have to write some kind of anti fraud stuff into their system or anti-spam stuff into their system because the spam gets so bad and it starts off it all starts off with the same the same precautions that are the low low hanging fruit spam
 yes I mean I'll biggest competitor is kind of internal teams mean every developer thinks they can do this themselves and for the most part they can you can get a very very basic system up and running quickly but yeah we're smart starts to shine is once you realize the things you actually need so one very simple example is experimental rules so when you write something to kind of block a huge category of people you first rather than experimental mode you looking all system you see what it's blocking and then you hit the enable this rule better and I don't have any stories of my own but I put a ton of stories of like you can block an entire country very easily with a slightly mr. than rule right and so I can scan it being able to Canary that type of rule is really important so Smite processes data in terms of events so these customers that you have are there defining the rules
 they're also defining their events that they are sending you you give me an idea of like the life cycle of an event as it's getting processed by your system I mean it's pretty much the cycle I mentioned before so if I take for instance a sign up on Meetup the use of will go to meet up take the sign up I don't meet up will then send us this kind of payload with a little bit of information about them the IP address anything that's ready relevance for the anti-spam system that will run into alcapa topic for your actions will produce the set we might label it as kind of one of the many categories of attacks they Gatsby might not if it looks good we will then write that stream to a multitude of caffa topics which includes the increments and the labels if it was a labeled as a bad sign up that with them get rid into one of our web hook Topix in calf
 and then another consumable consumes that and then sends me to the information about the bad santa that have different things that they're trying to prevent it might have different models that they defined that correspond to different Bad actors can you describe how how that works at does your does a sign up on Meetup does that get passed through these different models they have or do they just Define which types of models they wanted an action type to pass through I mean this is all kind of defined and I'll rule system you kind of you have this main squirrel file which includes you say include this bunch of rules if action name is sign up and inside that file you can then say things that block this action if this and that and a Playa rule say made
 Meetup a dating spam to apply a rule saying this is dating spam to that specific action okay which is the Smite query Andrew language that's a cool feature of the platform why did you build your own query language of those things that looks like a bad decision from the outside I'm and I'm still not convinced everyone's wrong but essentially we started we didn't start out building or not we started out with a javascript-based through language and it had a whole host of problems on one of the biggest ones is it became very hard to staticy analyze it's had a bunch of a security implications that we dealt with as best as we could but it's still very much complicates things one of the hardest things with JavaScript is because it's single-threaded I while true Loop
 Disney in the original version would have crashed out thread so we had to start using a V8 kind of has this idea of isolator JavaScript processes but once we started switching the squirrel in a started turning those off all system got a lot faster it was way more way more of a speed boat and then I even originally realized but the biggest point is ready to static analysis where now when you're out of school rules say I want to block if the account of unique IP addresses by actor is greater than 10 we will only start counting that once you were in your room where is the previous system we had a list of like a thousand things we counted and we would count all of them independently of whether you use them
 what is so I'm sure what is static analysis mean in this context you write your squirrel rule which Florence and says if number of IP addresses used by this actor is greater than 5 then stop him from signing up I mean that's probably not a real good wants any website but it's a potential rule we will as soon as you get pushed that rule to ask me will go look at the code programmatically and say okay you counting unique IP addresses / actor we will then set up a counter that counts every unique IP address used by the actor that'll go down to all sliding hyperloglog system but we will only start counting that once you start using it what that does mean is if you add a rule saying count the number of unique IP addresses for the sex of the last year as you push it we will only have a few minutes of data but we do have other ways of setting up conference in advance if you need that
 sequel like language such a good dialect for defining rules is a lot of these people that will be riding the rules are kind of spam analyst and they all kind of nosql it's a very easy to understand language on the other it's decorative which is great because it may have just said reduces the complexity a single rule is I need to find in one place and there are no kind of if statements that are confusing things no it's very safe to run we can ensure that we can ensure that the program family lights for 1
 so users don't ever Define rules to take too long to run so we do have a whole lot of timeouts cuz that gets pretty complicated in figuring out how long each kind of step of the process will take but if they do the finals at take too long to run we can track that very easily and let them know but also all the other roles that doesn't take too long will complete and every other rule will fire if it needs to win a user wants to customize their rule set that they've developed they can push these custom rules to Smite via get and then there's kind of a continuous deployment process can you explain how that works any more simple than you probably realize okay so we have we actually have it on a single 7 hour but they're in the prices I'm in I'm in the process of moving it into kubernetes
 actually it is an SSH server which then has a authorization kind of hook so when you ask it's the same wake it up works that authorizes you that so when you SSH we check that you are allowed to modify the stripper if you are then I please receive hook which is another get just in the docket stash box folder will automatically look at your changes make sure they correct make sure they pause where to do a bunch of error checking said you if you try use features that don't exist will throw an error with you get in you get pushed statements and the fish will not go through if the push successfully goes through however we have this recolored customer data internally but we will write the file contents to console which is okay and then
 should I keep value storage which all the processing boxes are watching for updates so the second update goes through those boxes pick it up and start using that updates as a side process we also have a kind of compilation step so for all the customer service is used for live updates but for all the customer data we can pilots on a death machines and then upload that with a deploy and then it gets over it in binding of the laptop dates Smite can respond both asynchronously and synchronously to client request can you give an example of when a client would want to do each of these different response types so the asynchronous response is ready. That isn't as urgent that you need to respond quickly to the customer so you got ideally everyone would always use sinkers but the problem with synchronous is that you need
 wait for smart response before letting the user know what has happened so a good example of when you want that is maybe a sign up where you don't want to actually allow anyone to sign up if there were talking in your sign up code while before responding to the uses the user clicks the sign up button it hits your server new contacts might last night if it's okay if we say yes you respond to the use of with okay otherwise you might want to send to use that capture if you already that it's a but there any number of steps you can do but the main thing about the synchronous part is that the user is in the loop so you still in a position to offer use it to verify something maybe two Factor authentication if you have that maybe a capture any number then where is the a synchronous path is really just kind of longer slower processing making sure you catch comments or followers or whatever is bad eventually even if you don't do it within the first
 I see right to the synchronous is when you want to just hear the user goes to to sign up and then the user is forced to block waiting for smites response to see if you give them the okay and then they stink and a good example of synchronous is when you processing a credit card transaction price fuel definitely want to check with us first before putting that through you optimize for user experience the user gets to go ahead and post their inflammatory comment and then once Smite calls back with the response that hey according to the model that you sent a request to this is a spammy comment and then maybe the comment gets deleted
 on the on the user side if there's a standing come in top for 3 seconds it's not usually that much of a problem right definitely so this what's interesting about Smite is it's this product that this would have been useful like 5 years ago I would have been useful 10 years ago like this is a private psych why hasn't anybody made this yet although you the the architecture describing is sounds really Advanced and complicated even though you are using these abstractions that make it simpler than it would otherwise be do you feel like this is is it something that like people have tried in the past and they just haven't really been able to build something that's this robot store I mean why now you know why has why hasn't this been built before important question to me and I don't know if I have the best answer for you I guess one of the one
 the keys as to why we built it is coming from that Facebook history with Facebook was in a position where they have this multitude of different products and then how do we protect 12 different things with each one has different requirements and I don't know that the feeling that many customers like that many companies in the past that have had a similar problem with the same kind of engineering culture that Facebook in Google app where they want to pull this one system that can deal with everything and so the difference solutions to the problem but I guess does not enough had that history of here is how we build this for 15 different companies that want to manage it themselves not just a big problem I see is a lot of the dentist and companies which try solve this problem with machine learning and regular expression just by themselves and it being a huge number of those
 the past 10 to 15 years $100,000 in credit
 since then and as part of a kombinator we've gotten credit from a number of different card providers Google essentially we look a lot like the Google infrastructure and so being on Google actually helps us a lot things like kubernetes things like big Clarity just having easy access to those are great and in comparison with AWS iconx you give you a strong on sir I think we had started on AWS architecture but look a little bit different but I don't think it would be better or worst do you and Pete have domain expertise with AWS never use Google Cloud before I had book is much much newer so they've had this kind of opportunity to redesign their IP honest and using Google Cloud API is ready just to pleasure like AWS is pretty okay compared right
 yeah and I think you know I keep seeing articles about how much cheaper Google cloud is investigated that because I guess I don't need to
 yeah okay interesting so alright like as last question what are some of the fundamental problems that you know after you've been working on Smite for a while about the funnel problems that you feel are just going to be the Matic in that make bad actor so difficult to stop on the internet we need to stop them will said the way we stop them is by finding identifying features so let's say some spam it was really an idiot and he use the email that every email address you start with the word spam weird found it please reply flats and most uses I mean that would be something that uses that have black spammy at whatever but essentially we could for the most part block out that username Baby by the email address prefix and the IP addresses or reputation or whatever the problem is once we start blocking them
 second you stop locking them they will try to get through and so that maybe try change the birthday maybe they've been selling their birthday is the 1st of January because they never bothered to change the drop down but as they keep trying eventually they going to figure out what you using to block them and then they going to change that and depending on how sophisticated just timer is they can get past almost I mean you can make yourself look as legit as you want I wish I had some interesting cases of kind of orange devices where it is actually a legit device on a legit IP address everything about it looks legit but it's also running another process which the spanner is using the Everlasting cat and mouse game between spammers and Auntie spammers continues well thank you for making the time to come on the show quite an interesting architecture you're working on and I'll be following
 Smite closely thanks a lot
 software engineering daily is having our first ever meet up in San Francisco January 11th at galvanized if you live in the Bay Area and you listen to software engineering daily please come check it out I would love to meet you or you have some awesome speakers that Pete hunt who was one of the early members of the react JS team who is now the CEO of smite haseeb Qureshi who has been one of the most popular guests on software engineering daily preethi kasireddy who has written about her career transition from Venture Capital to software engineering via coding bootcamp each one of these speakers is going to give an awesome talk and I hope you can make it January 11th at galvanized in San Francisco you can sign up on meetup.com you can also find the link on the software engineering Daily website software engineering daily.com I really hope to see you there
