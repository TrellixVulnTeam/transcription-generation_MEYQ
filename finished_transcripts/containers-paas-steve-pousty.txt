Transcription: you keep hearing about containers and maybe you have even used Docker in production now it's time to move Beyond Docker in today's episode of software engineering daily Steve posted talks about openshift a platform from redhat that helps Engineers Leverage The Power of containers and the devops harmony of microservices to hear these buzzwords you can always listen to the software engineering daily but to see these buzzwords demonstrated in the live presentations the 2016 O'Reilly fluent conference is coming up March 8th thru 10th in San Francisco and you can get a chance to win a free ticket by tweeting at us about your favorite episode of software engineering daily there more pieces of information about this in the show notes
at fluent Steve pussy will be presenting how to run and manage Docker based applications in production which is one of the things we talked about in today's episode of software engineering daily we also explored how Engineers are working with sysadmin better these days and we're the future of platform-as-a-service will look like but first let's hear from the sponsors that makes software engineering daily possible
 Engineers are always looking to simplify 2 simplify testing in deployment Engineers turn to code ship could ship is continuous integration and delivery is a service with code ship your tester executed against your code automatically whenever you push to GitHub or bitbucket on software engineering daily we've done several shows about devops and continuous deployment is he to devops it's a great way to break down the wall of confusion between development and operations managing your own testing infrastructure is painful that's why you want to service like code ship to do it for you if you were huge number of tests you can use code ships parallel CI to run all your tests in parallel coachable spit up containers on their own infrastructure to run your test in parallel with the code passes your test coachup will deploy it automatically to your users companies like product hunt are already using coship to speed up and simplify development
 sign up for free and start shipping today go to coachup.com or to try out code ships new Docker platform go to coachup.com docker
 Steve Christy is a developer Advocate with red hat Steve welcome to software engineering daily thanks great to be here you have talked about the unfortunate long-running war between developers and sysadmins what drives the difference in perspective between doves and Ops or sysadmins caused by I mean part is because they usually sit in different areas right so I think part of it is
 in most organizations even I like I used to work at Yale University and the one space and we develop different space is actually part of what drives it I think that's one of the things I like about microservices is microservices when done right actually include Justice admin person and so everybody has to sit together work together all the time it's not like I check it over the wall that kind of thing but then I think the other thing is the tasks that and the goals of each team I think for developers they usually want to roll things out fast because they have the end you should ask them if they want new things they want there's a bug fix it now right and I think so they have an emphasis on quick and easy for them to develop with and I think on the other hand for sysadmins they're used to running things like Oracle RAC clusters or email servers wear email server should never ever go down raining at the rap cluster goes down the whole company is in a panic because they can't do anything Financial
 and all that stuff is on things that are rock solid and just keep going no matter what's happening and if it's working don't mess with it right because then everybody's fine like you only mess with it if there's a security vulnerability and even then it's staged it's not like all the really working to fix it so I think that difference in goals actually leads the group into conflict because the developers are always asking from you and fast things in this is Ben's are like what we want to test a we want to keep it nice and slow there's why are we doing this cuz it wasn't broken me to control process and developers are less so I think that's part of the problem episode we're going to get into infrastructure-as-a-service and platform-as-a-service and why platform-as-a-service is useful for resolving the types of problems that Debs and Ops people encounter but I'd like to level set for people who don't know what these terms mean could you define infrastructure-as-a-service and platform-as-a-service sure
 there's still some differences in definitions in the community I'll give you mine and I think this is from what I've seen this is kind of the majority opinion so infrastructure-as-a-service the biggest infrastructure-as-a-service provider out there is Amazon web services right so it infrastructure-as-a-service it's exactly like the name says you ask for infrastructure-as-a-service so just like with Amazon web services or openstack you would say I want a server with this much RAM does much CPU with this network this DNS and it actually usually don't even get the DS you just get an IP address so you get all that stuff set up and it's almost instantaneous rate compared to the old world which is awesome but persistent means it's not really so awesome for developers developers because we no longer have to wait 6 months for things to be bought and go back and forth and racked and stacked and and so that's really great for us but the problem is for a developer who has an idea just once
 getting going on it they still have to install all the software keep it up-to-date do the DNS stuff they have to do everything else when they really just wanted to write an application so platform-as-a-service is a level of infrastructure-as-a-service I work on open shift which is Red Hots platform-as-a-service there's other ones out there that probably the largest one is Roku that most people would know about any idea what that is the developer while talk about what it's like an open shift and it's like the sun most other ones as well as well I want to work with python and I won't post press and they send one command to the platform and a python server server with mod wsgi and there's a git repo or some Source repository the developer of java example they would have a maven file with all the dependencies they put that in the get repo they put their source code in the repo they push that to the platform to platform take that builds it deploys it it's already got a URL it's
 Freddy got all all the wiring hookup it just runs and the developers just working on data and application stuff and not having to think about how do I configure this and then if there's a security vulnerability the platform is a service provider actually patches Tomcat or Apache or you know where the patchy like SSL the heartbeat right that was in an infrastructure the service model you have to go you add the developer would have to go at all the places and hope that you got it right with platform is a service you would count on the platform provider to actually patch Apache and all the other places that heartbeat might be affected by Pharmacy Service as this layer of usability that sits on top of infrastructure-as-a-service so with that in mind why is platform-as-a-service that you touched on this in in tired of the security vulnerabilities but I think there's also a whole a whole host of other things that make platform-as-a-service unappealing
 .2 resolution between developers and sysadmins could you touch on some of the the additional points the additional problems than it solves when think about the relationship between Gavin off yeah I mean to remember dad's wants wants to do things quickly and they want to get go and they don't want to say hey system and can you send me up a VM and then wait a couple weeks until or even a couple days until I get spun up bright an Ops don't want to give route to developers and that's basically the biggest thing they don't want to do they also don't want developers configuring things really differently then it's going to be running in production because then there's this whole nightmare of having to translate things so what happened to platform-as-a-service and again I know openshift most that's what I know best so I'll use that as an example with openshift what happens is the sysadmin set up the cluster open shift right so they set it up they set the version of Tomcat days at the version of Apache they in in the version
 currently an online that we use our own custom containers in the new version of openshift which will be coming to online sometime this summer it's all Docker containers right to the system administrator can say these of a Docker containers I want you to use when you do your development but you go do whatever develop me want what's that cluster setup the developer can then just request resources as they need them right so they get their own playground without having to wait on production to do it and so like a perfect example of this would be somebody like DreamWorks so everytime DreamWorks produces a new movie they often have a new website with the right and so the developers are needing to crank out web websites regularly at a pretty high Cadence compared to most other places and fixing things right it relatively quickly and then it goes away sysadmins don't want to be sitting there spinning up something every time and worrying that what they're actually building won't run in production so for example DreamWorks runs the whole cluster that's all open checkbook dad he weigh
 introduction the what happens is the dad's they say for this example we're going to be serving up a lot of or for this movie where you be serving up a lot of assets we want nodejs and it's already there on the cluster so they said I want and I want and they both of those they start writing their code they're done they tell the QA team hey we're done come test it so what happens if you 18 has view privileges into the dev in into the dev project and they clone the application but they put it on containers with more resources available to them and so then they can do testing on it if there's a problem they can push it back to dad and say hey keep doing it and they can go you know keep hitting that cycle and then once you raised on his eyes yet this is good to go
 production assistant men's so Deb can't push into the QA or production but each level above can see the level behind right as it on the road to production so production is probably just owned by sysadmins and what they can do it they can see the Q a project that's been passed up and they can say okay I'm going to clone that one and now give it even more resources and the DNS entries is going to get his actually reel life Productions DNS entries and so what happened you got this nice the dead got to do things quickly without having to talk to product without having to talk to the assistant men's but this isn't men's new whatever they were moving along the process was going to run in production because that's what they were running all along and he doesn't have you can use it all different phases of the life cycle even if you just used it for Dev what makes it nice for production is still this is Ben's know that everybody spinning up Tom Cat in the same way and their source code is going to probably be structured in the same way but they can also give them lots of other things to play with and have it sandbox inside
 the cluster rather than setting up individually on each VM that they spin up usually like for a developing say all well and then forgets to put something in writing and so then they're so it tries to strike a balance between that I can in certain cases with your service is not the right answer if you're going to need to go in as a developer and play around with firewall rules or you're doing something really funky with networking or you need to install a lot of packages that nobody else needs and they have dependencies in the core system especially with the older way the dark the containers were done that's not a good situation now with the move to Docker in Docker containers that's actually a much more realistic scenario that people can put their own dependencies build their own Docker images and go from there it's we moved into a doctor came out I would say what is it 3 years ago yeah something like that yeah about 3 years ago before that containers
 BSD change richdale's those are containers time it's just with what doctor did really write the container specification was cross-platform on Linux right and it is it lets you do a layered file system so they can do things like this one of our customers in Canada who's doing an amazing job of this is there's Docker Hub right where everybody can build their own Docker container and it just so we can also levels in on this with Docker is just so everybody understands the difference between the atoms and Docker containers cuz I think they're still needed some people so with a VM what you're saying is slice up this operating system and giving this virtual machine service again right answer then you install an operating the entire operating system into it and then you put all the other pieces you need inside of it
 write a 10 and one of those things would be ends is they also actually grabbed all of when you say I need 4 gigs of memory or 8 gigs of memory for this VM it grabs those resources and they're not available to the rest of the machine right even if your app in there is only using you know a hundred twenty-eight Megs of ram about the operating system you're still getting whatever the machine was given to you and so it's actually quite heavy in terms of resource use especially if you're doing something like microservices or anything in general the app app development what happens with Docker is wood doctor in containers do is they say we're going to slice up the actual OS we're not going to actually give you a new OS for everything that you spin up we're actually just going to slice up The Colonel on the OS that's there and you're going to bring whatever dependencies you need inside the container and we'll stay you can have up to 2 gigs of RAM but if you're only using 512 Megs of ram then that's all you're using and the only Ram your axe
 using is the ram did your application needs not all the ram that you needed to actually spin up the host OS that's running the containers does that make sense to have a prototypical example of platform-as-a-service that we can discuss throughout this conversation hit the perfect example is open shift because you work at red hat and Red Hats Pat platform-as-a-service product is openshift so what is openshift how how does open shift like how do you how would you define it as compared to other platform-as-a-service products to use we actually have been running for almost 5 years now their first iteration of open shifts so where we had it online and everything we were using our own containers not Docker containers
 and basically what it allows you to do is to take your source code say you want these packages spit up a container and then just run it and we had that posted it online which now has over 2 million applications that have been spun out you know hundreds of thousands of users that have used it and we also have an Enterprise version we're just like there's a red hat Enterprise Linux there's also where company could pay also for the software and put it on their own massage machines and run the platform-as-a-service themselves and of course since we're Red Hat there is also an open source version which is openshift origin and that's where all of our work actually takes place isn't open shipt origin it's in GitHub under openshift origin repo for it and that's where all the Upstream work takes place and that you can also install and run anywhere you want you just can't call in for support and you don't get the nice installers and all that stuff right so we have actual companies you've taken over
 origin like it up loud in Brazil where they said hey there's no good real pass hosting in Brazil right now we're going to take openshift-origin stand that up and run that in Brazil and so that was the original version where we use their own Gears in our own cartridges then last year at about June be released our new version which is now using Docker is our containers then it uses kubernetes as the orchestration layer right so these are two very large other open source projects and then we're putting stuff on top to make it easier for developers to use an easier for sysadmins to use both Docker and kubernetes to push features there as well or go to make it so that anybody running a kubernetes cluster gets the same we don't want people to think that they're the red hat Brunetti's is somehow different from everybody else is kubernetes so there's something we want in the base layer we push that up so we replaced a lot of the gun
 that we had in our old version with kubernetes is an open-source platform from Google that allows the orchestration so this is why it was a long way of me getting to you know what there's some on my team we stayed at platform-as-a-service is kind of passed and now we're a container application platform right so I think right now we are the we are out in front of allowing you to take Docker containers and then run them in production on your own machine or run them in are we have a dedicated instance where you can pay us until spitting up and check cluster in any Amazon or Google compute engine and that'll be yours and you can run it and then buy this summer sometime we'll have the public version again like we had before so the idea was open and that's another longer way to get to Oak what you would do with open just now is dead with your Docker containers you can either do that an open shift or wherever you want and then you can take those and then run
 for real in it open shift right without having to have the expertise of how to stand up a kubernetes cluster and maintain it or add music to your cluster or a Docker swarm cluster it's actually more focused on that separation again we're dead just have a Docker image and assisted Monsanto all set up the cluster for you and then we'll run it all together and then it gives you all sorts of the advantages like failover and scaling and also some other really fun stuff to the a base level conversation for my doctor is so useful to a platform-as-a-service I know you've touched on a lot of that at a higher level but just for some people who aren't as familiar with with the movie to having to work directly with i for my service Dave and work directly with Docker show
 you're just talking at base level theoretical terms why is Docker useful for a platform-as-a-service like openshift chocolate about why it's useful for Deb's is that okay as well just a little late please for a long time but the usual way that we develop deliver things was either a tarball right of all the source code or maybe if you were more advanced you might have an RPM or a Debian I forget what I know it's app yet but I don't remember what you're actually delivering with Debbie but basically you taking some sorts sorts go to you're laying it down but then whoever gets that Source would actually has to configure it to run on the platform and one of those things that Docker containers get around is they actually let you can figure everything and let you deliver that it can figure it out location wherever you want it's very portable you can just move that configured application around
 the part with Docker falls down is when you move to production so it's kind of like them to me when I ask developer when doctor came out 2 years ago when I started playing with it as we knew that openshift was heading in that direction I was like all doctor by yourself that's not much better than a DM right like I got all the stuff in it and it's all configured but like how do I actually run this in production and I don't really want to configure all that stuff and so how do I do networking like networking is particularly hard or storage with Docker is is kind of tricky as well so what's the nice part for a platformer the service or is it developer is you can actually take your package application but you put into different Docker containers and then you can deliver those pieces of the application to whomever and Sable run this and so what's nice for us as openshift is we got these Docker containers we can actually give you a Docker container and you can take your source code and put them together and we know exactly how to run it it's not like installed it and saw that install this then tweak this and sent this to this
 so that you can just basically give the docker container and run it but the nice part is the developer has a way to run that Docker container on their local machine and play with it as well so they can play with it what I think one of those things are kind of hard for developers in this is where I think doctor has some work to do is the local development experience for multi-tiered applications it's fine if you do an application with the database and the web server in the same Docker container but once you start having multiple Docker containers together like oh I haven't messaged you and I have a cash and I have two web servers and I have to database servers and there and replication and this is how they're all talking together actually moving that might be able to set that up on your desktop and it would be tricky
 and it wouldn't actually be very portable to moving that up to production I mean there's some products out now open just has one but there's also like Docker swarm the doctor's home again I think is more geared towards sysadmin running containers and highways open what open shipt is a way for you to actually write a configuration file and send the whole thing up and run it and we have we have a one of the other nice things about the way it runs as we have an all-in-one VM which has the entire openshift platform in a VM so you can download open shift out of work VM some engineers and I work on that you can bring that down to your machine spin it up using vagrant and then you can pretend about the cluster do Oliver specifications spit out the Json file and as long as your production class work and see those Docker images you can just send the Json file to the production cluster and it spins up the exact same thing in the exact same way so it's the entire application around as opposed to individual Docker containers
 Engineers love Automation and well front automate your investing as a software engineer at there are certain processes do you want to execute no matter what like integration tests during a bill you would execute integration tests manually you would use a continuous integration tool like code ship or Jenkins to automate your integration tests well front is a tool to automate investing just like a continuous integration tool runs your test automatically wealthfront can reinvest your dividends automatically and performance tax-loss harvesting automatically to get your first $15,000 managed by wealthfront for free go to wealthfront.com se daily and get started with wealthfront Slayer of automation on top of your portfolio wilson.com SE daily check it out it would support software engineering daily and you will get $15,000 in managed for free if you sign up
 get back to the things that you can't on me like writing code
 so you explain very eloquently how Docker gives us this layer of standardization that allows us to think in terms of these easy to use Docker containers rather than tar balls or like exe zand strange configuration strange unusual configuration files so now that we have the idea of of Docker being being how we are piecing together the applications that maybe a sysadmin is is configuring and and and allowing the developers to deploy in a way that they have contractually kind of agreed-upon give me an idea of of where kubernetes fits in and how kubernetes what what does kubernetes do within this relationship on this platform kubernetes is getting at solving that how do you run Docker containers in production
 right that's its main goal what it does is there is a master a couple if you're in high availability of a cup of Master machines and that's where some of the infrastructure assets and then you have a bunch of nose switch are going to actually run your Docker containers and what kubernetes takes care of in that cluster is orchestration so like how did the how do I spin up different ones how do I speed up different pods in different places right scheduling where do I schedule the odds I said painters in containers and containers and so a pot is in one or more Docker containers that you to run together and not in the sense of a web server in a database but more like a database and a monitoring tool a different note how to make sure if one goes down it'll spin it back up again right so they haven't built in all sorts of interesting
 just to run and orchestrate and isolate all the different Docker container so there's like Network isolation between containers that are running because I don't want my containers to be visible to your containers Rite Aid also does things like resource allocation to the pots and making sure the quotas are met and all that it like enforcing quotas on containers and things like that everything above the actual container it takes containers and actually has a great way of running them and then openshift layers on top of that because he's comes out of Google and it was built on the same thing it's built by the same Engineers that built for going to make which is what Google uses internally run containers anybody using Gmail is actually using a containerized service that's running a Google Google spins up about 7,000 containers a second inside a Google so everything that Google does is done with containers
 not Fork anything at the Grammys it's a straight kubernetes like if you wanted to use the Kubla API against an open shift cluster you could and are Json so what OS right so what let me go sorry I keep getting ahead of myself let me finish the open shift part and then I'll go back about why this is awesome things like a software to find network layer Network layer this might be the Google compute engine or Google storage so we bring software-defined networks we bring a safe driver or a Gloucester driver or NFS driver that we push up into benetti's right and then openshift brings things like these is really just about containers we had things on top of the containers that allows you to configure build Pathways like I hate this source code plus this Docker image and build this and this and then it also like a deployment configuration like watch this docker-registry whenever it changes actually automatically deploy it and so we actually had stuff on top of
 base layer to make it easier for assistments and developers so what other things do with kubernetes it's not new in the world but it's new for us an open shift that I really love is coconut oil uses decorative configuration so what I mean by that is we used CD to store the state of the world right and that is the truth right and then what's happening on all the news is there always checking into that CD saying hey this is the real world match the truth if not make the world match the truth so what that means is I can take a Json file that specifies which containers which Bill Pathways what URLs to expose all that stuff put it into a Json file push that to open shifter kubernetes and the true that becomes the truth and then the cluster checks in and says hey do we match that truth no make it so they're just goes out there and starts doing all it's worth spending all that stuff up it's not like
 like we have to go to each node and tell it what to do the nodes all noted to check in and to make themselves like that which is a very different model and it makes it much easier for us to do things like scaling were telling you the worst part you are in the Bill process because there's all sorts of checking in that happened between two nodes in the master it's just a much nicer way and so what comes out at the end of that like I said before you can spit that truth back out right into a Json file and you could give that to your sister man and as long as the system in can seem to see the same doctor Registries they can give that Json file right back into their kubernetes cluster or their Project Beast Buster and spin the exact same architecture up again because that becomes the truth there and then the cluster will proceed to make the world like the truth I'd love to talk about this in more of a holistic practice sense so
 Yokai talked about how openshift works with talked at a high level about how it improves the relationship between developers and sysadmins I'd love to put the shin in a more concrete contacts so how would I use open ships of I'm like let's say I am some kind of e-commerce company and I've got I want to use openshift or some other past let's just say open ship to build like my microservices architecture for my e-commerce solution that has all these different things it's got a shopping cart it's got you don't got to be able to like look through items I've got to be able to display ads all these different things that are composed with microservices is micro services are you know running on these machines that have open shift why would I use openshift to build a microservices architecture and and how would this affect the
 the relationship between developers in sysadmins at this theoretical company allows for much faster experimentation as long as there's a approve Docker image or that they really like living on the edge developer cluster anything running in the doctor registry you can run an open shift right so Dad can find them. They really like on Docker Hub and they can use that as their basements that they just run an open shift so that ultimate experimentation what we have found with most inside of most companies is and this was a great example of I saw where a doctor helps is at least a company's I talk to you they're usually running well no surprise right red hat Enterprise Linux so what they do there was a say hey Deb go grab that Docker image that you like try it out see if you like it but then give me the doctor file and I'll rebuild that exact same image just using
 how is the base layer the router comes from Red Hat so I know I can get all the pictures automatically and then you can use that I'll put that in a registry that you can use and so then what they'll do is The Debs can say well here's an old one that I want your is a ruby one that I want yours a mongo has a couchbase years are all the different types I want the systems make those put those in a registry and then the Debs can just play with them as they like it when they're starting up a microservice one of the things you have to decide is what's the right technology for that service so they may say oh this should work fine in Java and then they try to do some some performance stuff and it turns out it would be really nice if we could do some sort of single thread an old model it's very easy no one has to make a new the and no one has to do anything else like that they can just destroy that old project and spit up with Note again and then they can we want for the search service we need something like it has really really high throughput in cash is really well let's use this use Cassandra or let's use memcache because all we're doing is reading we don't really care about
 what do something like that or men base and so they can actually spend that up as a service and not have to worry about what any of the other teams doing right and they can keep it rating and then they can tell we're ready let's expose that you are out of the other teams right and only the URL that they want to expose and then he can control it and then inside of their project are there cluster they can do whatever they want so it makes it much easier for them to they always what we want rabbit or we want acted mq inside of are so we're going to put that there and then some of the other things they made be doing something like a central authentication server so the system Benz can say well we're going to own that so we're good we're going to have another openshift project and will speed up the central authentication server in that and you guys all here's the URL you guys again since you hit against then we'll take care of that service there or a dead teen can say we are all the entire authentication Service with you guys don't worry about it we'll split it up and then you can have a centralized authentication server as well so it's kind of a really nice way to orchestrate everything together and but still getting people freedom to play with the things they want to play
 if that makes sense right yeah totally and so I think that really helps with the microservices architecture because it's very easy to spend things up try things out change things if you need to change things but also still keep things isolated in a repeatable way as opposed you were all spitting up RPMs all the same way so there's no system there's no system there's no game internally about Auto knowledge right like oh I have to go talk to those people exponents been up note and there's plenty of notice bit differently how do we make that work oh this is men's kind of don't know that way but they know this way if you use that more standardized models and I passed everybody spending up know this is relatively the same way and if somebody comes along with a great solution that they want to actually change the way no drugs you can bake that into the docker image and then have all the other nude all the other note applications reboot based on that changed the docker image and everybody gets the advantage right there yep totally so
 we've done about quote microservices one of the team seems to be a it's all the times that company will employment microservices to improve the relations with Anna, it's not like you get some sort of crazy performance benefits or something out of it it's more this this developer options Harmony type of stuff but there are also you know the Practical advantages of of having some some atoms of scalability that you you know that you've got these the smaller services and you can really pinpoint what aspects of your application need to scale up or down during high or low traffic so is open shift or a platform-as-a-service in general useful for this type of up up or down scaling under different circumstances of traffic
 we'd actually do a lot with scaling and it turns out they're open chip this is one of the areas where we differentiate from a lot of the other platforms is a service what openshift actually does is it allows you to scale the number of containers automatically based on the load coming into the application right so know if you want to you don't have to write you don't have it so you can turn that off and you can manually scale which is actually still quite easy like in the new version of open shift is actually even a web interface where you click an up arrow and it just spins up another container and that's it one caveat on that though is whatever continue your spitting up has to either be stateless so that it doesn't matter if the load balancer sends different connections to it or it understands what it means to scale up so for example the are Partners at crunchy geosolutions they've written up postgresql container as well along with a bunch of a kubernetes file that allows it to automatically scale up read replicas
 so it starts up a master and a replica right away and then you can scale up read replicas as you're going along and I can actually automatically do that so how that looks for openshift is you can in the new versions on CPU in the old version is on HTTP but nobody new version in the new version will be more rules coming up there right now based on the amount of CPU being utilized inside a container the platforms are servers will actually once it reaches a certain threshold will actually spend up another container put it behind the service layer and then just start down Broadband connections to it and it will not load goes away it'll actually spin it back down again and so no one even has to be contacted it'll just do it automatically and I got some videos that actually shows up on the web like I got a video about something called scale or fail and it shows Auto scaling an application to handle an increase in traffic I use blazemeter it's it's jmeter is a service and I basically throw a ton of work at my
 at my either my individual application or my microservices and then I watch it scale up or scale down cool I think that's what we can put that in the show notes sings about those water testing services actually become even if you set it up internally and have your own service one of them. Actually comes much more important in terms of microservices because microservices the only way you can exercise the entire application like doing actual integration testing is he going to have to hit a whole bunch of different URLs and making sure is actually behaving in the way you want you don't have just one more file or one python application in or one Ruby application that you're just like Snot like one rails application and you just exercise those in points you have to be sending URL and posting Json and accepting J's on and doing a whole bunch of other things and so I think you know what having some sort of integrated testing service makes that a lot better about microservices for a while
 hey dope about performance differences I agree with you I haven't yet to meet anyone who says they do it for performance reasons they do like the scaling reasons about being able to scale independently but I think you know that the more mature customers I meet with it's exactly the reason you talked about which is
 I don't care what I want I want all this bickering to stop about what technology were using for what service because one team can agree with another team I want the teams to just own their service and I also I'm tired of dead morning a production saying will work on my laptop I don't care you know why isn't working for you they want more autonomy for their teams in terms of technology used but also responsibility for when things go wrong and being able to be on the hook and that's the team that's actually owning it and I see the more mature companies think that's the real reason for using that and I think more
 well they actually want to go to the devops model and going to a devops model is really hard when you're building a single War file that takes like 3 hours to build and then takes in a couple weeks to test that's just not acceptable so they are actually moving to the microservices to also help with their devops transition is well in your software it's hard to have a model that is not pushing that monolith over a waterfall for every cycle exactly so you're giving a talk at fluent 2016 called containers and more to get your service running at the skill you need what are you planning to cover his talk show in this talk it's mostly going to be what I talk about here today so I'm going to talk of a very small bit about Docker I think we were far enough along in the evolution of doctor now
 the most people basically understand what it is then I'm going to show the kubernetes an open shift object model just a little bit of it just so people understand the terms I'm using like service route persistent storage what are they build configs all those kinds of things and then the rest is going to be demoing an actual application running on top of broken ship like the deployment model how I can scale things up and down how I can take things out of service put them back into service just by changing labels mostly be showing people cuz I think you know I think people appreciate seeing demos more than me just showing slide where most of the time so I'll actually just be showing a bunch of demos of my application doing a bunch of different things that are possible when you move two containers and something like kubernetes in open are there particular things that developers need to know about writing applications that scale on a container based infrastructure or
 do developers just get to continue thinking about developing their software
 so I grew up in the age
 monoliths tonight you know where you were pretty you are great and you had a separate physical server for the web tear in a separate physical server for your database to your you were like all my gosh that's awesome availability power supply in a raid array in each of those are great right and I think up until just recently that's the way most people have been trained to think I think what developers need to stop thinking quite as much about is that being the architecture they prefer to deploy to and that rather than thinking about vertical scaling we're moving into a much more horizontally horizontally scaling world where when load comes in instead of calling up the system in sang hey take that back down and put some more memory in it or add another CPU or upgrade the CPU you actually think that I'm just going to add another container on the side and say you need to start thinking about you don't always have to do what I hate making these huge broad statements because there are like I don't think everything should run
 containers I don't think everything should run on a pad I don't think everything should be that way but I think you're doing yourself a disservice if you don't learn about how to write your Apple application so they horizontally scale and I think one of the technologies that people made out of used as much before or maybe of using a different way they made is a message to use I think people maybe use those before as like an Enterprise service bus like at this big layer in big complicated applications if you look at some of the younger developers are the developers we're starting to look at some of these you were horizontally stealing at their building message to use in as a way to decouple the different pieces so that I can nobody knows exactly who you're talking to they just know they're talking to the message bus or the message queue and so then there that way it's it's hard to do sessions state with a message queue right it's it's much more complicated if you wanted to do some you can it's just much more complicated you have to add in some big cashing layer or session cashing I think that's some of the things you actually you don't have to write all your apps that way especially
 trying to someone little one off right but if you're actually starting to write some real applications would pay to start playing with them and to see patterns and how they feel and that's about what I think people need to start thinking about
 are we get more and more people towards the devops model well or as more people choose to I don't want to talk about like some sort of cult are there are there points of contention that could potentially arise like to think of it in terms of devops you know oh it's it's harmonious but it seems like if the developers are riding their code AS infrastructure and the operations team is right there infrastructure as code maybe there could be some potential conflict an overlap so maybe I'm wrong about this if I am please correct me but if not maybe you could give some best practices for how Devin Ops should
 sure to give bounded constraints for for how they should manage their systems
 you know
 I think I can't give any Global rules doing this well the biggest thing that they dumb is broken down the boundary between developers in operations teams and I think that's what some people talk about with the no Ops model and write some people or even talking about now about no Ops I think Amazon Netflix is moving to a no Ops model where everybody is an Ops person and the part of the problem with saying that is that's very threatening to operations people and I don't think it actually means that they go away I just think it's that their place in the chain or their place in the T-maxx not even to change their place in the team the shifting from being separate to actually being part of it and they may actually be even writing a little bit more application code but they I think I'm model you're going to have operations people around
 for a very long time to come I don't see that being able to be totally customizable I sync when you're the most important thing though is having a team and not letting that team work together to figure out what's right for them like if you look at something like Etsy they have I saw a Rafe Coburn I don't know if you still at sea but when he gave a talk at Tober Fest a while ago they had an instrument did their entire deployment flow and their infrastructure so well and automated it so well that we didn't I think it's the first two weeks a new debit expected to push to production but they could change and production in the first two weeks so that's a lot of trust all the way around I think the trust and working together as a team as a huge part of that I heard Adrian Colbert born in the others talk about this if you don't change your organizational model Boot microservices and devops will fail if you don't actually change the way you organize people and the way they relate to
 weather no amount of Technology your new pattern is actually going to work you're just actually trying to force it she's going to fail I mean it if you don't put those people together it's just going to fail if you're not a team there is something else that you about tension points I don't know I think it's on and you try to move that forward I mean I think you could see some tension from the security team right cuz they're usually they have very different concerns from the OPP's and the and the dev team right and then Enterprise Architects they usually have different concerns as well it's a very large cultural change to move to devops and microservices and I think the cultural part is actually the hardest part and working at cultural part out is removing those tension points that you're talking about is that I don't know if that helps or not perfect where does testing fit into this conversation how does
 yeah what it what is what is a testing organization look like on on on Paz and how do the responsibilities of developers and operations get defined in terms of testing so I will actually do like I said with DreamWorks with a q a team and they clone the developers application and then you go through QA testing other companies they may say the testers are actually in the same team and they're testing the application continuously while it's being deployed on the past right actually they're working and testing because the developer do each have their own individual little project they are pushing into the you can merge them back up into the main project if you want as well and you ain't give me actually just testing again the main project the developers are pushing too as well it can fit into lots of different models QA doesn't go away it's probably in a micro Services though I would imagine that you I would actually be part of
 a part of a microservices team you don't want that he bolted on afterwards you actually wanted it just like you want to see men in their just like you want to TVA and your team you also probably want to ask you a person and your team helping to it so that everybody that you a person at least some level and you're actually doing the right kind of Q8 expert operations that someone with QA expertise actually brings you want to close off just kind of a broad question where is this going what is the future of platform-as-a-service
 that's a that's a good one I just know that if you would ask me that you know it 6 years back and said is there such a thing as a platform-as-a-service it wasn't much of one back then it was really nice and everybody was saying oh yeah won't capture March market share and it won't be used very much and now I know we is Red Hat we have our customers coming to us and saying you know I need this feature like that picture and went like that part of the reason why we moved to Docker last year because because all of her at all a large percentage of our customers were coming to the doctor when you go to the doctor so I think the landscape is changed in terms of what people are expecting I think
 in the near future I think it's going to be standard at most companies are most places that there will be some sort of has like infrastructure set up I think personally it's all going to be open but in reality it'll probably be some mixture of ARP as other passes either online or something that they bring in house and then some homegrown ones like I've seen a lot of homegrown homegrown pass like things using ansible and puppet and Docker and Jenkins and this whole thing of the Ring together I think more of those will tend to go away in the same for the same reason that AWS if you come so incredibly popular which is a lot of companies realize you know what running around Hardware is actually not we want to focus our energy on will let Amazon do that and will pay for it and when you can pay a little bit of a premium because it's just not something we want to focus on and I think building homegrown platform-as-a-service will be another one of those things tend to die away as the larger players be
 more popular and well-known and then you know I think we're at a time of container explosion I think the ends at a very nice job opening up the world to accept containers because once people thought of all I don't need a physical machine they became more open to different ways of slicing up a machine and now I think with Docker and some of the other effort that's going on around containers I see a lot of things happening in the container space that we hadn't seen before I think it's one of those see changes in terms of how things are built and deployed I know Red Hats all in on containers our team we have a lot of contributors to the doctor project and I know that we're now starting to also offer containerized versions of a lot of the software packages we have Atomic OS which is basically like the colonel Journal D6 to be just real low level functions and everything else you want to bring you bring a container for some of our customers are saying yeah yeah we don't have servers that we don't need
 post fix on a server that's not doing email right we are actually run two different versions of Post-its for two different sets of people and we don't want to get into RPM conflicts we can do that with containers right so you can be much more efficient and more focused using containers and I think you'll see more more Enterprises and small companies just using containers
 ghetto so we've been removed from the days of a virtualization two containers or the focus was on overtime now we're now or slicing up bbm's into containers so you know we talked about this at the level of like software efficiency but I'm also curious from an economic standpoint do are there a lot of cost savings associated with moving to containerized infrastructure containers coming out I think you know I still think v i was make sense for certain times in applications I don't want to say that the empty bottle weigh in we are actually see people put in containers into DM's all over the place right we're not seeing a lot we see some containers on bare metal but we're also seeing a lot of containers inside of the M is for lots of reasons like security reasons or slicing reasons for liability reasons
 but I do think there a lot of things that people had used yams for in the past are now getting done through containers so I think because you're not paying a VM license unless you're using something like the open-source versions of Zen or liver or something like that you're paying for every VM you spin up and so if you have better ways of getting more efficiency out of your VM without paying anything extra for that most people are going to jump on that even when we were running our own containers before and the other version of openshift we would say that people should we're going to give you more efficiency no matter what because it's impossible for most companies to get unless they're doing like high performance Computing feuding to get their VM that they give the developers to be running white hot anyway right where you bought you get a BM and yes you can get your server to get a little bit hotter because you put DM's on top of it like you're getting more efficient utilization of that server but you still can't really push the VM as all the VM
 it's hard enough getting your maximum value out of that physical machine that you bought two containers actually I allow you to pack the fish much more compute into that same machine or use it more efficient you're not getting more performance it's just you're using the performance you have more efficiency efficiently using containers because you can pack more into a good each container that spits up isn't spinning up an entire the right and not an entire OS so you can get things in there much more dads and you've been over British you can over-provision because not all containers are running at the exact same time like it says oh yes I need 512 Megs of ram but it doesn't need that all the time so you can actually usually end up over-provisioning and depending on how work load shift around you can get I like at 10 to 20% / provision on that and then actually one of the things that used to do with the old version of a open shift they will be bringing to the new version of open shipped as well actually I'll probably come probably will probably be pushing it up streaming to kubernetes is the ability to
 container to in the version of the one that's running an online hour to call version 2 hours we could actually see realize the entire container to disk and so it stops using Ram it stops using CPU is just using the disk space that it needs and then the next connection that comes in we could spend the container back up again and then start serving it up so that first user who came back in they might have to wait a little while well that container spun up and buy a little while I mean under a minute and even in a job application usually and then that would spend back up and then it would start me you can start serving it up again and I would stay up again for 24 hours as long as there was still HTTP connections to it so this allows a lot more over-provisioning because developers in their excitement about new and I got to try out rust now when I got to try out her lying and I got an answer they go to their system and Friday at 5 because I'm going to go and until this
 systems are working really hard on it they give it to them the developer the developer Works a little bit on it then forget about it and never gives the DM back here doesn't matter if you give them the VM or the container because it'll actually just idle down to disc if no one's using it and so you don't actually have to worry about it sitting there eating a bunch of resources
 well that sounds like a great place to stop at Steve's the super interesting conversation thanks for coming out of software engineering daily and talking about openshift and red hat and Tanner's and everything else that we discussed I appreciate conversation thanks so much so I hope it was helpful and I really appreciated the time yeah super helpful for you alright I'll talk to you then okay bye
