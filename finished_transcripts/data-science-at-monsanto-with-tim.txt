Transcription: Monsanto is a company that is known for its chemical and biological engineering it is less well-known for its data science and software engineering teams Tim Williamson is a data scientist at Monsanto and on today's show he talked about how he and a small group of Engineers created a cultural shift at Monsanto around data science driven genetic engineering in this episode Tim explains how useful graph databases are for modeling of the genetic lineages that Monsanto works with and he talks about how Monsanto simulations and experiments on their software genomics pipeline
he also talks about how a few Engineers can create a cultural shift within a large company like Monsanto using the leverage Allowed by software after we hear from a sponsor of software engineering daily we will get into the weeds of Monsanto data science as a software engineer you have tremendous leverage in the employment Market every company need software engineers and these companies are all competing for you the engineer a scarce resource but as an individual engineer you don't have much insight into this incredibly opaque Market that's where hired.com comes in her.com assigned you a talent Advocate who works to understand your needs and works to find you the perfect job go to hired.com se daily to try out the platform today and get a $2,000 bonus if you find a job the companies on hired compete for you the engineer
and they make beds to win your talent these are companies like Facebook and Uber companies that we know are on The Cutting Edge of engineering because they've come on software engineering daily to talk about their text back I've used hired personally and I've experienced firsthand the ease of finding a well-paid enjoyable job this was way better than replying to LinkedIn messages from uninformed recruiters and was also certainly better than using a job search engine to find a great job and support software engineering daily go to hired.com se daily and get a $2,000 bonus upon finding a job check it out it would support the show now what's going on with the show
Tim Williamson is a data scientist did Monsanto Tim welcome to software engineering daily Medical Department of Washington University in St Louis what compelled you to make a career transition from Academia to Industry washing University was my first job out of grad school and at that time I was really gung-ho on this idea that I was going to go to the the academic research route all the way and
at the time I was working in a lab that built large-scale parallel processing software for molecular model and I got really heavily into software engineering a day of science at that point and I kind of started looking around and thinking about where I could work what I could do that would have a really a bigger immediate impact of the world I had to sort of I guess academic midlife crisis and I I can be aware of Monsanto which is the biggest player in our region and I got really interested in the idea that one of the great problems that's going to happen on in my lifetime is how to how does the planet figure out how to feed the sheer number of people that are going to be here over the next couple decades and I thought that is a problem that I can work in an owner pizza and I went for it and I made a pretty big shift for Macadamia to the corporate world
so why is data science important to Monsanto are they important to Monsanto both because we are a large scientific R&D company which means by definition We Gather a large amount of quantitative data more so than can be processed intelligently by hand more portly the scale the side of our R&D pipeline has just become so large and so fast-paced over the past 10 years as we try to produce better that are proximal shorter timeline that we have had to figure out ways where we can design algorithms destructors that allow a lot of the scientific decision-making to the automated down to where are key high-value scientists are really only looking at that small percentage for problem that really requires an expert
and Monsanto has been around for a long time I want to eventually get into the software process season and things that you've been working on but one thing that I find interesting Monsanto it has been around for more than a hundred years and for many years most of the engineering was about chemical and biological engineering and management software has increased in importance more recently how did the engineering organization shift to one that can take advantage of high volumes of data and software
well I think so I've been here 6 years and I would say that most people would Define Monsanto is being a heavy genomics company and Seed Company since about 1995 when we drove into genomics and quickly, quickly to become a leader at The Cutting Edge of that space I think we were on the exact same trend is a company that the rest of the body medical Jones Community has been on the cost of generating high-value genomic data DNA sequence has gone drop precipitously over the years so much so that the cost of gathering the data isn't the rate-limiting step anymore it's more of a storage and an inference problem and we as a company way above my pay grade we had to make strategic decisions that if we are going to keep up and in a bit. Space we had two significant Lee change our head count and how we organize
very interesting so how does the biotech side of Monsanto and the and the chemical engineering side interact with the software engineering side well so are we are signs are new company not to express in IT company which means we have a large i t and suffrage in your organization that build platform by which those pipelines offered over to where I sit so for example my job and a job might be a team is mostly to build back-end data science and engineering products that local data science teams in scattered across very tiny cruise to tap into to accelerate their decision-making so myself my team and many others build back and systems that end-user data scientist can tap into we build our own intro platform that are local days
Mike's teams tap into to pull data out of the X Cube decision-making algorithms to run machine learning so on and so forth
 did the data scientist that you build products or do they tend to have a background in biology or chemistry or or a science or do they work if they don't do they were closely with people that do know if I mean I guess I would like to think that we are special in our needs however I think that are the skills that are data scientist have is probably not any different than any other company bar size which means it's broad its data Sciences I don't really funny hard to pin down term and it manifests itself here so we have a lot of data scientists who have heavy domain exporting back their primary training isn't that of the domain so graduate training in genomics biology chemistry however we do have a subset of data scientist that come in from the strip statistics are applied math background and what generally happens here is we have formed
 higher level academic Community around a Sciences to have significantly more skill and Engineering an algorithm design from the patient there are those of us that are domain experts on and those of us that are the main exports North programmers but hardcore statisticians and almost every important project that I've ever worked on has involved the combination of individuals from all those back
 cross training is definitely something that is difficult in lead we try to spend time on but I don't think we've we've yet to assemble a team where everyone on the team is that mythical unicorn data scientist that does everything
 okay so it sounds like you have the t-shaped people as we've discussed in software engineering daily on other episodes, space but I work in heavily will often have a couple genomics researchers that are are sure that the Cutting Edge the literature in the field that are working on trying to adapt how we how we can apply for ticular hour in the observation to a large dataset but the team will come together pretty early on that process to try to work at the early prototyping stage and make sure that scales to RR backbone pretty quickly we found that's the only way we can keep up
 so I want to ease into a conversation of how you built one of these tools that you exposed to the data science teams working throughout Monsanto and you gave a talk at the recent craft connect conference in San Francisco called graphs are feeding the world and you discuss the the evolution the construction of this tool that has become widely used by teens at Monsanto what were you trying to convey in that talk oh wow so many things hopefully some of them well I was trying to convey the fact that one data science particularly in the in the in the Life Sciences in the hard Sciences space requires really deeply thinking about how you shape a techniques in the date of the Prophet you're solving
 in addition I was also trying to communicate the fact that there are a lot of really high what should be high-profile problems that a lot of people very smart educated excited people don't, they get exposed to so in that talk I was trying to tell a story about how we build this fairly specialized data processing pipeline that very much matches the space of scientific data were trying to process with telling in the context of hey I think that this problem of how we are going to see the world is important ones one where people working in software engineering can have an outsized impact I want to tell the story and hopefully get a couple more people interested
 you said it that talk that we've gotten very good at making targeted modifications to the genetics that we want and we're going to make the next step change in food production in the near future due to a completely data science driven genomics pipeline how is this different from how we made improvements to food production in the past so I think it's an evolution of scale and quantity of quantitative data that could be mine to lead a better quality in Fresno so when you look at the core way in which new Crossing about what other at Monsanto any one of our competitors or any number of of academic research institutions you're essentially relying on another pipeline that has built up over the past several hundred years of plant breeding so scientists working a field will decide that they want to breed a plant that resists some disease and it was
 time they resisted Izzy's they also have to perform really well they have to be to produce to have to yield well that's easy to harvest they're going to achieve that by identifying plants males and females that can be crossed together potentially pass on those trades and then Examining The Offspring and see which ones are the best ones the workflow that's been not been out of persisted since the days of Granny Gregor Mendel the difference is now in the world that we live in we are increasingly trying to develop agriculture products that are targeted very specific environments so we don't just want the shelf for example corn that grows well across all of Iowa we want to be able to sell seed that performs Piggly well in a particular field which is some combination soil moisture weather app used to do that requires making a significantly would require making a significantly larger number crosses inputs which are pipeline technical we can always scores on Facebook
 so much and therefore our position and what me and my team now there's work on is well how can we rank that possible space more efficiently to only make the crosses and only pick the plant in the highest probability of the outcome not want to get an idea of how this tool the set of tools as a p i was constructed we need to get into some of the domain specific ideas or domain specific data structures that you work with could you explain what a genomics pipeline it was for Monsanto at least in terms of Montana what is a genomics pipeline and what is a breeding cycle sure so the easiest way to level up that everyone no matter what your your background is to this prom is League of your own family tree
 show the inside of a lantern on West pipeline looks like a larger and Messier version of the same family tree that you might look up for yourself on ancestry.com that's essentially what are pipe structure so the start of a betta breeding cycle of something that occurs many many times over within that pipeline So within that that genealogy to to use them or to me you're going to have plants that's a plant that you can cross together and we call those plans parents so if I decide to use to plan to the Cross I'm going to call the parents to use some more common verbiage and I'm going to choose those plants because both of them possess some set of qualities or traits that I want to have in one progenate so one plant might be resistant to a disease once that might be susceptible to that disease but grow really well and I want one plant that grows really well and addresses into the Seas
 show you think about that when I cross those parents and I get many many progeny plants many many seeds out of it I can scream those plants using a variety of physical techniques a good example of genomic technique that will use all the time are various levels of DNA sequencing or DNA fingerprinting we're trying to make some observations of the structure of that plants that we can make a decision on whether or not it's the winter on the physical side we might actually go out in the field then make an observation this plant is in fact resistant
 and then it every round of selection were only picking the ones that we want and let him know is go forward and I have Offspring and we're dropping the ones that we don't two or more time over many many years not just yours but many many cycle so you think about it we could get about for planting Seasons per year depending on where we should proceed around the world that builds up a family tree but over top of it has information across the tree around at every node every point in the tree what traits will observe about it and what genetic day that would gather and that forms that that form sort of that but they stay destruction of a charger in French the cross
 are you needing to grow and monitor each of these generations of plants or can you simulate things well how we can do we can do both and we're increasingly trying to simulate more example and that's what I talked about in that that craft kanektok is
 where we now that we've kind of figured out how to treat our pipeline is that it is a dense geological graph and draw inferences Crossett where do we go next and this other pipelines simulation comes up so you know I mention that price of actually fingerprinting something genetically sequence has dropped a lot but it doesn't mean it's dropped a lot if you have to you know if you have to characterize to gnomically several million seeds that year or month that's still not enough and even if even if it did start to drop really close it doesn't mean it would be a worthwhile investment but it turns out that you don't have to necessarily sequence something to know everything you need to know about chocolate so again I'm walking back to your family tree structure plants just like humans if you cross two plants just like if you cross two to humans are two mammals the progeny are going to be
 what percent
 nail and pictures of female genital some high abstract level now rather than assessed every project at a really high level of detail using a lot of money and a lot of time it turns out that if you intelligently run quicker samples of the genome so maybe instead of secrets in the entire genome only seek was it at Target places very hard to figure out where those are you can actually use the structure of the genealogy so what are my parents what do I know about my parents what am I measured about my project to simulate high-resolution data that is good enough to make an informative selection on the project and that's something that we about it work quite a bit at
 okay got it so whether you are simulating or growing real plants as I understand Monsanto models the lineage of its plants or you can model it at least as a directed acyclic graph or maybe not necessarily a cyclic depending on how you look at it but certainly a graph and each vertex is a plant species and each Edge between those vertices is a transition across a generation is that accurate except I would I would okay go a little bit in a little more detail each vertex is not just a plant species it's an actual single individual so Ace
 okay oh wow okay very interesting so with that in mind I mean I guess this is kind of a softball but why are graph-databases useful for Monsanto if you know a little bit of graph databases we've already kind of figured out why it works really well in this particular case it's it's like I mentioned earlier it's an example of where we can actually select a storage technology that Maps back to the physical demands close as possible the reality is is that data said is by any rational description a directed graph and by choosing to do the engineering and the modeling work to store all the date of that way we obtain both and extreme competition efficiency in operating over it but more importantly we obtain the ability to be far more expressive butter data set so when you're doing genomics research any graduate-level genomics textbook will be full of graft descriptions of how traits are inherited because that's the way the science work
 and therefore at the club or more are back end Data Systems match that metal model it's significantly easier to do high-end development work
 yeah there's actually in that talk you mentioned flipping through a biology textbook and finding that paper from like 1921 I think about poultry breeding which is about it Illustrated the usefulness of graphs applied to genetics that has I don't know if he asks would call it a data structure but it's been a day to structure that geneticists think of and use for a long time and that in that example I mean personally I like I like old science textbooks I think it's really is a hobby I think it's really fun to go back several decades and take a look at a field that you know for a while and think about where it was and that case you're right there was a really that was a vulture bird Integra from 1921 they were trying to describe a mathematical way how I can describe a a child as a summation of all of its ancestors
 I had run out of really nice diagram describing what we now today would call Co ancestry is Ann Arbor the concept and it was drawn out of the graph long before anyone really understood really deeply in life sciences what graph models were now fast forward to the day we actually have people have built databases that we can use the model that data along the exact same as a model I think it's fun is this is a bit of a deviation but I rarely talk to somebody who spends time flipping through extremely old biology textbooks do you ever find like would you would you ever like to be flipping through an old biology textbook and you see like somebody trying to write a paper about like the scientific justification for leaching or like something some like really weird scientific process that now makes absolutely no sense and they're trying to justify it cuz that was it you know thing in it some an acronym stick scientific process
 personally never an R1 but I heard I've heard stories like that
 you're wondering I think was interesting is you know any textbook that sort of predates know there early early nineteen-hundreds at the time when we were wooden signs of the first studying DNA they assume DNA were for proteins we had no idea that you know is a narrative something different so it's amazing to see what's different even now I went I was an undergrad I started my undergraduate work right about when the public Human Genome Project they publish the draft you know and to think about how the entire field and all its ancillary support structures has changed since I was an undergrad and I like to think that I'm not old is really humbling
 Engineers are always looking to simplify 2 simplify testing and deployment Engineers turn to code ship could ship is continuous integration and delivery is a service with code ship your tester execute against your code automatically whenever you push to GitHub or bitbucket on software engineering daily we've done several shows about devops and continuous deployment is key to devops it's a great way to break down the wall of confusion between development and operations managing your own testing infrastructure is painful that's why you want a service like code ship to do it for you if you have a huge number test you can use code ships parallel CI to run all your tests in parallel coachable spin up containers on their own infrastructure to run your test in parallel if the code passes your test coachup will deploy it automatically to your users companies like product hunt are already using coship to speed up and simplify development to sign up for free and start shipping today
 go to code ship.com or to try out code ships new Docker platform go to coachup.com Docker so you don't want one of the ways that you characterize and we can talk about it like an abstract that yeah okay this is that there's a relationship between the physical structure of the data and how you want to use in the database but you Benchmark this in a way that was like pretty convincing and so when will you characterize y graph databases are so useful to Monsanto is you talked about this operation just a very basic prototypical operation given a starting population return all the ancestors of that population makes total sense for somebody like Monsanto is doing lots of genetic work could you explain this query and contrast how the performance of the relational database
 compared to that of graph database so
 I said the beginning of the talk monsanto's being a plant next company since about the mid-90s so you know since then we've accumulated years and years of
 generational advancement so adding more notes that tree generating more seeds and also over that time we we bought intellectual property we bought other companies are pipelines expanded all along that time we are gathering this genealogical data but it was being stored pretty much if you thought about how you would model what what is a dense graph in a relational database that's that's how we did it so we have a large number of but we're coming to call of join table so parent-child tables in a relational store store all this day to end and then if we wanted to analyze it we would execute some you know some essentially what I like to refer to as a really really nasty connect by prior query and sequel space so connect by prior being me The Operators that use in sequel to do next two joints and we would run these Quarries in a sort of a warehouse C Warehouse style fashion to assemble the geological
 please that would go into Data Mining operations and this is all well and good to a small in on a small Gator said no because I think I would probably be really obvious to most delicious as podcast The Joint operations scales really really ugly as you do more more joints and so what I showed in the graph connect talk as if you take a pretty standard lineage and you look at it in your bench markets assessing promise the same starting point can I build its family tree back to some levels of death in this case we used up to a depth of 15 which is actually pretty small for a platform Pipeline and we measure the performance unloading the data from a relational stores versus the graph shows the graph person that we have produced and was pretty shocking that I think we were observing at the end almost a 94 difference in performance and what I thought was interesting about that graph
 call Brittany Glee is that when you look at the scaling it pretty much behaved as you would expect from Big O notation so the join bomb hit the join bomb you start this really nonlinear scaling as a number and the craft store that one of the fundamental fundamental properties of a graph database are evolving that's a really rapidly evolving field is that you should be able to achieve what's called index free Jason see which means I should not have to take a jointed to go out to my neighbors and you actually see that in our Benchmark that the scalenes flat know what's fastening about that from a distant standpoint is that for us opens up a really different space that we can work it because now I don't have to do Justice League choose to only analyze a small set of populations because I only have so much CPU time if I want to say analyze that the geological structure
 our entire North American tour pipeline that's possible now
 so once you realize that you can get these types of performance gains out of graph databases what were the types of higher-level abstractions that you were able to build on top of that graph query interface sure so
 to start off with you know me and my team fundamentally believe that if you're going to build a really cool data science project for data scientist the answer isn't built a really awesome database store for out there an expected were delivered yet another strange query language I just never felt right to me so we weeks I went there we're going to we're going to shoot lair on top of it where are the objects are defined in terms of things that people working in genomics and Plastering are used to dealing with what not only are they say they know what they are which means they know how to work with them when they're pulling them into their own their own analysis code classic example is what I alluded to earlier we were talking about measuring genomic data versus trying to simulate you on the data so
 air plant pretty pipeline just like in a million a million breeding pipeline the act of a male and a female crossing the yield project ideas is called its A2 across a binary crossed but it's also has a special status of being over combination event that means that two distinct lines two distinct genomes have merged together and therefore there's been a sampling so that finding that feature in a large data-set reliably as the underpinning of all of the work that you might do if you're trying to stimulate genotyping example is expressing that in Sequel is extremely cumbersome on performance and doesn't look at all like something or a geneticist would recognize which is being able to hit arrest resource and say I have is population give me it's most recent find Heracross at something that are standard domain domain Sciences can work with without
 really neat Without Really in frustration and then beyond that you go from there all types of common crossy Pirates could be represented in the same way
 so I like to talk a little bit more about this idea of that you should really consider the type of API the exposing to whoever your your your your data science customer is we did a show with a company called y hat where they're essentially building a tire company around solving this problem where you know that they're building a product that allows software Engineers to easily exposing API to their data science is so they seen this problem time and again
 I mean how should from your perspective what are the the broader lessons you learned here in terms of how software Engineers should be interacting with the data scientist that they are building products for I listen to that episode and I enjoyed it quite a bit those guys are really fun to listen to
 yeah they are
 at the risk of using a cliche that is a very interesting question and it's one that I thought about a lot and my colleagues have thought about a lot because I think that this space of data science vs data engineering vs. analysis is really no one really lace bandeau it's not nailed down
 my my intuition for what it's worth and when will we try to operate on is that the relationship must not be combative in any way and in fact must be is frictionless as possible so I think when I even when I started there was 6 years later no one's really to find exactly what data science is but in the beginning I think there was an atmosphere relationship between alright we have the domain specialist we have stat stations they know a lot of really interesting things but they're terrible at doing development and nothing leave they rightfully Works therefore we shouldn't really spend too much time working with them versus you're very traditional software engineering team which can build an Implement something very efficiently but of course the timesheet for them is figuring out what the correct thing to build an appointment is and that's part of the really swing way to software engineering I think for us all the meaningful problems have broken open
 and the friction between those teams have gone away entirely so for example if you think about again simulating genomes right the reality is that you know as good as those of us who have become more dedicated to the scientist and engineer paid interest might be we're not going to be is up to date on The Witcher is one or two scientists that has spent their entire academic first doing that now work here so we rely on them to Wade through the signal and the noise of the science but then work very very closely with us to ensure that we are interested towards can actually work at what we call pipeline scale and in fact for Honda saying that the coolest algorithm that someone could produce at Monsanto is really worthless if you can't process an entire crop pipeline at once you're not going to get any type of inference that you need to actually make a business impact in decision and that attitude Drive what we do
 now so again if are primary consumers are going to be people doing Flying are getting signs products to genomics problems than the surfaces by which they interact with which just might be arrested in this case have to match has to have little-to-no impedance mismatch with the way they think about the data and by doing so they're happier using the product I can use it more efficiently we're happy you're building the product we can use it more efficiently and so on and so forth
 so the service that you end up ended up building is called ancestry as a service at least it's an internal service describe this service to okay so ancestors of service is a first of all nothing cool unless you call it as a service so that that's where that came from it is a a surface which is it what is a rest API where scientist data scientist software Engineers development teams can make arrest calls into it against objects that match their domain so for example ancestors descendants find Heracross and so on so forth and they get back pay loads would you represent the result of executing some number of algorithms get your craft store near the provide the answer to that question so a great example would be that product served both software engineering teams
 data scientist going back to the example the labs that we used to generate genomics data highly automated and therefore there that means that means that we need to have machine automatable ways of quality control and data and the way that we do that in genotype space is that if we know that you know types of a set of parents and we're running several million progeny from those parents through the lad the machines that are choosing that day too will actually call out to ancestors of service to fetch all that rental in order to make a determination whether or not the day that I've seen coming off machines even makes by Logic sense
 show every every meaningful genomic element in our pipeline we have either expressed or try to are trying to express as a basic rest resource
 give me some idea of how this API has improved the workflow for the data scientist who consumer show on the the date of science I think there been two major areas of improvement
 based on the level of experience the signs of has show for experience data scientist and I just experienced that a scientist but experience at the company because every large company has very different ways of managing Third Day. Therefore there's a certain amount of impedance mismatch company for those that were used to working with our old datastore there's just been an efficiency game in the size of the problem that they can handle and the amount of data munging that they have to do to get their data sets so obviously you're doing work like this I think is more fun is when you say we can only make a brand new hire some awesome data scientist from
 some marketing company comes to take a job at a science company for the first time well if they are able to interact with a complex data set in terms of very basic biological Concepts at their colleagues to teach them if they can now the rate at which they can become productive and leverage the skills they bring in against their biological they said becomes significantly easier to climb the activation energy is hot is a lot lower
 so those are lutely those are two of those are really sore too kind of basing examples on the on the more complex side now that we can actually ask your questions of our data sets in a meaningful out of time we're currently undergoing the space where we're actually reopening some ideas that have been shell for the past couple years that just weren't being tenable by Watchman because of how the state of our data and ask yourselves which ones of those two may actually do now
 okay can you give me an example sure so going back to genomic stimulation ideally what you want to get to is the right now we have a pipeline where we might have a bunch of parents make a bunch of crosses do a bunch of selections trial a bunch of acid products in different environments and I try to make a recommendation based on where you're going to grow the seed what is the best one to buy that's a very standard pipe line for agriculture no matter what we want to do is flipped on its head to think about it not necessarily look at what process what process do I have the ability to make in the pipeline ask myself if I want to develop a product that is most optimal to grow in Central Valley in California
 what what parents can I cross in what way to have the highest probability of success of achieving the end result that I want so that requires doing so then you're so essential to try to do is become a prescriptive about what crosses that you're making and that is an area that we hope to make a lot of progress and it's extremely data-heavy
 it should work intellectually intellectually can work with the right data set and the right machine learning but that's that's a great example we love to get to a point where we could look at a plot of land you know make some quantitative measurements of State about land and then actually not just recommend an existing product that would work that would go back into R&D and say okay we believe that this is going to be a major stressor I like to reference water loss in California a lot if we think that drought tolerance is going to be really really important in the soil types we should be able to buy us our R&D pipeline towards producing products that will have that result
 okay so that's super promising interesting example so I want to talk about this system a Monsanto engineer build a system that uses Spark that enables estimating the genotype of any seed that goes to your genotype pipeline could could you explain how this works in more detail girl actually I'm hoping in another on another couple months or so that wax buildup of wax should be able to get him to put together a public talk on this cuz I think it's a really interesting using the technology but I sent you earlier when we talked about genotype estimation you really have a couple inputs that you need one is if you need to know I am a population what is the package illogical space what is the grass structure to the last time that I had some quantity of genotype data
 in my lineage that the tree structure tree structure with annotations that indicate where I have that genotype data and then I need that genotype date off which is another day to sit at the company it turns out that if you combine the status us together and you walk down each Crossing that treat you can make a problem with the estimate of what were the most likely combinations of the chromosomes of each parent
 to essentially estimate high-resolution your type data of your project so away to think about that is we know what a high-level that if I crossed a male and female of my projects 2% Neolithic percent female at a really high level but we know that it's not all standing across the Chino there's certain fractions of your genome 10 to segregate together well when we take a little ride when she did a set we try to map a process informative way such that we can estimate the gas estimate the rest that we didn't measure the way that was a chief type of me is that there are a variety of
 published algorithms for doing that operation it's commonly called genotype estimation refute ation in the literature we have an engineer data scientist who developed out what we believe to be a better version of that about Albert algorithmic technology and then scale it to the size of the several million project going to the lab we chose to implement it by performing all the genomic the probabilistic analysis in spark over graph data structures that we spit out from our genealogical platform
 okay that's that's awesome that sounds super interesting I'm looking forward to hopefully that talk if you can convince him to give a talk on that so I want to I want to talk a little bit about how you were able to
 get this project off the ground this ancestry as a service kind of movement within the company
 cuz it sounded like it took some significant like cultural shift was the graph database project was this part of like a Skunk Works initiative or anything or how exactly did you did you get such a large-scale shift off the ground so
 silhouette
 you're not sure of a high-level retrospect wear a large scientific research company but that's a lot different from being a large scientific IT company or Facebook which means that the number of people that are comfortable with essentially skunkworks tell development work is significantly smaller which makes doing really really big super in Innovative projects difficult sometimes we address that problem in an under-the-table sort of way so the prior to me and my my teammates working together we all worked in different parts of the company where are common thread was we are banging our heads against actually working with these new logical data set today
 and I'll we happened at to get together over some shirt pain and we decided that you know there has got to be a better way to do this every time we work with this data we end up sucking it in and building in memory crafts surely someone has figured out a way to actually persistence on this so I don't have to keep rebuilding them and I know hardly seems
 I think about it that way but we decided that you know there were a number of graph databases that we could use and that started everything off and then we once we we realize that there was a chance do this we are we took a day at work
 and I dodged a free day that we are granted our version of 20% time and build a really promising prototype that sells wonder if their problem and in one day very very quickly and then at that we were hooked and we were having a lot of fun so we spent for the next 3 months most of our nights and weekends working out so we're doing skunkworks development work for a company but on our own time I put enough and by the end of that we were able to make a product that the tournament early version of a product that works for R&R Pipeline and we showed it off road show style to essentially our version of internal investor so the leadership team that are capable of making funny decisions just like you would if you were an external startup and I got funded and that's where we are now
 I think that's that what I mean that's that that particular story really isn't that exciting for most people unless you do have the experience of working in a large company whose primary focus isn't so and that's how we dealt with it
 what are the key lessons there is that if you have an idea for something in a company a big company like this you have to build a prototype off a x to really convince external stakeholders that this is not vaporware I completely agree in fact that room that we like to use internally RN we don't want to be boxing arrows people so boxing era person is someone that draws a really great white board diagram but will never actually cheated the product that they're doing and people that are in position to the company where they can allocate money are very aware of those people I think you're right for any meetings Lee complicated software data science project you have to be able to prove that it is vaporware that you know what you're doing before you can reasonably expect someone to invest in you and I think the real world I mean obviously not work that's the way the real world works
 that's true absolutely execution is everything your ideas really don't mean anything so I want to zoom out time is drawing to a close and higher level things so there's been a boom recently in agricultural software technology like if you look at y combinator companies are just companies in the valley in general
 are there any companies or products that are really exciting to you these days like what what do you think is illustrating the future of this ag ag Tech I think is the category people talk about agritech for both first off I'm really excited I think this is a really fascinating space to work in as many variables that played and there are many different problems that can be worked all the way from a level of a very large local company to do a small startup it's it's right for Innovation things that I think are the most exciting I think there's two two general areas of work that I think are most exciting I don't really have enough knowledge of the startup scene to know the players needs one but I know that there are many companies out there a different sizes going after it one would be on the far end of the pipe light so delivery of a product to a farmer
 the space of water called decision advisors so I am a farmer I have so many acres in in such and such a place on Earth how can I use how can I use a data science different product to effectively give me the path through all the decisions I will make during the growing season such as I can maximize my return both in terms of not just what the plans how much to water and how much fertilizer use and so on so forth but when to harvest and want to sell so people forget that up profiting on a farm is not just about growing as much as possible but almost no grower can actually store all the property Harvest which way does a very short window for Wendy Harvest that he has to go to market and when he goes to Mark and he's going to get whatever come out of these different prices available on that day it was a really a lot of fashioning work on the economic side of how can I actually inform a farmer knowing the window that they have to match my spray
 so those decision advisors I think are fascinating there isn't work the other one is what I Look to earlier is how do you make increasingly more targeted genomic decision in order to yield products which will do best in increasingly complicated environment so how did how do you
 how do you mine all the day that you're gathering on the farm across particular set of microenvironments Regular Show up conditions particular weather conditions to better make decisions in a free pipeline to yield see that will better perform in that environment that's it that's an area that's right for innovation
 speaking more on the ladder side of the two types of categories you mentioned we did a Show recently about Soylent and it's kind of interesting they have this moonshot Vision that sort of like you just you have like a bioreactor that grows everything you need and then it just I guess pipes it types whatever food is growing to your food faucet and see how about the future is I give a water faucet and then like a food faucet as somebody who thinks a lot about biological engineering as well as how to execute on that stuff at scale is just like is it something that is inevitable in our future where we have this as an option or is it how it how realistic is it
 I think realistic scientifically is different from realistic socially quietly about the field and and I think
 you know for the majority of people in the world for food it is more than just the sum total of the sign that you took credit even though it's highly scientifically proven people like to eat they like the experience of eating they like what happens around the socially when they eat so I definitely think that Italian scientifically that vision is achievable completely I'm not sure how far off we are but I definitely believe that you can engineer someone's nutrition very completely I'm very and I'm almost positive that especially as we become a society that is humanity
 most farther and farther hopefully in new space that would like to see those advances becoming do I ever think that that type of nutrition will unseed people's cultural expectations of what it is to eat and what it is to be hungry and be full-time not sure
 is it desirable or realistic to move towards a meat-free nutrition model and tip can we get the the types of benefits that we get from proteinaceous meat consumption from you know reconstituted Corner stuffers this I have no idea although I will I will say that. Not that I know of I have to go to the papers for publication for that I do think though if you want to think about another more out there intersection of add Tak and the Soylent model I do think we're probably going to see some interesting advances over the next decade in the synthetic meat area so lab-grown meat I do think that'll be a thing
 certainly okay so final question I want to ask you a question is not closely related to software but we often hear the term GMO which means genetically modified organism and people have kind of been trained to react negatively to this term but we've been doing genetic engineering for centuries as you mentioned the days of Gregor Mendel ever since Farmers learned that they could select which types of corn were yielding better characteristics there's some misunderstanding around this term but my question is like do you think there is any risks associated with GMOs or do you think there is potential risk that is aggravating or compounding as we selectively evolve the the organisms that were modified with more aggression it's a very deep question
 very simply no I don't I believe that the signs that we used to make these modifications and test them it is sound and testable and and rigorous I think that the vast majority of what we do which is why breathing so fast and it is essentially a more automated way of doing what we've done for hundreds of years it's just that now instead of just really happy to observe every plant the check we want we have the ability to screen a genetically on and so on so forth I actually think that as the as the world tools that are available for making Jack modifications and assessing genomic content of for the mature in the areas of extremely precise modifications Allah Christopher I don't know if you forgot about that but that's for the news sure I might think that the case and precision and quality and efficacy of research will actually get better than this now will continue to get better
 as we as we continue to become more aware of how to make the selection that we want fish Italy and in the more precise manner
 awesome okay well that seems like a great place to close off Tim thanks for coming out of software engineering daily this has been a super fascinating conversation I'm glad we got to discuss the intersection of biology and data science in software engineering been a really great experience and I'm a real fan of the work that you've done
