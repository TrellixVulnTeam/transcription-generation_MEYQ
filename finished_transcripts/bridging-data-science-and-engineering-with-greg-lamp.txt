Transcription: Grand Rapids dcto of Y hat a data science technology and operations company Greg welcome to software engineering daily software company what is the typical relationship between a data scientists and software Engineers we are typically working with we find that data scientist are on one team where it's much more as you might imagine looking at data answering business problems or questions management company might have using that data and then a separate team you have the software engineering group where that's where your application development is done but that's a website or a mobile app or back-end ETL work that kind of stuff
what are the points of an application that both the data scientists and the engineers are touching one of the reasons why I started why I had a couple years ago is that
 we're both engineers and data scientist are working on the same piece of their application is usually something like a real-time prediction or recommendation so an example might be on amazon.com they have the well if you liked or looked at these this pair of blue jeans you might also like this pair of tennis shoes and so that's an example of a component of a web application that has a data science component to it as well and so you have to have both engineering and data science teams working together in order for that to be a successful teacher between the data scientist in the software Engineers like are the data scientist communicating the spec that they need from the software Engineers or vice versa
 yeah so the way that I found the typically goes is that data science team will come up with a new algorithm or new recommendation engine something that they want to try out on a company's website and once that analytical work is done usually what happens is it assigned to just kind of throws that work over the wall to the engineering team and she sort of says hey here's this whatever-it-is random force model that's predicting what pair of pants this user might like in you put this on the website and that's just kind of the end of it
 yeah we did a week of shows about devops and one of the recurring themes was there there was this idea of a wall of confusion between Dev and Ops and the devops movement is about eliminating that barrier of confusion do you feel that there's a similar barrier of confusion between data science and engineering teams
 yeah absolutely
 what I've noticed in one of the one of the core problems that you saw it why I had is that you have teams of data scientist who they're writing code they're doing analytical work you stings like or Scientific Python pandas Matlab tools like that stinks like Ruby on Rails or no Jazz store you pick your favorite web technology and even though you have is two groups that are both very technical. Capable they're both writing code but it's really hard to take that analytical code and get it to work with swords your production code or your the code is actually used to build your company's applications it's a huge disconnect between us
 ways that the data scientist in software Engineers translate code between these two types of platforms
 yes sir this is this is actually one of my first jobs was I was the guy who had to figure out how to do this and the most common ways that
 tell me one person who pasties
 call Amado written in our and then we'll go line-by-line through that data scientist work and translate by hand
 that code into the production stack for a given company so I might just job I was taking our code and going line by line and translating all that into Java and it's really tedious super error-prone and you know what I found is that I spent a lot of time just going through and finding tiny bugs or just validating that what I had was the same as what the
 yes I actually had that same job at a ad tech company where I had to translate some data science stuff from python to Java and it was just a nightmare I I saw a YouTube video where you were talking about how you had to translate like I guess it was 120 page PDF of code from one language to another familiar to me that was rough
 but yeah I mean it it's
 chase at times its data science can be fairly academic to the point where you're really just taking a paper or a aspect for something and going through in and trying to make it useful in the real world and it's it's very time-consuming it can be applying to some of these problems that the data science and engineering teams have one trying to work together what does y hat do
 sure so why I had help companies take their data science work or analysis and embedded into other applications that companies using so one of our customers is a bank in Europe and for each one of their branches are their online presence is in different countries they have different credit models that they need to run on those individual websites and so they use why I had to take for instance the credit model that runs in United Kingdom and they take that are code
 send it to Whitehead and then I can use the output of that and embedded into their site so that when you have people coming to that site they're making predictions in real-time using their latest models
 so would you say that why I had sort of turns data scientist into like restful endpoints to put it into a into a service-oriented architecture take something that a data scientist has been prototyping and working on and immediately deploy it and turn it into an API instantly consumable by anyone else at the company
 interesting so how to deter delve deeper into that how does y hat reduce code translation the biggest thing that we do is that we actually run the exact code that data scientists are developing in a production environment and so what that mean we're running the same scientific libraries were running the same helper functions the same data artifacts that they have on their laptop we have a
 process that automatically train translate that into a production grade web app that exposes an API which software engineers at that una scientist company can use to
 access the models in the data Sciences work
 what does the engineer need to know about data scientist writes some query and exposes it as an API endpoint what does the the engineering side need to know about the black box that is doing that that work that you're running that query and updating the result of that in point
 go to all the engineer needs to know is the data that is fed into the model of the dated at that model needs in order to execute so that could be something like a user ID for a given customer that could be
 data points that have been collected
 at different stages of e-commerce check outside or that could be caused with third-party data source like a credit bureau in the case of the financial services company
 okay what what's going on behind the scenes like what technologies did you use to construct this system of creating restful and points did you ever stract RG build on top of you know any any sort of like nodejs libraries or or rails libraries anything
 yeah so the biggest technology to sort of selected early on Docker as technology that we could leverage as a way to
 isolate and run these models as api's and what doctor allows us to do is provide a safe environment or one of these api's to ask you where it's independent of
 other models that might be running at the same time so instead of just having one API endpoint per server we can have no 10 or 20 or he's had as many as 60 of 60 data scientist models running all from within the same Hardware configuration on some shows that talk about Docker but just for listeners who aren't familiar with it could you talk about why Docker is so important in I guess what doctor does
 sure so the doctor is really I think it's a pretty simple concept Docker takes the idea of a VMware virtual machine and allows you to split
 GM into sort of little separate mini p.m. so you can think of it as like taking a server and splitting it up into a number of little mini servers that are running and each little mini server has their own operating system has their own isolated environment and allows you to do some pretty nasty things like control the data input and output from each one of these containers isolate different packages that you want to run or different files that need to exist in one container but not the other and so it really makes us
 it makes running
 individual api's
 on a single server a lot easier
 so let's get back to talking about why has Technologies what if your product is science cluster what is science cluster
 science clusters of a workbench for data scientists to leverage cloud computing resources like Amazon for instance without having to go through some of the it headaches of spinning up at AWI server installing the packages they want managing different threads of execution that they have going on at the same time and listen to it easily without getting the assistant administrator is Our IT department at all
 is science cluster an operating system
 no I don't want to call her an operating system it's a web application that kind of controls the
 trolls different jobs scripts IDs things that are running on a server that are specific to doing data science
 how does a user deploy science cluster so dead files for Ubuntu we have RPMs for redhead in sensuous so installing it is really just a single command size cluster and
 so does I guess most likely does he use your deploy science cluster to his own machine or is it hosted on the cloud or is there are there no requirements you can do whatever you want the requirements so there's actually one of the things that we found it really started why that is that are our customer base was very sensitive about their data so unique imagine privacy not being able to have not been able to send their data to cloud or a hosted service and show all our software is designed to run
 dinner on premise or in our customers Amazon account or other PPC
 so this is kind of a on a side but I've heard these kinds of concerns about security when using a managed cloud service but haven't we gotten like as a engineering Society haven't we gotten beyond the point where we like collectively acknowledge that it's more secure to have your stuff in a cloud hosted environment than like your own environment yeah I would say I know I personally definitely have
 but for us it's more of them are our customers and sure our customers
 I run the gamut in in size and industry but a lot of them are larger publicly traded companies and who really just haven't bought into the AWS
 Cloud posted Services quite yet realize how much of a bubble we live in sometimes my thought on his like Amazon knows a lot more about security than I do so I tend to let them as much as possible yeah so do you need a devops person to set this up or is this something like an engineer can just sit down to I know I need science Quest I can go to the like figure this out very easily at a time we're working directly with the data scientist or an installation 50% of time will work with companies it department and then this again kind of goes back to the whole security
 Cloud hosted vs. on-premise thing but like I said it's about one or two commands and then
 get you up and running and it usually under 30 minutes so it's pretty simple
 and how customizable is it
 so this is something that kinda goes back to Docker one of the reasons why I was selected as as one of the Technologies we wanted to use is Docker lets you
 mix and match what libraries are dependencies are installed from within the runtime environment and so what this means for our customers is that we can
 we can include a very specific libraries we can include proprietary python or are packages in our software distribution makes it really easy for them to work the way that they want to work there not confined to a specific set of libraries it's really anything
 I want to install can be included in our product distribution
 did you talk more about the science cluster product itself it's been popular with data science professors who are teaching classes why is science cluster useful for teaching a class of data science students
 yeah what time
 I guess the science cluster just provides a ways that you can have one Professor who might have I think it's the biggest class that we work with is about 180 students
 so you can have one sort of main hog or all of the students data science work to get done and the professor can easily administrate and provide course material kind of like you said earlier install specific libraries or packages that were or class
 and it also prevents students from having to set up their own data science environment which we found that can be really time-consuming and difficult for
 someone to do on their own and then added the fact that he's got a student who's probably new to Scientific Computing to begin with and that just sort of magnifies the pain for sure so why has it has another application called science Ops what is science Ops
 data scientist analytical routines and allows them to instantly deploy them as restful API by software Engineers or other developers at their company with just a couple lines of code
 it's a science let's a data scientist take analytical scripts that have been written in python or are and turn them into API like she was the flagship product so I know which one is a bit earlier but to reiterate what is going on under the hood to enable those endpoints
 church so each one of our customers models runs within its own isolated environment and that is fireman using daughter and that environment setup using our software in such a way that it's going to include all of the dependencies any sort of libraries that are required on a something in scientific Computing tends to be somewhat difficult is experimenting with the new package they were included in a model getting under production release date someone challenging so setting it up in a dedicated environment mimicking there any environment that they use to create that model and then API firing or creating an API endpoint so that that model can be accessed by
 what's the user experience of the onboarding experience like for a data scientist who is familiar with python or are but not necessarily with the Y had workflow sign Sox is designed to mimic a data scientist existing were closed so we have client libraries build-out for Python and arm and in order to deploy code that you've written to science Ops you just import the Wyatt Library
 Define one or two functions for explaining how your code will run and then it's just one line why I had to play and that takes care of the rest in terms of pie in environment and exposing it to the recipe for company
 the science Ops allows a data science team to set up predictive models against API endpoints and those models can be accessed by employees or customers are however the the company wants to configure it can you give an example use case example is one of our first customers Bank in Europe and in use sign shops to take their credit models and run them on their public-facing website and inside of their mobile apps Blog has a bunch of interesting posts about data science and one of the recent post was about how the blog itself is becoming really large and hard to navigate and you decide to implement a search algorithm for the blog and you realize that you could use science Ops for this how did you use science apps to build a Blog search
 I was thinking about how we did like you said better organize our blog and I had a really short python script that allowed you to take to serve arbitrary search through the content of our faults and so I took that Python scripts and I deployed it onto instance of science apps that we run internally and from there I just rigged it up for block with a little bit of JavaScript and
 created a little infant box where you can type in a search query and that would hit the sign tops if you buy that I deployed and then retrieve results for the search engine
 are there any really weird cases use cases for science off that you've seen your users Implement that you would have never thought of yes so originally found that most of our customers were in financial services sort of a where my background was and it has a lot of very natural used cases for science Ops in terms of credit lending fraud that's her thing but we found after we started the company around 4
 are your two is that there's a lot of interesting use cases whether it's no eCommerce doing things like recommendation engines we had text analytics companies
 natural language processing sort of everything the weirdest thing I think that we've seen one is using science apps for taking input data from form so looking at the speed at which their users are typing or whether they're using the Tab Key to fill out different forms and using that data to predict future behavior and predict and segments those customers that was a pretty weird one that I never thought could be something to use for fascinating
 data science is the focus of this week on software engineering daily but the next theme that we're going to cover is y combinator companies and Y hat is a y combinator company so for those who don't know why commentator is a startup accelerator that invests in the early stages of tech companies and we wanted to do a week covering it and full disclosure we want to inform the listeners that software engineering daily is actually applying to Y combinator ourselves with that being said what did you first have when you apply to y combinator
 so we actually applied to times the first time we applied was about it must have been about 3 years ago and we had a really
 poorly working prototype and just kind of hopes and dreams and remember we went out to California to interview and the interest you didn't go very well and as a result we were not accepted but it did at least get us kind of working on the idea and got myself and my co-founder Austin Ogilvie to quit our day jobs and dedicate ourselves full time to Wyatt
 fascinating As I understood when you actually got accepted to buy Conair you had a pretty significantly working product so when you actually got accepted how robust was your product
 so we were accepted to the winter 15 class and at that point we had a function products we had a few customers the product been on market for about a year which makes enterprise software world makes a really big difference and actually already raised so we had employees the company was already kind of off and going and why commenter was a great chance for us to go out to the West Coast and meet with some investors in California and then going to the program obviously was quite an experience as well to join Y combinator when you already had a developed company a developed product this was something that we really wanted to do and we had
 we had a few of our own Angel Investors had participated in y combinator and were very encouraging and in very in terms of having us go out there for the YC engineering challenges challenges not really on the engineering side at least in terms of the technical details are extremely helpful on the fundraising and insertive navigating
 denture and Angel Investing in terms of chronic there a great found that they were great motivator in terms of know every week you go in the partners and you need to have some sort of improvement whether it's improving your for us our blog and conversion van all that we had going on or in the best case number of clothes deals intuitive advice that you received a y combinator
 second one counterintuitive advice was that
 y combinator Joey emphasizes sales and
 engaging and trying to reach as many of your customers as possible so for example we were blanketing fintech companies with emails trying to find those companies that were at that right moment that they were they needed one of our products and you sort of your own Hacker News or read all these blogs you think that why, nor has always liked magical product in an engineering recommendations and the biggest thing that I got from them was just pushing sales and how important important sales into your company interesting tribal Knowledge from y combinator some of the tactics have become publicly available over the years through hacker music through Paul Graham's essays and so with that in mind I mean what was it that you got out of the experience that you would not have been able to get just by reading
 my favorite part was just meeting the other Founders in the other companies that were going through y combinator with us our guys was pretty big we had never over a hundred company in the winter 15 batch and just being able to meet so many people who were so dedicated and so passionate about such specific problems or specific domains I found to be made for some very interesting conversations and was a lot of fun adopted the why I had product
 unfortunately I don't think any of them could really afford us we're much more geared towards working with larger companies you know the order of 60 year 150 employees as opposed to the two and three person operations in y combinator what is the cost for white hat enterprise software licensing
 license or software on a per server basis and be honest the pricing depends a lot upon the customer so that users number of servers that they're going to need that sort of thing but it's all done on an annual agreement and we provide support and updates and obviously if they have teacher request sir recommendations were also more than happy to include that as well
 what is the moon shot goal for y hat
 so would be if we were served the data science company for Enterprise overcoming for how did a science gets done so if you think about the past 5 years they've been sort of days as you call him and data Tableau that conquered the the bi market and then you had Cloudera who conquered the Big Data how do we process all the data that were ingesting before we have to ingest more data and I think the next days is the prescriptive where the Predictive Analytics Market in so that's what we're going after that's the okay we have all this data with made all these nice pretty charts how do we actually take that data and use it
 to forecast what's going to happen as opposed to either processing the data we already have or reporting on historical data yeah I like the quote from Peter teal where he says big data is off and dumb data fastest-growing undergraduate major how does a data Science Education differ from a computer science education a data scientist in would be focus a little bit more on the math side so it's more statistics index linear algebra courses
 and then something that certain engineering programs do is like a studies or Capstone projects where is on the student to formulate a you're not just solving a problem but also figuring out what the right problem to solve is in the first place and so that might involve some data collection that might involve cleaning and scrubbing some data and then finally synthesizing all of that into a solution or an answer that can be presented to some sort of Beholder is the role of data scientist becoming more distinct and different than a software engineer or are data scientists and Engineers becoming more similar or how do you see that great in changing
 there's been kind of a rise in the idea of a data engineer we have historical data science but kind of fell under software engineering I think that's kind of helped set some dividing lines in terms of Who's Who
 but I see data scientist is more of the people who are answering business questions analyzing data and then presenting results I see him more as the shirt of the creators or the implementers of
 whether it's a website or app for whatever the company is is building learning data science from scratch how would you go about it the way that I did it myself which is just take a problem and try and solve it so for me my first job I was trying to classify web pages and it was a way for me to get out of a lot of my kind of day today work and so it became a side project that I was working on eventually led me to pandas and let me know scikit-learn and some of these other great
 libraries for for data science and analytics and one thing led to another and I just I guess I just kind of got the the bug do you have any preference for a new day yes I should start with python or are encouraged people to have looked in there. So if you happen to work at a company that has a lot of our users are would probably be a good choice for you just because your support network is going to be a lot better put in terms of weather are python her better I think they're they both have their merits they both have their weaknesses pretty similar anyways so you might as well just go with the one that gets you the best what do you think about the Julia language
 ready for Primetime yet I think it's still going to be another year or two before
 it's a it's like actually feasible for
 regular user of hobbyist users to to be using it at work what are the deficits
 from what I found I mean it's it's still just evolving it's still you there's a lot of there's a lot of tooling that still needs to be built out around it and their Community is just not as big as the r or python Community yet is it easier to teach a data science to an engineer or engineering to a data scientist I don't know if there's a answer one way or the other I think it just depends upon the individual and whether or not
 are interested in some of the more analytical and statistical concepts of of data science I want to go through a simple data science problem there's a talk that you gave about how to build a beer recommender system using Y hat and I'd like to talk through an abbreviated version of the stock see cuz I'll put in the show notes the the presentation that you gave but it's a really good solid example for it for somebody who has no idea what data science is or like a we know what kind of problems you can solve with data science
 this problem to start with we we have a collection of several beers and we have a user ratings for those beers so each user gives a simple one to five star rating of a beer and we want to be able to measure how similar each beer is to other beers so then if a user likes one beer then we can recommend similar beers and as you said at the beginning of the show they played applications to this is Amazon so what are the steps to take to build this recommendation system work with
 and so the the blog post of the talk that you're referencing uses a an open source data set from the website beeradvocate.com and they've been around for a pretty long time in Savannah collection of about a million reviews that that we can work with the next step is to take that data set and come up with a way to condense it down so that it's a little bit easier to manage and a little bit easier to understand so and this example we decided to do was look at how individual users were rating certain beers and then compare those users to other users who raided the same beer so for example if I like really like Sierra Nevada I also like maybe Coors Light we can look
 add other users who also like Coors Light and use that as a way to say what they might also like Sierra Nevada so we use what's called a a distance Matrix to quantify that relationship and then using that distance Matrix you can just like you said take certain list of different beers and compute optimal recommendations based off of that based off of the distance of the relationships between each one of those beers yes I think the Crux of this is like you can turn each beer or each object in a recommendation system into a matrix of numbers and then you can plot those numbers in Cartesian space and then you can use cosine similarity or some other similarity
 formula to gauge how similar one vector space is to another why is cosine similarity so useful to be honest I'm probably not the person to answer that I'm much better engineer than I have a data scientist I have notified for like 4 years and still don't know why you use it over other things I think that's actually part of the data science has gotten so much more accessible is that I don't have to know the nuts and bolts of cosine similarity to use it because he's third-party libraries open source libraries have gotten so good so I can use Manhattan distance cosine similarity euclidean distance without having to think twice about how to implement them or
 trying to guess you know in theory which one would be best I can just try them all out see which one seems to work best and just take it from there cool so I let you be the clothes off with some kind of Rapid Fire questions what are the what is the biggest engineering problem that why had is facing right now
 putting a lot of work to making it extremely easy for us to build build software that can run on premise and so it's extremely challenging to build software that kind of runs not on your own servers just because we don't have control over it we're not there to babysit it and that's something that we put a lot of work into over the past six to nine months how do you do hiring at whitehat LinkedIn
 but the most important part of our hiring at least on the technical side is will bring in a candidate for a kind of a half day when will work on them on whatever project can be something that they're even playing around with an open source project that they're trying to learn more about and just build something that's the best way to get a sense of one someone's technical ability but also and what I think is really important what it would be like to work with that person especially for us you know we're only about 10 people and it's really important that we can work well with
 everyone else on the team in that everyone gets along and and is able to work together effectively that's a strikingly different
 interviewing strategy than the typical boilerplate whiteboard interview on both sides and I just never found in to be that great of a way to assess how well I'm going to work with someone yeah I kind of it it's kind of tragic Legacy icon of software engineering
 interesting Greg lamp thanks for coming out to software engineering daily it's been really fantastic talking to you
