Transcription: software engineering daily is sponsored by hired.com if you're looking for a job hired.com is the place to start I've used it personally and it is an excellent service software engineers and designers can get 5 interviews in a week with top companies go to hired.com software engineering daily for a $4,000 bonus upon accepting a job thank you hired.com
 Apache Flink is an open-source platform for distributed stream and batch data processing Stefani you and is a committed to apache-flink stuff on welcome to software engineering daily ease into our conversation about flanked by first talking about streaming and batch in the context of a modern Hadoop ecosystem how do you define streaming and batch is a pretty
 it's a pretty widely defined thing actually there's this this many aspects to it in
 a lot of people when they hear streaming what they think about is in a real-time low-latency kind of applications but it's actually it's actually a lot more so data streaming is in some sense
 a paradigm that that this data processing in a way that it Embraces the fact that
 did all data is actually created usually in streams right I mean this is not really use case where all of a sudden it comes 2 terabyte of data on your right it's created overtime as events and and streaming just is a paradigm where you say Okay mostly processing the data sequence of events are not trying to groom it into into sort of Davy Jones and then run a vegetable root for them actually I'm recognizing the Spectrum and dealing with the dealing with A continuous and nature explicitly in my data processing programs and some sense
 is not more than what what many people will think of in where the first thing about streaming right it does definitely comprise the the low latency application save the event notifications but it's it's also it's also a lot more interesting this streaming is it the way we see the actually a superset of batch processing your documentation says that basically says batch processing applications run efficiently as special cases Upstream processing applications so what is processing applications run efficiently a stream Especial cases of stream processing applications
 you can think of that's a batch processing over a set of files and something like S3 or a two-part system you can think of it as a stream of data that is not actually Unbound it but that is found it it's fine I'd write and spell interesting ly a lot of parts of the application do evening battery explode this thing about it if you run something I cannot produce drop the fine as a stream its parts of the of the pipeline are going to be record at a time and then and then and some parts usually materialize into Penn State exchanges streaming notion as as long as possible at its dreams data between for example mattress and reduces if you have them apple juice case or between joints and full groups in another program standards it really makes you realize it's only when the semantics of an operation require that for example if you do a full aggregation or a sword
 something where you need to consume the entire input before producing anything this has a blocking nature and everything else is is stream through this is the motor systems are doing this for a long time and Paula are doing this under the hood so they're their there even though they are executing use cases that are associated with this fine I found it stream
 show we will get into more of the intricate details of flank but zoom out and give me a definition for for what blankets give me a high-level description
 yeah it's it's pretty much what was Ulysses said before SS the description on the website that let me try and make it a little more Chris it's a streaming data flow engine
 it's a powerful streaming data Pro engine that you can tune bows for cheap for throughput and for low latency with with programming abstractions for batch processing processing plant in stream processing with very powerful primitive swipe for dealing with unbounded Natur-Tyme time of processing time of events and so on
 and is Flink a replacement for any components of the Hadoop stack
 I wouldn't say it's necessarily a replacement for specific components there are a lot of things that people are doing with other friend works that you can definitely also do with length but one thing that it opens up I don't think any other system in the in the open-source handles all these days and they will definitely to simplify a lot of a lot of infrastructure setups where where people are putting together things like I do and flu and then spark and so on and please disconnect sleepy we need to express the streaming jobs
 show what are these new use cases that flick is able to address these days they're open 10 release it's being voted on
 as we speak actually being tested and voted on by the by the Flint community and the and the PMC and watch these ads is very very interesting Primitives to the data streaming site that I think is more flexible and powerful than that anything you find than any other open-source streaming that allows you to do very complex forms of of aggregations and Aaron detection sensor on based on time on elements on data characteristics in in intervals of time and at the same time it has something that's
 something called Advanced time support for something called event Time Event time is it
 is a paradigm that is it is getting a little more well known as of late thanks to Google having published quite a few papers on on their efforts on streaming technology and it is a very prominent part of that it's also a very prominent part of Lincoln's of the of the new release process system not with respect to the time that it arrives in the streaming system but with respect to the time that it occurs in the real world and you try to 2 / and Bounds on the on the leg
 call whole tater tots from the from the devices that produce events to how long it takes before it reaches your processing Engine with what is the maximum like if I do I'll let you try to implement dealogic to to handle this to be able to to deal with approximate explicit approximate results and is it to make this make the snacks of time and Zone explicit in the application that makes makes the meaning of time very explicit in the application rather than Barry and implicit in the way that a lot of pythons have it right now in at midnight and say to the other batch if you happen to have any dates, that are in the second best there's a lot of custom logic to compensate in hindsight for that and all of these things because I'm just very naturally expressed in the NBA
 event time sounds like that's basically as explicit as you can get when you're dealing with time which is pretty pretty interesting but you also mentioned that blank allows for simplification of certain distributed architectures what what is the simplification that you get when you add Flink to your Ado barkitecture what are you what are you replacing or or augmenting
 yeah I think it is multiple things so first of all what you don't need multiple Frameworks to cover the spectrum of use cases from low latency let's aim or medium latency of seconds with with Morris more powerful handling of the streams 222 classical batch processing you can do actually all three of those things and fling low-latency reaction to individual events with millisecond latency is how many seconds chance you can do the distrain processing with windowing and aggregation with which event time with latencies and in the end of seconds and you can you can do that at the classical song brass where was it it off it's very well in the framework that is that is one thing so
 YouTube video John needs something like let's say another job or buses Park streaming job plus a assistant job to go from 2 to navigate to go from low latency over over other streaming tube at 2 to have you been shut so another thing that that is a pretty common observation is that what the pipelines the data pipeline speed block building are using veg technology but are actually streaming pipelines in Disguise so every time somebody by to drop that off the Interstate and Rose files on an on an hourly or a daily basis and then you have to schedule and the background that schedules are not to or a spark shop to process these pies are produced different files and then
 then what you really doing is actually I have a continuous pipeline streaming hotline you through window it by hour and and you're sort of using patches
 yeah snss streaming in disguise right here your scheduling. Pet Shops which really are streaming Windows right now and if you have a problem streaming friend that you don't have to do it again it's something that is implicit in this architecture It's a combination of the Pet Shop plus the scheduling from job or whatever and then the streaming grandma gets very explicit when during definition
 is Frank a generalization of Hadoop mapreduce
 yeah you coming
 but in many ways I mean yeah spark was also already a generalization of that if you think that this is a streaming framework and which really really streaming is a superset of best you can think of it it's a generalization
 sure sure sure Frank implement the Kappa architecture what is the cap architecture I'm not sure if there is the definition of of a Kappa architecture there until I'm actually goes back to respect to the people behind the Apache Kafka and it is sort of their response to the design pattern of the lamd architecture Wright architecture being the idea of combining best system in a streaming system together with a better system just too heavy lifting periodically and the streaming system basically covers for the the Delta since now and the last bet show
 DeKalb architecture this term I mean it's good you related to them that I can check the right that the term comes from from the from the idea that the lamb. I can't really walk around because of not very powerful stream processors once you have a powerful stream processor does not really need to come by in a batch system and I swimming system you can just do it completely in the streaming system everything
 that is the day that is the idfc I'll take up architecture and in some sense you can you can think of a Flink being a following that idea because yeah I mean went through what we're building it is a powerful streaming system that allows you to do these things so you don't have to have a bench and a streaming job so I'd like to talk some about how Flink integrates with other Hadoop components I get the sense that many listeners in fact myself is included in that don't totally have a holistic view of how the Hadoop architecture works but one thing I understand patchy Flink runs on top of hdfs and yarn which are two important components within the Hadoop ecosystem can you describe what hdfs and yarn do and and describe wife link relies on them
 Okay so
 sling actually does not necessarily rely on them completely independent of the entire a tube steak or the letter the technologies that are usually included in a tube distributions The Only Exception is if you want to run in a in a higher bioavailability modes you're either relying on yarn around zoo keeper but for 4 months of the other cases definitely for all of the non highly-available batch processing also if you can run completely independent from her job so you can just bring it up on let's say you know the Amazon Cloud on the Google cloud system download
 cuz if you all use cases with C4 Flink are in in conjunction with with other Hadoop to Wills so if you run bed shops in flank chances are very good at the input and the output data isn't right there are no mezzos or something like that running blinkers not yet integrated with with maces so I'm going to stick to the example of yarn and what they really Tuesday they basically bring up the other workers to Toronto chops we are not installing thinking it's on the machines so it's it's really integration with systems tuning rather than heavily or a critically relying on these components
 why do users choose to implement Flink on top of their pre-existing Hadoop rather than implementing it separately from there preaching to dupe system
 I think it's mainly a thing of where is your data right if your data is in hdfs and you have your own running on this class that's just the simplest thing to do on the streaming site actually be the most prominent technology that people use playing with a sexy Apache Kafka the message queue / log that's the basic The Collection pieces streams and you can use blank to to consume this James stats from The Mentalist time and also produce streams back to back up again today is the day time to discuss the streams are in Kafka the simplest thing is to run thing also there were two cop cars in that class.
 because the Raiders already there
 sure about it so let's talk about the distributed runtime of flank Howard jobs managed
 now what jobs managed what do you mean by that people mean different things are they ask that question do you mean like
 so I'm trying to do some sort of some sort of distributed like multi multi-stage machine learning process how do the different jobs within that process get run with it blink I guess and managed
 okay more specifically from the standpoint of like a distributed system the responsibilities of a master node in the worker notes and how these different distributor components are working together I got you okay so I'm so thankful as a pretty classical Master worker pattern Watch what it does is it if you have a job let's let's assume it's a streaming job that is continuous streaming job uvulitis as a job application and send music message to Joe cast of execution Etc to your class the right it will bring up a master note so that the client program will connect to yawn bring up the master application ma said it's all surrounding that think my stuff done and we'll give it to the data flow description of that program description we call it to the job graph executed
 what operators are executed in what parallelism with watch configuration parameters how the individual operators exchange data stream stats on the note that basically keeps the overview of which operators are running where where the stages are they healthy if they fail if they failed it takes care of redeploying damage it coronets checkpoints and so on and then there's in addition to that Master number to set up worker notes that that that registered at the at the Monster Mash the monster that becomes aware of them they offer their resources and then the master can't deploy in the pic of operators release notes it's fairly it it's really straightforward multiple multiple Masters out of which one is always the the elected leader coordinator and NFL / case the responsibility falls on Virtual to another Mass turn up
 how does Flink maintain fault tolerance Data Systems I talked about about streaming for tolerance because that's really the more tricky tricky part so what do I do if link was what's up what's another word I never met a message to do photo to inspire distribu the checkpoint in so they're there is the following data does streaming program going on why aren't you have some Transformations here data stream to some operators that two windows that are some things that may interact with a database and so on
 you want to make sure that in all and all failover cases you you keep strong Symantec guarantees like they're not duplicates introduced to give this exactly once a month at the same point you don't want to be trekking too much intermediate metadata don't want you to too much for keeping because it just costs and will decrease throughput if you do so much what are we doing in Flames for basic did you finding these checkpoints which are which is a collection of of states that are consistent with each other right so it defines in my input stream I have been exactly at that position
 all the records that have been before that position in the input stream have been reflected let's say in this in the state of this window Aggregates in the end account records that start before that point have been reflected and committed to that database or so and link to this points in the in the Stream periodically I'll miss coordinate system by injecting Circle checkpoint areas in the Stream you can think of them as metadata message that flow with a stream lunch and coordinate exactly the alignment of what should be at the checkpoint in the box with the operators and it it stores the its source that the stage of the streaming apology as of the checkpoint in the background somewhere in some persistent storage if it is if your job is not maintaining a lot of State can just be part of Zookeeper that is mentioning a lot of stairs you probably want
 and so one city find periodically this consistent checkpoints in case of a failure with the system does it suppose you could just rewind all operators to the latest consistent point and balance them resume the work
 be the interval in which you do these checkpoints is how it's a totally application-specific if you have something that's where the failure case you want to make sure you don't rewind so fast you you're probably run run this check was very often if you have if you have a job that's that goes through a lot of data with super heavy computation where do you have to say very happy windows and the time that the records travel SodaStream is going to take a while anyways because it's goes through so many successes windows are so you may want to do this a little less often service interval of drawing District Kansas and practice anywhere between I would say 500 milliseconds and a few minutes or so
 MJR this really defines where the streaming program how much it how much it has to redo or to watch point for Speck in case of a recovery the nice thing about that approach is that
 by itself it it's very little over half the only the only cost that checkpoint really has is backing up the state of of operators internally that is
 I think the minimum amount of work so you can do for checkpoints in San that sends it's it's it's really getting to the minimum amount of work that you need to do and it gives you very strong semantic the guarantees and it allows you to actually extent is semantics if you if you implement certain interface is also to watts
 what state in the India and the arm
 we we say outside the system in the outside world to give you to give you these consistent amount expect that every element is reflected once in the states that the elements that are reflected in that state of the reflected in another state of the loss of taste and this guarantees also to be to the outside world outside of the streaming system by itself given that
 in the data sources and sinks Implement certain interfaces which which is very interesting because it's it can effectively mean that you're streaming system becomes something like a distributed consistency or checkpoint coordinator for moving State between multiple databases
 was this method for maintaining fault tolerance was this one of the the main breakthroughs that that's kind of separates blank from other streaming systems
 it's one of them definitely yes it's I mean if you think about it the same in the end it's not a super complicated thing it's it's something that's based on a very well-known algorithm that is a variation that's that we did have it or something's Taylor to the suitcase it's just something that but if you think about it speak because it gives you this nice property it's not it's not dealing with any with any unnecessary in Flight data and so on it's getting to this minimum minimum State backup work but you really need to do this is a very is a very good piece for Friday through porch streaming systems is one of the outstanding think since you think that would be
 yeah is that that Shandy Lamport algorithm is a snapshot or what would I watch that do they have an algorithm they call it or it's called Shandy Lamport
 I think it's called the Candelabra dog with them for distributed asynchronous snapshots of so I don't have to have to look up the exact I thought so I'll find it in putting the show notes so hard is Flink compared to Apache Spark
 yeah I think I think it's pretty simple in the end apache-spark is a batch processing system I think is a stream processing system so what what is partisan behind it's in the editor it's the best bass processor that that transforms and and reorganized and chocolate State assets approximate streaming on top of a batch process server running these so-called Michael purchase a lot of small batch programs exactly the other way around if you wish right blinker is a streaming processor at hearts and dispatch processing on top of streaming so if you wish the Sparks Steak in the flank steak are exactly opposite
 fascinating so in practice link works on pages of bikes and Spark works on collections of objects how does the change how does a change of a Primitives that are being worked on how does that change the type of operations that are being performed within Flink vs. Spark
 okay so so true things about that I don't know what the latest set of Spartacus I think the sparkly blocked and also changing their internal model of it so that that is a car. I'm not really an expert on Ponce Park especially not on later versions so the current version of lingo point to 10 it just stinks like it differently on The Bachelor on the on the streaming side so this working on collections of pages is fully implemented if you run best programs on top of on top of playing on the lottery on the operator code that is executed khopesh programs if you run if you run fancy windows on the streaming site is it still a work-in-progress to implement them all on this memory Pages rather than Java object over in a bit of a transitioning face on the on the streaming site so let me talk about how it is in the bedside because that is that is really how
 the court of the Muslims think that they would also go for in the streaming site in the next month's just working progress there
 sure okay so DDI deer the observation there's the following
 the jbm
 has never really been designed for super dead and tense of work
 the way that you do when you represent massive amounts of data is objects we have billions of elements to represent the misspellings of objects you first of all have quite a bit of an overhead in the representation of the data as each each object at overheads the way that that you that you lay our state basically with with references between objects is not ready cash efficient
 the next part is that if you have a lot of long lift objects that techniques the garbage collection techniques that job is built around do not work very efficiently any more trouble can handle creation of short lift objects and destruction of chocolate subjected message scale very well as soon as you start accumulating a lot of options and they tend to live longer this object drift into a something called the 10-year generation space of the jvm end and start feeling that one up and when garbage collection of that Park become necessary that is extremely costly system such that it only really had a lot of short lift up only really good chocolate objects and I never keeps these objects around very long. Rather than that moves the date of these objects into into
 by the race that are basically live forever and ever and ever need to be garbage collected
 so what what does effectively means is that that link does not accumulate the records for what's make a country that say you have a you have a simple mapreduce style program it just where in the reducer we're collecting elements because we have to sort them
 it's finger's not collecting these elements in lists and then sorting the list instead of its checking each element individually and and sterilizing it into into the car we call the manage memory you can really think of it as a as a collective by the race that lives either on the evil of the hip
 and sew them then the subject can be immediate-release that's really short left and once once the day has been accumulated in the spider is it really implements the heavy lifting algorithms to work on the sewer line State I rather than on the object so the sorters and the vegetables and flank they they all work on serialized data rather than an object standing by virtue of that you basically get out of the way of the garbage collector in addition you actually can't exactly control how much memory you occupied and you can also easily wants to start accepting that move parts of that memory to disk and slide remove the back into memory so very very robust out of Coral Ridge
 very fascinating we'd like to take a moment to thank our sponsor digitalocean offers simple Cloud infrastructure for developers in one click you can have a mean stack or rails application Ubuntu box or another custom environment software engineering daily is proud to have digitalocean as a sponsor because digitalocean is the simplest cloud service provider are the interviewed moisey oretsky who is a founder of digitalocean and he told me that digitalocean was based on the realization that other cloud service providers are so complicated if you want things to be simple when you deploy your application use digitalocean to try digitalocean go to digital ocean.com and Inter promo code SE daily that promo code is 1 word s e daily now let's get back to our show
 so you've mentioned that link and Spark should have look at the world in inverted ways Flink looks at batch processing is a special case of stream processing and Spark looks at I stream processing is a special case of batch processing so what are user ever want to include both link and Spark on the same stack
 yeah actually we see people that do that absolutely I'm in the way that both people actually work flip side right
 it's that means that they have different sweet spots right so the
 and I'm obviously bit biased but I would say streaming is it streaming blank is much stronger
 on the other hand there are aspects of batch that sparked as much better than blank, especially when it comes to this
 this this Paradigm of you know you you loaded at us at a memory and you cash it there and it just want to settle of injective crazy over that so sweet I use case for Austrian processing fee that either latency or be descended in the
 and then the cop architecture style that you want to do a sophisticated state. Or when doing that you have a Christmas tree with streaming for playing at the same time in another part of the infrastructure you have you scheduled this really no reason why
 how does Apache storm fit into this conversation
 how does a
 into that yes so
 in some sense the first streaming system in this Apache Big Data the potato stack it is
 I would dare to say a little old but now I mean even though it's not really not really other than 45 years but technology so storm boss technology that was solving a problem back then but I think we've since learned a few things on how to do things a lot differently get to get better performance and semantics and so on and then streaming so so I would say storm has been for
 flings definitely for some music isn't for some tricks how to determine inspiration but I would say that at this point in time functionality wise
 most of the time
 you can do it things with fling that you can do with with storm definitely while it's not quite the other way around especially when it comes to 2K let you use cases that at the end on on on and on hydrocodone stronger semantically guarantees like exactly 1 sensor 1
 got it yeah that's that's my sense I also so blank has support for what are called iterative algorithms what is an iterative algorithm
 is an algorithm that does the same thing over and over again until a certain Criterion is is reached I think of it as a tattoo until Loop in a in a program right you do something
 until a certain conditioner switch to PS4 that is is machine learning you do start with a random model some parameters some random initial values and you to apply a training step that updates Beast makes them move more towards a convergent State until they've actually reached so to update until convergent status for example of algorithm sweet we put this this Primitives in the flow of the program that is repeatedly executed
 until a certain activity convergence it has been reached
 right and there's also this notion of We're looping occurs and in flank you get the efficiency that you don't get an in Hadoop mapreduce apache-spark so in Hadoop mapreduce apache-spark looping occurs outside the system can you explain what that means that the difference between that looping outside the system and how apache-flink works
 yeah so saluting artist outside the system basically means that you write this part of the after of the part of the eye that should be repeatedly Appliance as a program
 and then you have that's a really a while loop around it or a for loop around that partage repeated it takes this gives it to the class and says execute that part and then once it's done you basically execute University start the same program again and just make sure that the input of his neck situation as yesterday that said that was the author of the previous situation that is how people have been doing this a certified wear them send in a to Forever For example of a lot of the items in Demon's Heart Library are implemented like that spark went and was was clever and in that sense that they said you noticed that we have to always read it from hdfs Rider Tracy versus is a high overhead why don't you just you know cash it in Memory Ride it's too bad it's to memory read it back from memory and Sons it's basically programs that it's it's still individual program that executes
 Teresa memory to a virtual memory rather than reading from the secret fastest computer system the difference in flank is that they that the entire program looks to the
 looks to the system release one step of a visitor to program with with a feedback channel right so you basically have each operator in the steps running only one time and then having having actually a cyclic data flow so the last latest point of the of the pipeline that you were tired of the executed actually fits its by its data in a streaming fashion back to the to the first operator and you can Europe you can basically run a cycle extreme of data in in the system
 that is that is a bit different in that sense that all the other systems explicitly restrict the computation to text to directed-acyclic-graphs and and flank has the special form of a feedback which makes the grass psychic psychic but there's there's some form of Cycles in the graph that are allowed to and that that that Express this is feedback
 got it so let's talk some about the Flink api's blank has three api's the data set API the data stream API and the table API describe the usages of these
 yeah so
 let's start with the datastream api-api really exposes the streaming of The Primitives you need to provide programs in data streaming Paradigm you creates you create streaming sources you apply functions you window them whenever you want to do applications you actually need to window them in there a streaming and if you see this this flexible clematis window in for maintaining State and so on so the data stream a pure is really for for the streaming use cases both low latency at the mall cop architecture stressed out streaming use cases the data set is really for for batch programs
 it's basically is an API that
 that says we're not trying to force you to write a batch program in a streaming fashion by you know going and and saying OK create create a stream I know it's the final stream so I don't really have to window and so on but it's just forgetting about that and spent in giving you all of The Primitives you it's it's it's throwing out all the stuff that you need to do if your unbounded screams and makes all the simplification so you can do for ya for find out data sets for probation programs and it also at some additional functionality in the translation of the program today to the distributed execution for example of the Flies optimization that tries to figure out how to reuse sort orders partition exams on land and in order to speed up execution because of this town datasets you can make a few more assumptions and on and on it strange that is something that is unique to potato salad
 what's a data set in the datastream API of really if you think about it if your eyes in Java and it's Carla where you work with objects in Java and Scott object so every time one function 1 transformation produces data allotment it it has to actually be described a scholar class so primitive type that describes an object programming language classes in conceptually objects in practice serialized forms of these objects patch conceptual incomes of objects of and causes of a programming language much more logical thing I think about it as as something similar to Microsoft Lync and
 an index in that sense there's
 it's not really yet you're not programming with egg with classes anymore but your programming basically with the logical with logical tacos with names and you're applying logical operations to that rather than rather than implementations of programming language functions it's it's your analogy I can give you a something like like Microsoft Lync or assumption maybe hibernate hql or so something that is
 conceptually close to sequel without being in about just a string that describes everything it's it's more affluent API in the programming
 yeah that makes it makes a lot of sense so flick also has some domain-specific libraries can you talk about blank ml
 yeah so
 plane crash test to measure Library so I can order the craft Library jelly and the Machine learning library to to basically that we have seen that people that people like an h and ledwith actually implemented in Frank and in such a way that they become composable and reusable
 and stay
 see the observation is that
 a very handy model in this field is is the model of of pipelines that you built that did you build a chain of the Transformers in preprocessor history of training data that step step for example normalize them scarce k l m n Dey Appliance learner or a trainer and the result of that is a model and then you actually take the same pipeline to apply for example if it's a classification model to use that model to classify the data stream of the target data stream off of elements that you want to classify so it's it's it's building infrastructure exactly that it is very much inspired by and by the way that scikit-learn Defiance machine learning pipelines tries to make things type save it
 it's a lot of Australia's very fancy top system and and implicit to type save training and classification algorithms
 play can pretty much work in progress right now a lot of this basic infrastructure is in place unfortunately not a lot of algorithms to pick from happening implemented right now and in the latest release the flying Community has put a lot of focus on advancing the the features in the streaming space so the last 3 months I've not seen tremendous progress on flingomatic would like to change this again in the future because it is a very promising piece that is just at this point in time I probably still working progress sure well I mean it's it's interesting cuz if you compare that to like the spark ecosystem minor saying is like the spark facilities for machine learning at work so appealing probably had some some sense compounding interest because people would see the machine learning libraries on spark and then they would go contribute to spark and the Machine learning libraries we get better and more people contribute
 so maybe that's in the future for flank the most open pull requests right now interesting what can you give me a better idea of what the open-source community of a flank looks like
 the open source community of length is actually right now at the pretty impressive right right now it's it's going to to the extent of Camaros and PMC members have to have to start coming up with better processes to handle the load we have right now I think 20 call Metro Self length they come from that they come from from various places an organization so the company where I worked at Artisans it was as if he found it out of the plane Community by a bunch of comatose coming together and bonding company so a lot of light cameras work at a tardis I think a little less than half of them at this point in time other computers come from from Academia and also from Sacramento Street from we have a very strong Focus still in a very strong Community sailing to Europe so I would say in the
 Geordie of the Commander's is in Europe but we've also computers in Korea and the US
 I went well so going there so much for the commenters the contributors have a thing cross 230 on Route 49 in the in the recent weeks so this really are an impressive amount of come to contributors right now and said they're contributing to to all parts of the system the tooling and also the Light internal low-level algorithms which is which is very impressive
 antique the contributors also stretch both Academia and an industry and and all regions of the world but how did this is something that I would say that's a development that is
 or less happened has happened during the last year so where I would say year ago the vast majority of contributors were from Europe this is definitely no longer the case as of now
 so I let's be in the clothes off I'm very curious where you see data engineering going what is the future of the Hadoop ecosystem Portishead tube get supplanted by something else or what do you see in the future of data engineering
 predicting the future song with sitar Thing 2
 so just a duplicate supplanted I mean how do I do business Tech right it's it's more than than one thing I would say that mapreduce by itself
 only going to be less and less but I still also includes my hdfs and hbase yarn Third Estate
 hi again I may have a bias few but I see that that streaming is becoming a big part in India had to vent restriction that
 that there is a trend right now that people that people realize that you know that I don't like I said in the beginning God created us purchase the the inherent nature of most used case is the data is created in a continuous fashioned at the time when there was created actually matters and that's that the program should actually deal with this continuous nature and realizing that the pipelines they have build a streaming programs in Disguise even though they fill them with touch technology so my bet is that there's going to be a big shift what streaming Technologies in the in the future that's more and more gigabytes in terabytes of data will be stored in an Apache Kafka that supposed to receive SMS
 black and red under the ratio of didn't have guys going to go go out in the in the next the next in the next year it's definitely and with that that's more and more turn off the data processing we move to remove to the streaming paradon from the batch of paragon fit in where it where two containers fit into the future of Hadoop
 how to contain acid
 Leland in incense containers
 infrastructure pieces yard on Main Source are not all that the idea behind them is not all that different from the idea of containers as far as I understand it stays right so bringing up
 bringing up containers to have after a polite way of of running multiple operations multiple application Services next to each other without them interfering it's not true two different from having operators in NJ VMAs being brought up by yarn and bases next to each other from different for the time canoes canoes for example I think it's future is now yeah I think I think it's already happening and
 this is again this is again something the more the more you use you move to something where resources are used in an elastic way so yarn is bring elasticity to Pet Shops to a large extent in streaming elasticity will be I think even more important than in bed shelves because if you have a streaming job honey 24seven that your data rate is not all the same for for all day all you would want to scale and scale out this this job in order to make it over to use as many resources as you need to do to keep up with the current data right but not keep so many Island resources at the data rate drops during the night or during summer vacation time for Christmas I don't know
 this technology is like being containers. Yarn and mesosphere play an important role you're working with several link committers on a company would you care to talk about that company at all
 so that the company where I work at Horizon City was founded by by basically a set of Lincoln Meadows who have been working on North Lincoln Academia it was still cold Stratosphere back then it was the agenda project that later became Apache Flink and it is it has been the basically the property that work on during my PhD thesis also another, that worked on the train in speech deep is opo stock as well and at some point in time we realize that and we had so much fun maintaining the system we put it off and sauce and we had so much fun mentioning the system I'm supporting people who are using it Gathering feedback and proving it and so on that they Whistle Stop doing research at the University but we're just at I just supporting people between open source and that there was a point in time when when when the sponsor people
 just left the university altogether and and founded the company to keep on supporting
 cool well Stefani wedding thank you so much for coming out to software engineering daily and talking about flank and Hadoop in the future of David engineering it's been really enjoyable talking to you thanks for her for having me Jeff and thanks for forgiving giving me the chance to yeah to speak and share my opinion on data streaming and flank
