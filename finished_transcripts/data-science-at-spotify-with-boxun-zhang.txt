Transcription: life is too short to work at a crappy company that's why I software engineering daily is proud to be sponsored by hired.com the job market place for software Engineers if you accept a job you hired they will give you a $2,000 bonus but is an extra bonus to our listeners you can get an additional $2,000 that's $4,000 total if you sign up by going to software engineering daily. Calm and using the link on the right side of the page to sign up hire.com will set you up with five great companies for interviews are companies like stripe Facebook Uber company's you would actually want to work for where you can go and learn The Cutting Edge of software engineering go to software engineering daily.com click on the banner on the right and try out hired.com
Spotify is a streaming music service that uses data science extensively to recommend music to customers generate playlist and build lots of other aspects of the product boxing Zhang is a data scientist add Spotify boxing welcome to software engineer Daily Show prior to your work as a data scientist at Spotify you did a PhD in parallel and distributed systems what is the overlap between distributed systems and data science depends Walker's so if your focus and know if your research workers is let's a measuring system than an ex or motoring system Behavioral or user behavior in large-scale just me the system
I would say it's quite similar to most of the data science work carried on in companies is it RN in the procedure is very light very much like you set up some measurements infrastructure you start collecting data than you have the data you clean the date are you looking at it are you changing some inside and in the end the inside either end up in a mechanic application or ended up in the computer company report I think in that sense to overlap his bed and all the cat is very small if you want to jump from your PhD in that or insulator science work but on the other hand is your focus is more on algorithm and purple design for this billing system for example you want to say I want to develop a superstar for tolerance algorithm for data storage for large scale digital Systems USA your focus is more on the more computer science
not much on the data science I'd fill in the Gap is there
 interesting so I feel like data science is somewhat of a newer term in the past there was certainly data analytics and stuff that people would do just you know using a database but you know it maybe the term data science started coming around as the term distributed systems also started being Wiley important to think there is this is there a song Some Kind of chronological overlap between wind data science started becoming prominent and when distributed system start being really important so this is a very interesting question sold the way I see it is so
 when I think just this two-part really started then the term Big Data get started so when people a certain point when people realize they have too much data to the store for single machines and then people start thinking about okay we should have her do it she has all kinds of storage system and I think that's also the time people realize using the traditional who was or techniques to analyze data becomes more and more challenging two more techniques were motor was or tools to analyze the data I think that's more like the way I say wipe data science came to the scene you know how to rotate so there's certainly a sort of overlap between the store
 what is spotify's approach to machine learning and data science so I think it is
 quite a bit in always not really like a small startup anymore so we have lots of teams working on very different products over the company and apparently different teams have different approaches that's from what I know Spotify many sports teams take a very applied approach when it comes to machine learning or data science which means we spend a lot of time researching the problems we have and then we applied existing techniques either from machine learning or data size to our problems then you know we get our results
 so no but on the other hand we also have in a teams building our recommender systems who will spend lots of time researching new models or new method that suits our needs so I would say it's more like a hybrid approach
 okay interesting I saw a SlideShare from Spotify that explored the evolution of Big Data at Spotify that's what it's called the evolution of Big Data at Spotify in the show notes would like to go through some of that history and hopefully as we go along we can tie and how this big data architecture feeds into the practice of data scientist Spotify from your point of view how has spotify's big data architecture evolve over time so this is this could be a long story but settled so when it was 2013 so we had about around 200 knows maybe slightly more than $200 an hour how to Cluster and notice if you look at the customer I think we have more than 1500 notes and it's still growing so just
 scale the cluster is totally different nowadays and doing this you know two years there lost things happened so that the first first we switched from system called archiver to Costco for more efficient and reliable lock delivery but to accept us and we away from Hadoop training using python to punch for more efficient data processing and also during this time we've built a lot of Tools around how to so you know for our internal values are so we can easily use the crossover so if we can pull one so we build is a
 sort of no data retention platform previously with all this to you can easily delete one terabyte of data in Albay 101 the best command line but no witness protection to we can actually no save the data in the sort of no trash can for each user so if you miss taking it easy today. You can actually get it back so we have to be happy with loss of those Motors that makes the whole experience getting better and better over time
 great yeah we can we can go through some of those those points individually but as a data scientist do you need to understand this big data architecture well or do you just need to understand how you consume the outputs of this architecture depends on your bedroom door for me I my background is cured in computer science so for me it's quite straightforward to understand the underlying technologies that but I can imagine for data scientist who come from different backgrounds for example physics or chemistry you know there might be a got to understand it the underlying technology and also for many cases I literally say is necessary to understand the underlying technology because in the end they do scientists really focus on the data so
 so you know to put it in the more extreme contact Henry say once I have the data I don't really care aware of the Day. Come from to be honest as long as I can make sure the date is correct as reliable as long as I understand what's going on it's fine
 we did a Show recently about data engineering there's like this kind of new term called the data engineer that you know in some and some company is the data engineer will be you know what kind of do this stuff like data cleaning and setting up these data pipelines and really try to relieve the operational burden from the data scientist of the data science can really think more about statistics and how to build machine learning models of gas in but do you do you see this as the dizziness is this separation of roles exist at Spotify or do are there a scientist like yourself do you also do a fair amount of data engineering
 is there any existing Spotify because when the company or when your data grows to serkan scale and then nothing this two aspects of an ellipse 8 data science work you know becomes very much for separable and it requires very different skill-set sew-in food Spotify I would say data Space Engineers have a much stronger and services on the computer science skills in the skills for building reliable veterans assistance and also and of course they should also have a certain no more I can pay them out at some point people should be more sensitive to arrows in Dayton Oregon police should have a status update of Quality Inn you know about all outliers know somewhere numbers going when they build a pipeline they should have a sense of that but you know what that's not really their main focus their focus is really on the infrastructure to do to make the infrastructure more reliable
 accessible to data scientist and on the other hand data scientist are really focus on the more statistical skills machine learning skills and motor skills so we do have this separation
 what kinds of data is Spotify using what kind of data do you have to accumulate in in like at what volume so as if we're supposed to file weekly text Data from our client so we can understand you know how users use the product so we can improve the product in the future so if you look at our Hadoop ecosystem basically no storage so we have more than 40 petabyte of data so everyday we have about 30 terabyte of data ingested from Kafka and are on pipelines also generate another 400 terabyte of data within our customer if you look at you know look outside right now count all the service we have jalapeno and also the audio files we have you know for our service we probably have more than 200 petabyte of data and is growing pretty fast as well
 okay and I've heard that data scientists often spend up to 80% of their time cleaning data when is you said certainly had a mature organization like Spotify you know maybe you've broken up the the role of data cleaning in two separate type of employee but also you could just have tools and processes in place or just the collecting the data in a well-formed fashion that reduces the amount of time spent cleaning day. I'm just curious about the data collection process and how that has become just from an organizational standpoint how how do you organize the data how do you how do you reduce the amount of time that you would otherwise spend cleaning that data
 so I think the way we do it is to set up dedicated teams responsible for the process of death ingestion and did the cleaning or building the core data sets that are used by other Aveda scientist or other teams so by aggregating the responsibility of mineral cleaning the data
 when is the amount of time you don't need it from other teams or other data scientist to clean later is reduced its matically but in reality that no no no not at all the case because the knowledge each team has about you know how they should clean the data is open limited and also as we discover more and more in size from we will learn more details about you know about how should be cleaned it out we will identify more cases so I will say is what's 5 never say there are few teams in the responsible for cleaning the data for the whole company building recorded his head and when they the scientist who are the teams that are using those days that we will do another round of date of cleaning but those cleaning or more for specific use cases
 as you said there was a. Of time where Spotify had an architecture called log archiver that interface with Hadoop can you tell me more about log archiver solar system used to deliver our login data from our servers like we call it access point to accept as a storage so that's a long time ago and it was built around are staying and ICP and we've cuando stops regularly to transfer data from our servers to our Datacenter
 so it's it was a very simple to an overall
 and why why did it fail on a regular basis so I mean as you can tell I'm in if we have screwed you know using rsync and sap and it was a Quant so it always is not such a big surprise to see you know if failed every now and then because you basically have very little control very little money for ring going on there and
 I mean that's not the only reason why we replace it later with the cops got another reason is the performance for delivering the Lord is was really poor so the time needed for the data to be transferred from the server to hdfs was around a few hours that's was a very long time especially compared to the form as we gain by using Kafka So speaking of kaka kaka now is used by Spotify to accomplish what log archiver used to accomplish what were the benefits of starting to use Kafka
 so I would say there are there are few big benefits so the first one is a performance either I mean from both the super point of view and also from the time we need to transfer the data SoulSilver put Wise Guys in Grace and we can transfer loss of data in the referral time without any problem and also the amount of time needed to transfer the data to our storage 281st is reduced from hours in the time we used when we use Bonar timer 2 seconds so I would say it's that's a significant improvement over the performance another benefits is scalability so we don't have to crawl on the Top Gun dogs like what we did for love archiver and is designed to skate to the two large systems so I would say those are the two major benefit sweet me gain by using Costco
 are there any unique use cases for how you are using Kafka at Spotify that the listeners might find interesting so I would say what is Spotify doesn't really use the vanilla version of Kafka we actually build lots of custom parts or components around for our case so that sound we start using cup gods or .270 I think that's what's the time cut cut doesn't support like your replication or more definitely will have the reliability guarantee so we actually build custom components for a reliable and sand delivery by enabling replication of the the messages
 and also reviewed our own components for encrypting cushion and compression for all data so together right now, and all will customize customize components you know we actually in oysters hour
 okay got it
 Spotify also created a tool called Luigi what is Luigi data pipeline or any pipeline in general so similar to other people with automation tools like make and end
 so what's the scenario we are targeting is so let's say you want to build a machine learning model and to build a model you have to fetch data from multiple data sources no free sample you can get data from a postgres database and then you want to use the some data from across the room and then you want to come by in this today the sources together and see the data into the machine learning pipeline result into another post and that is processed we can basically Luigi helps out to help us to chain all those papers together in a very easy way so we don't have to do it manually and it handles all the dependency is really well
 when you chose to build Luigi were there any open-source alternatives already existing that you could have considered I'm not quite sure
 probably there are some but my guess is and Luigi probably but I mean long time ago and I guess even though there were some alternative all they're probably none of them or very few of them seats 245 use case because I was using cleaning drastically and also we have our own unique yusuke's so I believe the reason why we build Luigi is we couldn't find any alternative that fit into our own use case
 so what are the problems that the big the big problems you encountered with Hadoop in in the past and in the present and what what are the persistent themes in the problems that you encounter at Spotify so in the past I think up time was a big problem that's was more like before 2014 so small class that we had was not so great so that basically make the circular class or not that use believe you see okay to cost various is down very often
 and now the cluster is very stable in runs very smoothly so now you know the problem we have a problem because we have a fast-growing needs for data and inside so there are so many pipelines running so we always run into this contention problem you know we are competing with in Spotify for the customer to run our own data pipeline
 got it so let's zoom out a bit and talk about the end user experience the end-user benefits from the Big Data tools that you haven't placed from an end-user point of view how did the experience improve due to the improvements in big data architecture from tools like Kafka and Luigi like I know that's the sort of an indirect you know long-term Improvement that would result but what did improve over time
 so I would say by having more than two weeks in our big data ecosystem I think the biggest Improvement is the they say the feedback loop all the time we need to build a core data set that supports user-facing features and also since the time we need to build a stated that is reduced drastically over time we have more time to actually do more quality control but they decide to make sure everything is correct so overall I think that's already a big game for the company because I know we lost to the same place we actually is pretty easy and visible to support laws of user-facing features using all data
 now that we've talked about spotify's architecture in an abstract sense in the in the Big Data architectural sense let's talk about the type of work that such an architecture supports like the type of data science that you're doing what what do you work on it Spotify what is the type of data science work that you're doing day-to-day so
 in the past I've done all kinds of work you know under the data science term quiet know quite a bit but nowadays I spend most of the most of my time doing long time for that and recently I spend most of my time studying user sessions and its properties basically how user use our app in in general tell me about your workflow like what would be a problem they would solve and how would you approach and what technologies would you use so I would say I'd only have a very fixed workflow but one thing is pretty sure I'm pretty sure is I always thought with a problem and I always start to define a problem so I'll try to have the problem I start
 click me some data info from Hadoop hdfs work on database and then I will look at it in a little bit and I'll do some exploratory statistic analysis and also that I spend Saturday amount of time reading papers and basically I try to get to know what happened done by other companies or by other universities in in the past and then they come up with my own solution and after that if that works well I talked to engineering engineering team so to see if we want to build a proper system around it so regarding the standard tools so together to prepare the data are used and abused
 I want to do them all those I use piping in our I find IPython notebook or you Peter notebook nowadays is particularly useful for sharing as reviewing father's work is recently I started using xgboost a very popular to machine learning a library montagel users that's a library for beauty Boutique twist or gradient boosting models and the four minutes is really superb and I would really recommend you know you was in the audience to check it out
 could you talk about that tool in more detail like how does it give it give an example for how you might use that tool you don't have it doesn't have to be a Spotify related example I know maybe if you were studying oil data or something is a library or seem more like a general purpose for gradient boosting models what is gradient boosting model is more like a tree on Sample and all similar to random for it but the difference is no one likes random Forest you know the Mortal will peeled loss of decision trees at the same time but gradient boosting models will build one tree at each time and each tree is build a pound of data that was not mean that the previous model didn't perform well
 so it's more like a process of self-correcting
 so I'll throw a proper tuning in loss of practical use case is it find I find out a boosting models outperform random forest in many cases so that's why I started using pussy trees model and the sexy boost Library actually offers loss of interfaces to all other major languages used by scientists like bison or a Julia so it's extremely easy to use
 said there are probably some listeners who are confused by some of these machine learning term could you define what a random Forest is sure so run them for the name suggests is basically a bunch of decision trees so and the way random Forest spilled is each decision tree in the forest is trained by a random sample of training data and randomly selected pictures so in this way random Forest performances really well when there are lots of noise in the data so the motor is really robust because because of his to fold randomly randomly ization
 when you say random features what how are those features approach there like maybe you can Define the term feature in the in the scope of random Forest so so so the feature is a know is it's like feature in all of the machine learning you know models basically just got like a numerical representation off your data space ep 1 value for one column in your training sample and they run immunization here in running Forrest basic is about proof example if you're cleaning set has 10 different features 10 different columns and random Forest will take a random subset of distend Collins to train a decision for it so that's a no one decision tree can be trained by the first five columns and the other dispensary can be trained by another random Note 4 or 6
 columns in your cleaning set
 and in a given tree is is the goal of the is the goal to to minimize or maximize this column or like does the does the user-defined that or how does that work so so the goal of each tree is the same as the goal for the random forest for example the goal of the machine learning task would be I want to predict is a user will stream a song
 and each tree will have the same goal but using different training set to train okay I understand so so when you're looking across these different trees you're looking for like consistent patterns in how the different data sets that the different trees have have correlated so so imagine if you have that's a 1,000 trees trying to predict if a cat is a cat that's a
 so when I have all the trees train it becomes a voting problem so if example you can have 800 out of 1,000 free say okay that is indeed a cat and the other two and replace make myself a note. Object is not a cat so in the end you will do a majority vote you will take you know you will basic include okay that because 800-1000 please say so you know the Moto will be much much more reliable and accurate compared to one single decision for you because one single decision tree is very vulnerable to noise in the data
 show this process of looking across the different trees and doing a majority vote is that's ensembling okay is there a way to do ensembling where you're not looking for a binary outcome like if your liquid if you have a gradient of potential outcomes can you still do ensembling that way yes yes that's totally possible because random-forest can be used for both classification and regression problem and the same for boosting liquid in boosting models as well okay cool
 over Thanksgiving I had a great idea for a web app so instead of spending time with my family I locked myself in a room and I started building this application using Express JS because I love full stack JavaScript so I was testing my application locally and I was making great progress so I decided to deploy it and share it with some of my friends and get some feedback I used digitalocean I sign up for an account using promo code SE daily and in 15 minutes I had my app deploy to a server and running it was that simple this was really the first time I had use digitalocean so if you're like me and you like building stuff and you have ideas for projects give digitalocean I shot it is the fastest and simplest way to the point application that I've ever used if you want to give it a try go to digital ocean.com and use the promo code SE daily to get 10.
 region free credits check it out
 so I'd like to Define some other data science terms some statistical terms while we were on the topic what is K means clustering well K means clustering is probably in OT are the most popular clustering algorithm used all day so it's extremely simple as soon as you have
 you know 100 observations and you say I run a painting clustering algorithm to cluster of those 100 observations into five clusters so the album it will basically a sign those observations into those five clusters with the goal of minimizing the
 within cluster distance of each observation to the mirror in the cluster so
 it might not be so clear from my description but if you happen if you think about it you know which cluster will have a stand for it so the central point of the cluster and buy a defining different observation in two different customers you will be able to calculate the distance between each of the relation to the center of the cluster and
 did go down there with him is to find out the way or the centroid that can minimize the distance to some of the business of all the observations within its closer to the centroid so basically if the album is successfully run you will have clusters that have ablations very close to each other
 another term is that we often hear when we're talking about machine learning and data science is gradient descent or statistical gradient descent what is this and why is it so important to machine learning in data science is a app that can find the local minimum of a function so I know basically the way works is so
 when you have a function you know with a fuel prime interest you sometimes you want to say I want to find the local minimum and the gradient descent actually
 Tuesday spy going to the negative direction of the derivative of the function basically is the gradient of the function so it's more like you'll be surprised is an old it to the National Place in space with the two primary and I know so the value of the function is more like a no-account or parties more like you're walking down to the final of the mountain know by applying gradient descent and why is important machine learning as because if you look at linear regression probably one of the most important machine learning algorithms all there so the goal of linear regression is about
 minimizing the sum of squared residues between the predictions and the training training data and that can be achieved by a to find gradient descent because the sum of squared residuals for the object function of linear regression can be expressed as a note of the Soul by applying within this and we can actually find out those parameters very easily
 got it
 so we did a show with a company called y hat which builds tools that allow data scientist to collaborate more easily with software engineers and you know it is interesting cuz you do you were talking about your work and use it sounds like you start off your work on a problem surf siloed you focus on this problem you read the literature associated with it you build some prototypes and then you think about you know what is this a scalable solution should I give this is myself already had it had it off the software Engineers I'm curious about how the collaborative process between data scientists and Engineers works at Spotify specifically like once you move Beyond this this prototyping phase how do you go to the phase of let's let's integrate this with with the the engine
 guaranteed in the scale will fashion but I think this is a great question I think your loss of companies are think are placing this problem now so I would say in the way I sort of discovered the problem to to work on is not really Buy in Oakland literature study were looking at the data by myself so the way I'm doing it you know and also is the way I find it very efficient is I know I normally try to stick together were very close to a father team or engineering team and by doing so I get very close to the source of all kinds of challenging problems so in that way I can make sure all the problem I get or importing problems to at least some themes in the company so I will not have this no crazy idea or no one will benefit from if I even if I can solve them so that's why I think that's a very important lesson I learned in the past when you know
 when I walk in the fortify so First Interstate closed closer you know when engineers and product seems so we find an important problems to work out and so that's why we find a problem and build a prototype and the problem now is how can I put it in production system so there are multiple options were doing that no one on this one is your hand over the cold you know there will be that's a proper engineer so you know we sat there you're cold and we Implement everything and but another way another approach I took is
 I tried to make my own machine learning pipeline or at the machine and cold as good as possible so it gets to us day that's almost ready to be integrated into a bigger Pipeline and even if the pipeline is implemented in a different language we have no different ways to train them together for example in over there might be some API region different languages for example from piping to Delaware from python to see or we can simply store the output of the machine in pipeline in
 Coleman accessible storage space like a database or hdfs another pipeline in the bigger system can pick it up later
 so are you saying that like sometimes your your approach the Prototype or whatever code you right ends up being like just good enough for production you just kind of have to plug it in and connect it to the right datastore that other people are accessing so I wouldn't really say it's always the case because I'll serve during the day designs work for some time I wouldn't really say I am still writing that say production level called
 but I didn't mean when I write I tried to make it as good as possible Queens to the best practice in the software engineering to make sure it's maintainable extendable in the way but still I would say when we plug my cold into some there are lots of things we need to maybe we consider because there might be other use cases we want to tackle in OS update our system so there will be changes to the cold
 yeah one interesting thing you said you know about sitting with the same the people that are encountering those problems that you might end up wanting to tackle from a data science perspective it reminds me of when I used to work at this trading company and they would sit the engineers somewhat close to the Traders because the Traders are we are constantly encountering these certain problems in the engineers are building products for the trailer so it really makes a lot of sense to to have them kind of cold located with one another so interesting you know what your building products for other people in the company you know it's make sense to sit close to your users I think the key benefit of doing this kind of embedding were sitting together or whatever they call it is we can shorten the feedback loop between different teams drastically
 and sometimes it's very very quick call so for example in Spotify between engineering teams or proteins to data scientist or analyst and sometimes if you don't stay together people send emails across different teams and there's no guarantee how fast you can get a feedback for anything you know sometimes he happens 30 you know sometimes it can take some time but why when you stick together with it with each other you don't even need to send emails or no talking through some messaging services you can just talk to the guy next to you you can just have a small chat and you can just resolve the problem so I find it extremely valuable and encouraging actually because you can literally stay small Pro glasses are made and that's very like that's a very nice feeling totally
 we've done several shows recently on these different streaming systems on this is kind of zooming out to to a bigger picture but you know there's always strings sisters like store spark streaming Sam's afflink all these different things I'm curious what your perspective is on why there are so many of these and where we're going with all these different stream system then maybe you could touch on how streaming systems are used at Spotify so first of all I want to see some side but my view only the fact we have so many like new streaming systems coming out all the time these days is I will say this is the sign of a new blooming field or a very new requirements or demand it from the industry so previously people were using Hadoop or other technology
 death notice for batch processing for quite a long time I think in the past couple of years and no people start realizing okay and we have stirring all the beta come in all the time and we don't want to wait for a couple of hours until our date is ready so streaming becomes a very natural next that I would say but at the same time I think from the industry there are some very Diversified event for using streaming system people have very different use cases and I would say none of the current streaming system is actually mature enough for big enough to cover all the use cases that's why I think we are seeing so many news Premier systems ain't no coming out and completing each other and the person I think this is a very nice thing to have and then I think it's very promising for the near future maybe in one no two years we will have one or two very much
 streaming system implies many companies will use
 so regarding regarding Spotify I think we use a streaming system for a couple of use cases I think we have some music streaming system for at marketing and media streaming system for personalization but it's not a huge used Casey Imports by at this moment
 is that because the sensitivity of the of the data processing is not super high like it I mean I can imagine if a user listens to a song and then you need to run a machine learning algorithm on that user listening to a song it's not a huge deal if the user's playlist gets updated in 24 hours or 12 hours or whatever rather than immediate is designed to to to to give you new songs in the playlist every week so in that case you know using some batch processing pipelines it's not a problem at all but on the other hand you know think about another use Tastefully Simple we want to personalize our recommendation based on your recent search Aquarius
 so in that case you know having a few hours get between these are actions and having the day that you know your system is not really acceptable and I will say it to build Sox pitchers so in the future if we plan to do to do more real-time recommendation or real-time theaters in Australia system will become a must have to hold and makes sense so there was recently a a product that was open sourced out of Google called tensorflow I don't know if you've looked at this much but I'm curious if you have what you think of tensorflow so I was saying I mean I would say everyone is looking or talking about 10 simple now it's it's a big thing from from Google store so I haven't really spent so much time looking to the product but from what I know I can I can only say it's a certain a very promising from the white paper
 I got from from the website of tensorflow but I do need more time to try it out to see if it will epic say no for real data because tensorflow itself is such a big products and has so many components I think many people most of the people need lost a lot more time to actually understand what they can do what what it cannot
 yeah I spoke to Greg Colorado yesterday who is one of the guys who works on tensorflow and he was telling me about how I didn't really understand it before I was interviewing him but he was like you can deploy machine learning models to people's phones basically in it have those models dynamically update with new information and maybe this is something that is not a huge New Deal Spotify where if you already had if you had this pre-baked model deployed to your phone and it could update all on the client on the phone then every time I listen to a new song You Know The Machine learning can happen on the phone I don't know maybe this is a baby this is not anything maybe this is something that that is already happening and that's not the big breakthrough tensorflow but well but that means regardless of tensorflow but I think outside the capability of the point of motor oil into user device I think it was hugely valuable because
 if you think about the the traditional way of building recommender system which is about getting all the users that they listening you know history you know what songs you just send them to this huge Matrix and doing Matrix vectorization and building lots of Ensemble models in our server Farms know that takes a lot of time and use lots of data but if we can have smaller models in a personalized to use a level device you can actually traino's model based on only based on users on data so in that case the amount of time and say no energy needed to train with Moto is so so much smaller or in the next cleaning a shoot model for all the users all the continents we have yourself is hugely valuable and nothing Google have
 the machine in the model in Google photos or some other Google product avoid on Android phones already yeah yeah yeah machine line that is focused on things like collaborative filtering we need the entire user set versus just having something that is much more individual user specific place you think about sea turtles like to Google know the personal assistance assistance I need to Stephanie I use case examples we know their the Moto only rely on you know probably doesn't charge so much about what other users are doing as long as they take us out to the current either is fine
 right so let's let's do not even further what is the future of data science like when you're when you're working day today and you encounter certain operational problems are certain like systemic problems you say gosh you know in the future there's no way data science is going to have a problem acts like what are the problems that are going to get it sorted out over time how will data science change become easier so I will say in the future I don't even know if the future is our future or near future but in the future we will have lots of tools available for data scientist or
 anyone works for the beta. Can
 you know takes over all the routine Works in all this data scientist need to do list example in or running basic diagnose over the data example you know I want more complicated a very complex they decide I want to say okay and go home I did it that look like and you know even though it sounds pretty simple but it might take quite some time to to to to to do this because you have to run proper analysis for each Cola Mortgage l'erable in your data said you have to do something normally detection their loss of routine works I think those work will be taking over compiti by automated tools
 I think there are already some tools like automatic statistician are all there and Skytree Infinity
 all there to to to do this kind of work so I would say no
 dim those tools at Sears maybe three to five years notice will be powerful enough to take over to handle most of the routine work for data scientist and as a result I think data scientist will be pushed into a
 plays that help people need to focus more on that's a feature engineering Park in Bay City you spend most of your time thinking about what kind of data are you going to fit into those in a super awesome tools sold those tools or those bathroom can give you a nice result
 and also people will focus more on interpreting the interpreting the results in or from those tools and convert those inside into you know the insides bit of business values
 yeah Mr maybe this is the interpretation side the you're talking about but how do you think we're going to move some of the job of the data scientist Beyond a place that requires coding
 I don't say it's possible I think but I think that's also depends on the type of data science work so I think you know it's very hard to predict if that will happen because I notice when they designs been in a big data with machine learning there's so many possibilities for the future alone for the coming year
 yeah definitely so I guess I want to close off with just a question I would not normally ask this at at all but since you're busy work at Spotify and I was just like really curious what music do you listen to these days what are you listening to music from 70s or 80s and I would say that's probably because the movie The Martian
 Jiffy Lube in the movie they they they really put in a lot of the nice music from 70s and 80s so like storm and from David Bowie I don't know how many times I've listened to that song repeatedly and from there I I start listening to 222 music from Bob Marley Fleetwood Mac and Eagles rocks at the Bangles in all sorts of an oblique stars in the 70s and 80s two to three hours per day like there are a lot of features and then maybe I haven't explored I certainly use discover weekly but do you have any recommendations for process to check out the freezer okay so when you're when you want to listen to 70s music are you like going to the radio feature or how are you discovering 70s music you want to hear
 so normally I go to browse so our basic editorial playlist and there are you normally find out music from different arrow in the 70s 80s 90s and we also have a good relation of different music genres so for me and want me that's the starting point and freezing point jump into a that say rock music in 80s playlist and I start looking to it to track and check it out his page and then another feature use is related artists bill that's in Glade price for expanding the view of the music Horizon
 when you're consuming music on Spotify do you find yourself thinking about what what in machine learning like one machine learning stuff has led to this song being generated to you or or do you feel like you don't have enough of a grip on how recommendations are made at Spotify that you can actually conclusively Trace that I was saying oh from my own protective because I know how them anymore those work so when I listen to African food store weekly I can sort of the you know you know how are made and I think I also talked to some of my friends who use discover weekly are often and I think you know sa user outside Spotify letting people in all ways you can also sends you know how is generated because one Coleman let's say you know this playlist discover weekly
 personalized for my taste because there are lots of music peoples are recognized in some some generous or the mood or the artist type
 yeah definitely what boxing Zhang thanks so much for coming out to soft Wednesday daily it's been super interesting talking to you about Spotify and data science and machine learning and all this stuff I really appreciate it thanks so much it's also my pleasure to talk to you
