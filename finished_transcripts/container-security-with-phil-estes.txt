Transcription: containers have become the unit of infrastructure that many technology Stacks deploy to with the shift two containers the attack surface of an application has changed and we need to reconsider our security models the resource allocation of our containers the interaction between different containers on a single machine the big picture how the external web May interact with our containers there are so many different things that we need to consider when we move the security model to a world with containers Phil Estes of IBM joins the show today to discuss container security as well as the oci and container orchestration and other container related topics it's a in-depth container related episode
life is too short to have a job that you don't enjoy if you don't like your job go to hired.com se daily hired makes finding a new job enjoyable and hired will connect you with a talent Advocate that will walk you through the process of finding a better job it's like a personal concierge for finding a job maybe you want more flexible hours or more money or remote work maybe want to work at Facebook or Uber or stripe or some of the other top companies that are desperately looking for engineers on high you deserve a job that you enjoy because you're someone who spends their spare time listening to a software engineering podcast clearly you're passionate about software so it's definitely possible to find a job that you enjoy check out hired.com SE daily to get a special offer for software engineering daily listeners a $1,000 signing bonus from hired when you file
find it that great job that gives you respect and salary that you deserve as a great engineer I love hired because it puts more power in the hands of Engineers go to hired.com se daily to get advantage of that special offer and it's thanks to hired for being a continued longtime sponsor of software engineering daily
 Velasquez is a senior engineer with IBM Bill welcome to software engineering daily thank you you have been talking about container security at conferences for a while and I've learned through the conversations on this show that regardless of what application domain we're discussing whether it's cars or a database or a chat application if we're talking about security the place to start a security discussions off in this discussion of an attack surface we're talking about containers what does that term attack service entail
 yeah so a good question there
 is a sense in which the attack surface on applications doesn't change necessarily because of the sort of domain that's running it whether it's a virtual machine or container so we kind of have to divide I think our our our view of the attack surface into what stays the same and what's different and I think the the what's different is what has been interesting as containers become more popular is the desire to understand what are the strengths and weaknesses of this contained environment that seems kind of like the M's to people when they first year what a container is but but we know technologically it's quite a bit different
 and so much of the attack surface when were talking about containers has to do with if I'm relying on Linux and Linux containers are kind of
 but for the most part all that we have I think we could talk about the history and and look at some other Unix operating systems and and the fact that Microsoft is also implementing a container Paradigm inside the windows kernel but let's just focus on Linux for now when we're talking about the tax service then we're asking whether the Linux kernel Primitives that created container are they safe can they be broken out of our their weaknesses and so that that's really I think we're a lot of the focus has been on containers is how can I trust my container execution environment weather that's Docker or some other existing technology to truly keep my application separate from other processes on the Linux host
 you you mention to the wider definition of containers is two containers during this conversation it might be worth defining that term because in 2 years from now baby we're not going to talk about Docker containers we talked about some different container technology that's related to Docker or is it is a descendant of Docker in a fundamental sense what is a container I've asked people that question before you get different different answers what are the properties of of a container that we need to think about what I'm saying about security what are the properties of a container that we need to secure
 yes good question and hopefully my answer might lineup was with one or two prior guess we'll see so in the Linux world what are the things that makes containers hard to Define is that the Linux kernel has not defined a concrete construct that we could really call a container and so we're left kind of describing the pieces of Colonel technology they're definitely Linux developers who who call this combination a container and and think of the set of capabilities in the colonel as the container API so to speak. But really it's comprised of today at least six namespaces and so these namespaces are the isolation Primitives in the Linux kernel
 so we're talking about the mount namespace so what is my file system look like when I'm in my own mount namespace versus the host of the pit namespace and what processes do I see if I'm in my own kid named space then I better only see my own processes the username space which is a probably the most recent of all the name spaces to the altar Linux that says I can now segment out even the user ID and group ID ranges for a container the network name space so you know my network interfaces my network routes are all unique and then there's a few others to IPC namespace for in a process communication so isolating my ability to use shared memory or shared memory resources
 and then finally the UTS namespace really just allows a container to have its own hostname and domain name the main isolation Primitives that whether you're talking about alexie which is existed for a while or chorus is rocket or doctor or any other containment type execution engines that come on Linux at least they're going to be assembling these namespaces for you hopefully in a way that isolates you from the rest of the host and then on top of that there's resource limitations which simply called c groups in the Linux World control groups is the full of moniker spaces allow me to isolate different pieces of the system then see groups allows me to control how much of those resources my container uses weather at CPU or memory
 so hopefully when we talk about container systems whether it's talk or something else at least on Linux will probably end up talking about namespaces and see groups and how we assemble those into what we commonly call a container you were thinking about securing containers we may be talking about securing one single container we can talk about securing the host that is a probably a VM that has several containers running on it we can talk about perhaps the orchestration system that is managing our containers so what are the shingle container retainer that's running some stuff in it what are the basic security assumptions that we can make about a single container
 yeah so to connected to what we just discussed one of the things is that will effectively be relying on the fact that whatever container execution engine we've decided to use we expect it when it's set up these names bases and see groups that they will actually contain my process the even if I'm somehow running code to talk she trying to test the limitations of these isolation Primitives that effectively I'm expecting that that's a wall that can't be breached so that's kind of our first line of defense is that we expect the Linux kernel developers have worked hard to make sure that all these namespaces don't have leaky isolation mechanisms that can be breached and obviously
 given the container technology is not new. Many of these namespaces have been being developed for a decade in some cases there have been a lot of CDs and insecurity announcements so if you look back in the history of the mailing list for the Linux kernel but in essence of our first line of defense is expecting that the Linux kernel protects my process from from Gaining access to the host another host information also we have a touchdown this year because a Docker innocence introduced the whole concept of a prebuilt image of which I think is probably one of the reasons the doctor has gained so much your popularity compared to maybe other prior
 offerings in the container space is that you now have this Docker Hub with thousands of images your favorite open source database your your favorite web server
 into the other thing we have to think about what we're just thinking about this single container is how to decode get packaged inside that container until I trust if I'm using it from a Public Image that it doesn't it self contain Roku or weaknesses are explodes that haven't been patched so I think those are kind of the two main areas when we're talking about a single container is it truly isolated can I depend on those Primitives and it if I'm using some kind of pipeline that that got my code into this container can I trust that pipeline do I have the appropriate security measures of two handle that is not necessarily the idea of a container getting breached but more the concerned that the container
 takes more resources than it is desired that the program it's running is designed to be allocated is that accurate yeah so so this is probably where we would start to try and understand kind of deployment model so your concerns around containers will probably depend on on where your place in containers I guess is one easy way to think of it if if I'm putting it in a shared environment but within my own company's intranet then my security concerns may be vetted by by the fact that I'm in somewhat of a trusted environment within my company if I'm placing them in a shared public Cloud then maybe that changes to some degree what what my concerns are
 but definitely in in the in the model where were packing containers together in a single host the definitely resource allocation becomes a concern similar to cuddle the whole nosy neighbor problem that even has the attention of vmworld of GM's on a single host how much memory how much CPU Kenichi each my Vans allocate so control groups of the analog to that for the container World definitely that's of interest in a shared environment but I won't I won't say that. Container preaches are important as well as a concerned especially
 so IBM's public Cloud container service model is that we're sharing Docker hose on their metal multi-tenant so the container next to mine might have might potentially be attempting to to breach other containers to inspect the system around it and someone in that model of a share public host for containers that I do have to concern myself with how do I make sure that even a breach could be controlled by other aspects and that's that's where we probably end up talking about
 other Technologies like Linux security modules, Lee a Parmer is a common when selinux is the other another containment mechanisms that make sure that even within a environment where I can't trust anyone else there are certain knobs and switches that let me protect that environment yes situation we've got a host with several containers what are the risks that an individual container poses to other containers on that host are are we thinking mainly about like you said the Noisy Neighbor problem here or then or are you starting to think about oh baby you don't want to expose
 you aren't even asking permission settings between what different containers can access from one another what do you start to think about when you're when you think about the multi container interaction security model
 yeah so like I said they're they're definitely said that's something that that our own public Cloud offering has had to think long and hard about we have a security researchers were much more intelligent than me about the the Deep sort of security research around the colonel and and and some of these containment mechanisms and you know they've spent several years now looking at those issues and then for my part II get to try and express that and in more common terms is both enjoyable but also I worry sometimes about being ask the hard questions but in the sense of this particular issue I think there are a couple things that that we worry about one we've already talked about which is a simple resource usage so
 say I have a container startup on the same host that I'm located on and it turns out that this container happens to be created by a spammer who all they want to do is use up as much Network bandwidth as possible to send out you know spam email in this case it's very important that I have knobs available where I can restrict the higher bandwidth for the network ports similar for disk IO and these are thankfully these are capabilities found within control groups are these are things that was each version of the Linux kernel there have been more there's been more enablement of of these tweaks and knobs to control processes resource usage that's one area of the other maybe is a bit more theoretical in the sense of we've already talked about the name spaces
 sort of expected that there's no way to escape my Mount namespace or my pin namespace and start to try and control or or get information about other processes and other containers but would that were that to be possible in the future due to some exploit that is not known yet some of the capabilities of a farmer allow me to write a profile that says even if this container could see this file system over here don't ever let her write files here in certain cases don't even let it read file down this file system and so that adds an extra layer of protection were there to be an exploit from a container having full access and this is also where username spaces comes into play because if the code in my container is running his route because it needs to start of a web host listing of 480
 that requires extra Privileges and Linux username spaces allows me to remap that whole idea space inside the container so that even though inside the container on look like I'm the user on the host if I were able to break out I'm actually running as some high numbered user maybe a hundred thousand or two hundred thousand and if you look on your Linux system you'll see that user ID 200,000 really has no permissions to do anything of interest on my host and so that's another protection so there's a set of layer Productions that are available that are available in Docker they're available in some of the other container of execution engines and and combining these together gives us that protection such that we can feel comfortable running this multi-tenant container Cloud where I've got multiple containers on the same host and I feel like
 can I have the tools necessary to protect them from each other and also from innocence denial-of-service thing than the other container is by using all the bandwidth after all the io all the memory etcetera different layers that got the external environment the host the containers within that host how does the security of our applications in this containerized world compared to the old world of perhaps BMS or just bare metal whatever we were talking about 5 or 10 years ago the trendy application models they were things more secure than or just totally different
 what's the topology in your perspective
 yeah some of that that's a great question and one that I think a lot of people have been discussing for a while things to compare it's it's a very good question because you have what we see a lot of excitement around containers and I think you can find lots of startups and small companies already using them for meeting for work you know IBM's big enough and old enough that we have customers that take a good bit longer to to reach some of these newer technologies that no maybe you and I if I've been talking about them for a year or more so those kind of customers are definitely wanting to see this question answered in ways that give them Comfort to to start to go down this route and so I think
 you know Microsoft and then what I've seen in the last 12 to 18 months
 and I feel like it's it's starting to be backed up by a very good work like the NCC groups hardening Linux and containers document Aaron grattafiori because put that together it's an excellent very in-depth look at all the container execution options what they have available for security what their defaults are and so that's a long intro to saying that I perceive that if I container as my application and use the defaults of docker
 I automatically have a set of capabilities that in the past would have taken some engineer's thinking seriously about how to write a check on profile which is secure computer in your capability in the Linux kernel to only allow certain calls to be used I would have had to think hard about how to write an app armor profile that will allow my application to write to certain places on the on the disc so all these things are sorted given to you but of course they're they're given in a default mode you could you can expand them you can make them tighter what are the tight ropes the doctor and other providers have to walk is that you don't want to created by default security profile that hampers container application from running
 but in essence by the very nature that I'm giving a set of defaults that are already turned on we know that developers are lazy and so if it works out of the box and then I'm probably not going to do much else unless I have a very rigorous security you know development guideline and so compared to the vmworld where I would suggest that you know once we got our application packaged and maybe there were multiple applications in a single VM we weren't isolating them in the same way that we're getting out of the box isolation out of containers and so by that to buy the nature of that we've automatically improved application Security even from each other so my database for my web server my redis cache from you know the front end of my application fees are already automatically isolated from one another in ways that would have taken some
 good Chino engineering work in the past that we're getting by default in container inside I would say that we're definitely improving and I think we only see that increased as we move toward microservices world where we can even be more explicit about what an application is supposed to be doing and when we see it not doing that we know there's been a problem in and can respond quickly and so he even that movement which isn't directly tied to Containers but I'd say containers are enabling that movement you know I think we're going to continue to see you in Improvement naturally and skin the security profiles applications because of it
 do you think it's also an ocean of security in operational terms because the idea of a container so much more expensive and if something's going wrong you can just throw it in the trash and then spit up a new one is that is that fall under the purview of security. The definitely has security-related implications is the fact that you know maybe step back even before VMS you sort of have this pristine production environment and nobody should touch it because it's actually working today and let's not you know I messed that up so the movement away from that model and nvm's maybe were step in the right direction we sort of could create this Pipeline and and
 there is a security issue in our operating system where we could regenerate the other VM image with the update and push that production the containers take it and I'm tired you know level of complexity easier as you said hopefully already have a sort of cicd system where my containers have sort of this pipeline all the way from Soros to image and so you add to that all the capabilities being added by various clouds to have automatic scanning the container images and so I have this immediacy of okay security scan and found an issue let's update that package that's regenerate all that contain could get that through test and push to production
 and just even aware the operational awareness is so much higher than then stepping all the way back to that first example of point of this pristine production environment that no one should touch and is anyone even checking if you know package CDs so so yeah it's definitely the relation of containers as quickly are replaceable and rattle map packs
 how does devops change in the age of Docker and kubernetes at aprender.com se daily you can find a webinar about devops in the age of Docker and kubernetes featuring Jhene Kim author of The Phoenix project Gene was instrumental in popularizing the devops movement and that aprender.com se daily he will be discussing the topic with speakers from Google and aprenda Docker and kubernetes have exploded in popularity and with these changes there has been a shift in focus from automation to full orchestration in distributed environments learn from Google's experiences running containers and clusters at massive scale and learn from Gene cams explanation of the state of devops at aprender.com se daily thank you to a friend of for being a continuous sponsor of SE daily and if you're a listener
 want to support software engineering daily while also learning about devops and Docker and kubernetes check out aprender.com SE daily apprenda provides Cloud platform software that works with your existing applications and infrastructure so if you are looking for a Enterprise platform-as-a-service you might also want to check out aprenda. Com / SE daily thanks again Brenda
 I would like to shift the conversation to talking about oci because you are you have a depth of knowledge in containers and oci is an area I've been wide to cover this is the open container initiative
 but could you explain what that is and what why why this got started what's the history of the open container initiative
 sure so the OC I really came out of a desire by many different partners who out of state in containers and even people who are very active in the doctor Community given some of the the challenges of competitive environment swear I noticed you know Brandon Phillips has been on here recently Socorro s had some issues with with Docker and their Direction created rocket and the app C specification for containers
 and so there was a desire that if we were going to see you no potentially very competitive offerings arise in the container executor space that there were at least be a place we could all work together and harmonize on a specification that says from Linux and other operating systems to follow here's the basic idea of the container runtime if we all can Implement these pieces then you can say that your oci compliant and we can have a interoperable configuration of of what a container runtime I will do without set of inputs expanded earlier this year to add the fact that it's one thing to have the ability to take a set of configured inputs and run it contain process but also what does it look like to have an interoperable image and what
 continue what metadata about the image describes it and how to run it and so these two pieces together the OCR run times back in the oci image back are quickly moving toward their 1.0 release candidates actually one of them the runtime spec is already at rc2 I believe and so there's a good community of people working on that court cases involve doctors involved Red Hat IBM Huawei Google and several others home and so that's babe I forgot to add to the one that was kicked off but that was announced on stage dockercon San Francisco in 2015 so it's been sort of in operation as a foundation or part of the Linux foundation for just over a year now and so so yeah
 again a Level Playing Field interoperable specification no matter which container executor new choose hopefully in the future they'll be a compliance guidelines and a certification sweet that you can say OK my run time is oci certified and therefore I'm interoperable with other oci certified run times two things that the oci consist of this container for Matt and the container run time that we want an open definition for what is the relationship I mean I guess what is the definition for a container format what's the definition for a container run time and what is the relationship between those two things
 yeah so what are the easy ways to Takata visualize it is that the part of the founding though see I was to create a reference implementation of the runtime spec and so there's a project called run see that is also about ready for its 100 release it's already in use by the docker engine and so it's already received a lot of testing just by nature of the being part of Docker as far as the container execution at the colonel air is actually be performed by run see that I want to use Docker engine today so as I said once he is a good picture of the relationship so runcie needs two pieces of information to ask you your application as a contained a process
 what are named Jason configuration file and like we talked about way back at the beginning of this episode a big part of that configuration is which namespaces do you want do you want all 6 and some of them have configurable details and then secondly be on this configuration file and we can talk more about what's in there there's obviously the name of your command to run to the environment and environment variables and what he wants certain Post locations mounted file systems within the container so so a lot of the same things that you can do for example of the doctor run command much of that's available as options within those Json configuration so given I have the configuration file which you can say is the embodiment of the runtime spec I also need the actual file system natural file
 what makeup that root file system in my container and so if you think of taking an image from Docker Hub and exporting it into a flat file system obviously in many cases looks kind of like a small Linux distribution with the application I want to run and maybe a few other tools around it and so with those two pieces of information run so you can ask you and start your container so the image format is a combination of those layers which make up that root file system and sodak created kind of his concept of a layered file system that's related to their Docker build capability so I can start with AB into I can add for maybe the job of the jvm I can add tomcat and maybe I copy a few configuration files and my War file into this and that
 what is commands basically become a set of layers and so the image format references all the layers that I need and then you can think of those as just tar files each constituent layer and beyond that the image format contains a simple container config of you know things like name and the secure hashes of each layer and any other meditative so this is at the oci image specification is actually a started with a copy of Dockers existing version 2 image manifest format and so that was something that aren't the doctor was already using and so the oci image Speck started with this existing concept so I don't know if that was if I made it more convoluted the necessary but essentially if you can buy but the image back in this runtime config
 those are the inputs necessary for an Executor like run C to run with that and then start your process with all the configuration options you chose and you're wanting you mentioned there was the relationship between what oci is and what Docker was at a certain point I guess what I mean when
 is there more darker was kind of the de-facto standard for container images any kind of kind of still is but what what what is the relationship between the oci format and run time and the docker Docker format in runtime
 yeah so at this point what you have is the Doctor Who has basically in essence contributed that lower layer to the OC sucks the doctor now becomes a consumer of the oci runcie implementation and by that I guess you could say it's kind of funny but the darker bites all can no longer run containers because it's actually using runcie and all that code they contributed to handle setting up the name spaces in the groups that all exist within the oci and
 so Docker now becomes if you will the API the client interface things at a higher level like live Network so all the networking support all of the volume management some of the again some of the the more you X related features of of having a place like Docker Hub to store your images are more subjective decisions when we talk about the atomic basic unit of water container is that is what the oci is trying to make a a bare minimum definition for so people can build alternative things alternative software products that are containers but they may have different networking strategies different ux
 sayings until I think we will you said there could tell me if I'm wrong about this there was a certain point where the OC I said okay Docker does things this way we're going to basically take a snapshot of what doctor does and Docker from now on will will will try to be compliant with the oci and and the OC I will just kind of remain this this defacto standard and then other things can be built on that standard as well as that accurate
 definitely. That's that's accurate and the expectation is that it it softens the the confusion around a core OS having an execution environment call Brockett and Docker having their own execution environment with their own API
 and it also gave a place for some of the lower-level functionality for other containment system so I don't know how far we want to move out outside of Lennox pistoleros has zones Brian Cantrell has talked a lot about that with the with their Triton capability joints Triton capability so so some of those Solaris folks are putting that zones capability into oci so that you can have for example of a the tool called runs the Harlem lunar phases could continue to do all the things they do such a stalker
 but you might replace runcie with Ramsey and now I'm creating Solera zones instead of Linux namespaces and see groups so you so yes all that to confirm that that definitely this unit that were thinking of is a container oci's taking over kind of that definition such that there can be both higher layer obstructions built on top of that where we can all at least agree on what the the common unit of a container is and then at the lower layer it also allows other people to implement that spec and use their own containment strategies whether it's on in the windows kernel or Solaris zones or something else Solaris
 so you said she said like the diesel Arizona people are saying hey we're going to add this function how to get to the oci which is this lower-level primitive why doesn't that break what Docker is doing at a higher level of Docker is agreeing to comply to a lower level template why doesn't adding something to the OC I break the higher-level products
 compatibility with oci
 yeah so that's where there has to be a lot of care taken for this oci interface that it can handle other lower layer implementation and so the specification itself has been worked on diligently to have whether it's optional sections for operating systems that are unique like Solaris but as long as a higher layer implementer
 agrees to only interface with the oci specification it actually does does work in the sense that. As long as the lower layer of the Temptation can fit within the OC ice pack and that's what Microsoft and the Slayers folks are working on right now then the higher though layer doesn't have to know because again I was in our faces of of start me a container of the name of the application is this and here is the other metadata that I don't have to care what the lower layer is doing on the back end even if it's a different isolation mechanism then see groups and names bases
 that makes sense so what's the
 what is the governance of the oci are there I mean zones that sounds like a pretty clean up augmentation to the oci I imagine there are more contentious things that could arise if somebody wants to change some of the more fundamental building blocks of how the oci works and you know Docker is on top of the oci we don't want to be compliant with that thing cuz it might mess up our functionality so is that an issue or what's what are the governance challenges to this oci
 yeah that's a good question I think it actually is something that has been potentially misunderstood not the Twitter is always the best source of information but better for you can you can look back and see that there's been confusion around who controls the oci what is governance is and then some interesting back and forth there is like it's like eventually eventually consistent opinion database you can't trust it all but long-term it's it's like the blockchain like eventually eventually eventually it resolves right right so
 is that it is fully operated by the Linux Foundation they have a set of what's called collaboration projects of which to oci is one of many CNC off is also collaboration project and I know there's a whole list on the Linux Foundation website but what that means is that there is a charter for those he I signed by all the members as of December last year when she explicitly States the governance model are there is a technical oversight board that meets there is a certification a trademark working group there is a sort of technical committee I forget if I have that name quite right there's so many foundations that are named things slightly the same that but think of that is sort of the core maintainers of the OCR projects and each sub project has its maintainers with its own governance for how many teens
 is there added Dockers obviously a core player in the oci but the tobh contains members from from quite a few companies including you know chorus in Google with red hat and so
 anything that can't be handled through standard open source debate and consensus that goes up to the Tob for resolution there may be a better few things that I have ended up there in the last year part of it was really understanding the scope of oci's there was a little bit of debate about the scope weather was only the Run X back or whether image format or even image distribution would be part of that discussion and so the Tob helped the parties agree on a scope which is also there and body did the charter that you can find online
 so all that said that I think definitely there can be disagreement about potential directions with with this pack or additions or changes of the image format itself is had you know some back and forth on its scope but for the most part these are being worked out by you know potential competitors in the space who also happened to work together well I'm just to cheer technology technology definitions until we see the oci as as a good place with common governance that's not controlled by a single vendor and you know good good work has been done there by by parties that that could be seen as competitors but who are working well together to make this kind of standard definition note that the lower layer
 how does the oci evolution relate to The Container orchestration layer where we have kubernetes meso stock or swarm other orchestrators
 yeah so so the relationship has been fairly clear that OC I will not have any say in that space that that's left up to hire layer does communities am very specifically the cloud made of computing Foundation cncf shirt has a block diagram that says will consume a container runtime based around oci but will look at the higher and higher layer of orchestration so I don't COC are trying to expand into that space at all I think the scope of the project is is fairly clear but you know we'll definitely see CNC often and other communities trying to to work at that Hard layer of orchestration I don't think that this
 we're going to see sort of the same idea around a specification I mean that's not the state of purpose of the CNC at this point it's been more place to to be an umbrella for for projects related to Cloud native which you know it at least today is with her first contribution from Google kubernetes the cncf is mostly the management of that the kubernetes project as well as Prometheus m in a few others coming down the pike
 so yeah long answer again but but OC I think will remain very specifically focused on only the container runtime at the lower layer
 so kubernetes today as far as I know baby I made a mistake I thought something between kubernetes and Docker like do you have to use Docker containers to use kubernetes the expectation is not kubernetes would package a version of the docker engine and that when you start it up a Cooper netease pod it was actually running Docker containers and Docker images would be loaded but you don't actually start those containers of that still the case of the current version that by default there going to be running the doctor engine
 there are communities within kubernetes that have enabled things like replacing that with rocket from core OS so there's rocket buddies find that projects within the broader kubernetes community and most recently some of the oci participants from redhat have created a replacement that's trying to only use oci components now that there's an image back and there's some tooling around using oci images
 they've actually it's just from my conversation with you
 yeah yeah so so definitely using oci format images and OC I can play run times makes a lot of sense I think we'll kind of see where this goes as far as this new incubated project I think ocid is its current names for like oci demon is Docker or any project becomes officially compliant with the oci specifications but image of runtime that. It should be a replaceable component with anything that's OCR compliant so yes I think they're
 there will be a continue 2 times to see if what what's the best part of execution engine to to fit underneath kubernetes and hopefully oci interfaces are are the norm and that weather Dockers the implementer of that or something else should be a you know and user-specific choice in the future there acrimony recently I don't know what degree it's it's it's just like Twitter Twitter clickbaiter word bait what are you want to call it
 but I mentioned that that I met your Bitcoin earlier as a joke but I think I actually the container debate from a distance at least it seems somewhat it reminds me of the Bitcoin and ethereum debates and forking issues and stuff just because there's all this contention I was acrimony and
 it into being well in in the Bitcoin immediately it's ended up being it feels like it's been a productive discussion long-term at me I don't know if you fall the Bitcoin community at all but like it's resulted in etherium coming around its resulted in your there was this Bitcoin Fork stuff that happened early on that was or that happened earlier I think I have a year ago or half a year ago or so and it was like really really worried some stuff within the Bitcoin Community but in the long in the long run it turns out like the stuff is at disagreements are actually really important to resolve because it's looking like this is going to be core infrastructure stuff and there's just no getting around that there's going to be some conflicts the same stuff has happened in the aetherium community with this this Dow conflict stuff the other day the Dow got hacked essentially and then they decided to forgo etherium is is like a hundred and fifty million dollar decision
 and it's obviously less directly Financial in the world of Docker in containers but it is of course Financial it is of course emotional for people this there's this threat of a fork that. These rumors of a fork of a doctor Fork I don't know how much you want to touch on this but I should be very curious to get either your direct thoughts about these discussions about a fork what am I mean or just met a discussions about when were talking about forking
 Corridor structure Technologies in September 2016
 yeah sure
 it's definitely been a very interesting to to see it from the perspective of someone very involved in some of these open source Community The Narrative that I have heard about being potentially Fork is Docker injected some capability should built-in capability for their swarm orchestrator in the docker command line and that are some people in the broader Community but maybe you could tell me what's the correct about that and sorry to interrupt your Google that's that's good too too kind of set the background and I think for most respect that that's not action is baby Eazy-E the linchpin. Of it but it's not sure of the start of contention of already mentioned a few times that have been
 do the doctor community and differences of kind of technical Direction let them to create their own container execution engine in rocket OC I was definitely partly Cena's as a way to Quail some of the the the disagreements there and now we're kind of a higher layer where kubernetes has become quite popular Docker is both an open source project but also as we all know the startup with significant funding and a lot of momentum and including their they're sort of most recent attempted orchestration layer directly within the docker engine was seen definitely buy some shawcross the bow
 and I think the credit doctor then to the fact that the doctors become popular enough so that that there's an attempt to want to continue to use it not not to switch to something else but actually use Docker itself and just for cats and there can be more control you know obviously shows that that doctor is seeing as it is a very critical and core components of a lot of these higher layer systems and as he said I think they're there is definitely a perception but that containers are very possibly the future for her for a good while ago of infrastructure for the cloud there's a lot of emotion around you know what people have created and the various you know moment momentum around these various projects that people are very attached to their you know Solutions and everyone understands there
 there's a lot of money at stake here there was was sort of whoever wins if if if someone quote on quote wins in that sense so I definitely understand the sentiments of the emotion
 I think and I hope that we're going to see some some responses to all disclaimer it's definitely affecting me to morale and various communities to have so much contention that's going to unresolved and then sort of sitting there behind the surface I know for a fact that that doctor cares about that and they have worked hard to have their own open source community and you know just another sort of meadow point is that you know prior to Docker swarm being integrated of the engine I think that just the whole perception that Docker Inc controls Docker very tightly has been a point of contention that that is also led to this moment of the you know the various groups who are saying it's it's time to the rest that control for a from the sort of corporate sponsor of the open source project
 you know were involved in all these communities and so are Our intention is to hopefully find Solutions done are quite as drastic as is trying to her to rest control and in Forked open source project but as you said I mean I think Donnie burkhart's talked with so soon after some of this chatter started on Twitter and if she blocked us and gave kind of a history looking back at various Forks that have been successful or unsuccessful and in most cases there in all the positive cases there's been a resolution and some good things have come out of that discussion happening that you know made some some parties consider you know ways that. These issues could be
 attack better and resolve better and communities operated better so I'm hoping that none of the next month or so we'll see some concrete steps to resolve some of these issues whether or not all parties except that we'll see but I think I think there's definitely a willingness to to look at this as a chance to to figure out some some hard things about moving forward with the various pieces of this ecosystem if you will
 let's hope so and I will continue to cover it in future episodes of software engineering daily Phil thanks for coming the shows Mel wide-ranging and deeply technical conversation I really appreciate you joining me on software engineering daily
 well thanks it's been great to be here and then good to chat with you I'll talk to you soon thanks
 thanks to sinfonico for sponsoring software engineering daily symphonica is a custom engineering shop where senior Engineers tackled big Tech challenges while learning from each other check it out its symphony.com SE daily that's s y m p h o n o. Com SE daily thanks again Stefano
