Transcription: augmented reality is coming at us fast every large tech company is rumored to be building an AR product Microsoft hololens is already available to developers Pokemon go the most popular augmented reality product today was made by a company that was spun out of Google but Apple seems to be ahead of everyone apples AR kit is a set of tools for developers to build augmented reality applications applications people are building with AR kit are remarkable and two of those early adopters who are building applications join the show today for an interview Jesse bounds and see you song work at mapbox a company that makes mapping navigation and location search sdks
location is a natural companion to augmented reality if I'm walking down the street with a pair of augmented reality glasses on those glasses can augment the world with information based on my location because the fit between AR and mapping is so natural matte box has been rapidly experimenting to build up an expertise in AR as a result Jesse and see you make for great guest to talk about what Engineers can build with a arkit today and what might be possible in the future
developers love Docker containers because they give applications portability and consistency all the way from your laptop to production but things can get complicated fast when the time comes to deploy manage scale and secure containerized apps in the cloud Amazon ec2 container service from Amazon web services makes it easy to run Docker apps in production with Amazon ec2 container service installing updating operating and scaling your infrastructure happens automatically using simple API calls you can launch and stop Docker enabled applications the state of your cluster and natively integrate with powerful AWS services like security groups elastic load balancing EBS volumes and more best of all you only pay for the AWS compute and storage resources you use with Amazon ec2 container service you can focus on building apps not
running time to play scaling and managing your container infrastructure it's time to get back to what you do best learn more about Amazon ec2 container service at ECS. AWS today that's the letters e c s a w s
 Jesse bounds and see you song our engineers at mapbox guys welcome to software engineering daily thanks very much you've done that touches on augmented reality so I don't know how deep were going to go today because I'm going to do a lot of shows on augmented reality in the future but I certainly like to at least get an overview and talk about some of the applications you guys have been seeing what you've been tinkering on and your thoughts on the future but just to level set let's let's just start out by explaining what is augmented reality and what are some of the applications for augmented reality well I think additionally it was a term to describe some artificial interface or have laid over the real world and kind of like modern more modern are vetted reality kind of came around in the late nineties with lines over Sports Fields like the 50-yard line up in football games and kind of fast forward to the future
 more recently we've seen libraries by Google and other companies and devices that the lie to do this just that and then of course more recently what they are kid and apple kind of getting into the game with a library really specifically designed to enable developers to insert inject this digital content into the real world space early I personally think about it in terms of like things such as heads up display that you see video games in like movies but being able to do that with like real world data and things that are at your device camera can see in the in your like immediate future like in your immediate surroundings I felt like Pokemon go was the first big augmented reality
 there are going to be out in your face kind of a application what do you think were the takeaways from the explosion of Pokemon go what did that take off because people were too so fast me by the augmented reality aspect of it or was the virality of the game what are the lessons their perspective I think it was kind of the Alchemy of a different type of gaming experience combined with the like unique IP of Pokemon with Nostalgia around it and kind of the Aesthetics of its things that we've seen before Francis a company and they Pokemon go made a very had a very similar game called Ingress with elements of a r and a location-based location-based like points of interest collection similar to Pokemon go but it didn't catch on in the way that Pokemon did so in terms of gaming and more
 sing the trend is that both Pokemon go is unlocking a combination of like augmented reality games and unlocking a lot of eye peas in combination with augmented reality games let's set the stage in terms of the hardware and software what are the advances in technology fundamental technology that are enabling this augmented reality to make its way into the masses today I think for the most part it's sensors camera and and motion sensors on devices there have been some companies like upset that have been in the space for a while and they just last year released a headset with a sensor bridge on it that allows you to do some some pretty amazing things very similar to what you can do with AR kit for example I think bringing it to the masses is starting to happen because the devices are the phones that people carry around in their pockets have sensors that work well enough and then that on top of that
 computer vision and algorithms and chips cat that can do those calculations quickly enough to serve calculate the devices bearings and relation to where it is in the starting point in the real world space really brings that technology to people that have like phone cameras did a decade decade ago kind of interesting to see the thing that's really exciting is that when iOS 11 launch is there will be something like a hundred and sixty million they are like natively are enabled devices just out there so craving that install base I think is one of the most exciting things about this particular push I've seen all these videos online
 of a Arc at the pre preview stuff of a Arc it cuz it's so I think where we are today with with a arcade this actually I guess we should just start by why don't you guys explain what a Arc it is Trifecta it's an SDK that Apple launched at WWDC couple months ago that wraps up computer vision and camera sensor features combined with core motion into a set of pretty easy to use API is that allow you to start a session with a session-based API you can start a session you can then monitor the the state of that session then when it when it discovers it's bearings in in a 3D space it'll call back to the application code and then you can use any number of rendering 3D content creation or 2D content creation engines to inject your own content into the scene and a
 2 points in plain sight in the scene that they are kid has discovered and of course it it handles just as importantly it handles the the movement of the device after the session is started so it keeps those that your digital content locked to anchors in the scene as you move around which gives the illusion that the content is really there as you move around the table or or have the content animate around in the room
 so what I've heard is that the next iPhone is likely going to have some laser systems and some more advanced sensors and that's going to make it even easier to track stuff around the room like track horizontal planes around the room so that you could display something on top of that horizontal plane like a dancing hot dog or a piece of furniture whatever kind of whatever would make useful sense depending on your application you know it's going to get easier but today it already looks pretty good the stuff looks pretty good so is is the current model of detecting a scene or or understanding the same as it is at all just computer vision is it more computer vision that it is about sensors and Depp I think it's both working in concert so the computer vision part comes in and in the context of recognizing a scene and getting the initial bearings and you're recognizing that you know there is a horizontal plane there's a table in the room
 come and there's an object on that table and there are points on the you know on the object that are closer to the camera and then then the table itself and just kind of creating the app that's called a point clouds establishing that point cloud and optionally horizontal surfaces and then the motion sensors come into play once you start moving around the scene so that helps you maintain the location of contents in the scene as you move say no to me backwards from where the session started or whatever Direction up or down and as you rotate the device around 3D space today the motion sensors feed into it they are kids allowed to do that part yeah and thinking blue sky like far into the future the ways that this could be even more handsome is to have better just awareness of on the device of what the environment looks like so right now in terms of image detection mostly it's been focused on like rectangular surfaces
 tabletops but being able to Galaga 3D Volume of your environment or the room would definitely be kind of like a holy grail of Elise from the hardware and software side being able to do you know like very in high fidelity simulations
 we talked about some of the abstractions that we need to be concerned with your horizontal planes sessions scenes could you introduce us to the vocabulary that we need to know to understand and talk about augmented reality do you mean the vocabulary in the context of the AR kit DK specifically or just more generally I think both sure that they are kit API like I mentioned is a session-based API so you can figure a session instance and Passyunk configuration and the configuration allows you to specify things like what kind of tracking the tracking of another key word here you want to do and they're there two types of a tracking available and they relate to the degrees of freedom that the device can track him so three degrees of freedom can be achieved on any device that supports AR kit so we're going back to the successes
 and that got the A9 chip so I'm on those devices you can at least look around so you can kind of have a station you can imagine a stationary camera and have it look around in the space and then more modern devices with faster chips can be configured with a 6 degree of Freedom session which should allow you to not only look around from a singular point in the space but also move back and forth in its ordered like we were talking before so that's the session in addition to session their objects called anchors which I really key I think because the anchors you can hit test for them so you can touch the touch up 2D space on the on the screen of the phone and hit test for tankers in the 3D space and then get a set of anchors backs are ranked from like farthest away the closest to the phone and then use those anchors to attach your your 3D content that you put into the scene I think beyond that start to get into some of the things that they are kit doesn't do so.
 kids a little bit lower level in the applications plugging things into it for 4 Graphics so obvious one would be seen kit or Sprite kit for 3D or 2D Graphics respectively and then also I know if you want to do something with no geospatial like latitude-longitude injecting content into the scene not just in meters away from where you are but translating a latitude and longitude to to a distance in meters away from the scene that's a kind of kind of thing we're thinking about but the it gets really interesting when you start thinking about what you can plug into it which kind of leads to it to Unity which is what we've been working on here to speaking I guess moving up a little bit in the stock towards like hunting creation like kind of the glue that this allows us to delve into is doing like more traditional like CG computer graphics
 3D animation techniques thinking about the a r k camera in terms of your 3D camera there's a nice level of abstraction we're setting up an AR camera within a video game engine like Unity you're allowed to treat it kind of like you would any other video game camera as a thing that moves in 3D space and you said that 3 environment around that camera and all the content kind of locks into place and so I think in terms of vocabulary and things to think about as creative as we're creating. They are content and they are applications one of the things that will be interesting exciting is like they're there are a lot of like techniques and methodologies for animation and video game creation that will kind of overlap very nicely for AR content creation
 gramatik code sonar helps development team improve code quality with static analysis it helps flag issues early in the development process allowing developers to release better code faster code sonar can easily be integrated into any development process Advanced static analysis of C C plus plus Java and even raw binary code unique data flow and symbolic execution analysis to aggressively scan for problems in your coat just like battleships use a sonar to detect objects deep underwater Engineers use code sonar to detect subtle problems deep within their code go to go. Gramatik. Com SE daily to get your free 30-day trial exclusively for software engineering daily listeners
 coach sonar analyzes your code and it delivers a detailed report the code shown are user interface provides all the information that you need to quickly understand the reports follow cross-functional understand cross-references quickly navigate between files and visualize large pieces of your code go to go. Graham attack.com SE daily to get your 30-day free trial and at least the power of advanced static-analysis thanks to grammatech for being a sponsor of software engineering daily
 okay well we'll move up the stack in more detail on a moment I'd like to get both of your subjective experience working with a arcade or working with augmented reality on Apple devices you know I think we have different experiences with different Frameworks that we use for the first time I know the first time I used a certain a certain framework that I'm just not going to name cuz I want to insult anybody but this is really painful and at the end of the first time I used to react it was really fun and pleasurable which is totally depends so what has been each of your experiences getting acquainted with a Arc it a little bit more space here but most of all of her in part because I really enjoy working with Swiss Apple API is a nasty case I find them usually to be really well designed and nice to work with
 AR-10 is is no exception currently that the surface area of the of the guy that you have to learn understand is relatively small it does it does what it does really well and like we're talking about before there's these Notions of obsession and anchors and then it really delegates to other libraries so the complexity would come in and Matrix math utilities translating transitioning objects around in the scene and I using an entirely different library for 4 Graphics rendering I found it to be really at the joy to work with and took to work surprisingly well like I compared to some other somewhere libraries that I've I've seen all of them but experiences that I've seen on the internet from other projects like Google has with Tango and even up some of the other no dedicated Hardware experiences if it works as well as
 most the time to some as the other dedicated more expensive Hardware that is really unwieldy compared to know just the phone device that you have in your pocket already
 yeah I'm speaking from the unity side I started working with a Arc it via Unity plugin so it's essentially findings in the images directly to the air Kip i c k when you bailed out to an iOS device or application and yeah I found the experience to be pretty enjoyable like pretty easy and painless the workflow generally is that you treat kind of how a Unity or game developer would interface with their kid is how you treat the serca camera as your game camera and so once you have that Cameron place you'd feel just being around that and some of the things that were some of the challenges that we ran into were mainly with like world scale scaling of your objects in 3D is a different when you are making like a traditional game that's played on
 I'd recommend the phone that's not a are you can kind of have full control over what the units mean but when you're working with a r kids Special considerations for the units in the game engine I'm being real world units and how that affects things like shading and lighting bottles are things that we have found that we have to consider not necessarily entirely new challenges but just like a specific subset of Graphics related things to keep in mind as you work in the air kit Cube rotating in your living room looks really really big sometimes it's disorienting as you're as you're learning and experimenting with it in playing around you just said that that I found so far are dealing with occlusions and the illusion of of the content can get sort of ruined when you can see it through something that's physically in the room that you had a chameleon
 normally and get that where actual real content or for a real thing in the world you expect to be hidden by the other thing in front of it sitting around this using horizontal plane in conclusion what you can do now but example of be like maybe you you build a little app with a robot that that travels around on the on the floor which is one horizontal plan but it moves under the table which is another horizontal plane and unless you write code yourself to stop rendering the robot when it moves under the horizontal plane that's closer to the camera then the floor you still see the robot through that through the table so kind of wrecks the illusion that the thing is actually in the room when it when it starts to bleed through the other in a real-world objects again sort of solvable for four objects in the same room as you if the objects are horizontal surfaces but I think you mentioned before that the rumor of of new hardware is fall with the laser
 which a potentially allow for vertical detection and therefore a vertical plane occlusion which would be really nice to have tubes currently with a our kid at least there's nothing there's no way to detect vertical surfaces which is limiting people on Old Hardware would have a different experience of an AR product then people with the brand new hardware not exactly yes I know that he go back past 6s just speaking and not thinking about iPads and iPhones for example of its kind of either have it or you don't so free 6s you can't use AR kit 6s enough you can the difference is I think the difference between an iPhone 7 and 6 is that you the degrees of freedom of of camera and plus moving around in the room I was just going to talk about before so and then on the latest and greatest devices with an A10 chip you can look at your content
 and walk around it and look underneath of it and you move away from it and see it gets smaller and bigger on an older device that still supports AR kid but you would only be able to see the contents are stationary in your room and move your phone up and down and you would see that the the content move up and down in your screen but you wouldn't be able to like walk closer to it because the phone can't track your your your movement in relation to where the content is placed originally in the room but as far as like so that you can add anchors to be an arbitrary objects in the room or place them on planes that that all works no matter what Hardware using the day as long as it Hardware support say Arquette
 now I know in VR experiences if you get something wrong it makes people sick but at least what I've heard about with regard to like you know the hardware is not good enough or if there's some mistake in the stitching algorithm where they're trying to stitch together the virtual reality environment if something is off people can detect it and they just get sick does that happen with these AR kit experiences the difference between a are kid and VR experiences is kind of like physical and hardware-based so Parts part of the reason why people get sick in VR experiences is that those experiences do cover your entire field of view and you're also looking at something that when you look at them that takes up your entire field of you your cognitive like your subconscious like cognitive
 processing is very sensitive to things like that so I things like refresh rate and resolution matter a lot more but what we're seeing where they are kids specifically given that it's on US-23 screen in front of you that's not a surly taking up your entire field of you a lot of those problems are donuts in early present themselves in the same way it does there are things that might like break your sense of immersion in it they are if they mention that like if you don't do occlusion properly things might not look like they're situated in the real world but as far as looking at a screen on an AR get those like motion sickness type issues with VR don't ask silly carry over but when you get into things like AR glasses and I wear I think that's where are like your visual in like Oghma live senses come back into play I think the bigger problem may be many many millions of years and not just Early Access developer
 people holding up iPods walking down the street and running into telephone poles or something like that cuz it's it's very very much about moving around but but even then I think that way but it's really designed for is tabletop visualisations of like a game board or some sort of animated object like a dog or a robot moving around in a in a in a room like the size of your living room and it's something like so you just said it's something that you have to hold up a device in front of your face to be able to to see to see the scene so it's probably in that sense a little bit easier to use and less likely to make you sick incredible so I was under the impression that we were going to need
 AR glasses to have really compelling a our experiences but after seeing these things on Twitter like there's a Twitter account is made with ar Twitter account I'm sure I mean it's just a Content aggregator basically but it's really cool people want to see some like some samples of the coolest AR stop why is so cool but if you have not seen a our stuff you should stop is podcast right now and go check out some of the AR kit stuff it's it just breathtaking to be honest and it makes me feel like okay glasses are going to be great but do we actually need a our glasses to have what is essentially like a platform shift like what I would consider as important as a platform shift what are your guys thoughts on that like if people are just like let's say no cuz there's also rumors about old apples going to release classes by the end of the year whatever maybe it'll happen
 I coming back into the four maybe Google last will become a consumer product soon those happens in the next year too and we just have a our applications on our phones is how impactful is that like how important is that yeah I think it's a super important stepping stone I think I personally think that they are glasses will still be compelling in terms of use cases I think one of the good things about AR kit and the demos on I like iPhones and iPads is that it's very easy to share what that looks like the like a video or an image it's much more difficult to express or to actually like represent what an AR glasses experience actually looks like via video or image which is why I think like it hasn't it's harder to catch people's imagination or get people excited about that type of experience I think especially in the next year or two with AR kit on screens it'll be a very important way to grab people like mine share about
 what is possible with a r I think especially with you know the kind of a our conversation that happened a couple years ago around glasses like I think people are hesitant to or skeptical about the kind of how impactful an aerospace can be in like how useful or possible they could be so I think like one of the really tiny things would be till like show some actual like really practical use cases for AR and getting people excited about a are used to it before you know like the classes arrive probably have to wait and see what the hardware looks like and how head of intrusive it is in in people's lives but I'm interested in because of thinking about location and kind of like what kind of like pushing it a little bit when we think about location and an AR in AR kit again cuz they are kidding I think was kind of Biltmore for the tabletop like in
 use case but if you start thinking about use cases for walking outside and wayfinding and tourism apps like sort of taking taking the idea of being able to hold up a nap and see what's around you and expand on that a lot more adding a lot more day two layers like what we haven't met box I think it would be for me really fun and interesting to be able to have that experience outside without having to hold up a flat screen in front of my face to do it but again I really have to wait and see and like when an f and the hardware comes and what it looks like well let's talk more about what's going on today I want to work in a conversation about unity and then we'll get to map box and some of the things that people are actually building including yourselves we glossed over Unity a little bit but I know Unity is a 3D basically you can make 3D models in it and do other three things that maybe 3D animation
 can you explain how Unity fits into this conversation and what is the unity SDK that works with a Arc it it's an is to enable like specific class of content so I think Jesse mentioned earlier that working with the native iOS SDK it's would you describe it is mostly like a 2d kind of focus in terms of creating content working with ar kid in xcode requires that like the gear it's basically just working with code compared to looking I think right I know where you're going like when you experience yeah and that doesn't really exist the next put it exists in terms of model creation but but not not like what you're doing if it's in his I think it it opens up like different class
 applications be able to be developed so working with like inherently like 3D techniques 03 models 3D simulations like particle systems physics emulations it makes that a lot easier and lower the berry Ventura a lot to creating air content using those techniques and those systems and yeah you don't have to necessarily like the interaction becomes not for the developer at least isn't necessarily like working with lines of code but the developer are more alike in that way and the unity AR kids kind of plug-in essentially are just hooks that combined the same like API calls that are available in the air like the native iOS AR kit SEK into being accessible with in unity so controlling the unity camera via a Arc it is essentially what that,
 blocks
 okay so what have you used this Unity AR kit plug-in for like kind of give a breakdown of an example of how it's used and I guess you can have the abstraction layer to put together
 as a user I can speak to that so I created a a scene I think it was last month of some location in Hawaii so using rs2k at that box I created a 3D scene there was a train Mash of a beautiful looking Cliff overlooking the ocean in Hawaii somewhere that scene is completely possible to put it in a game or than the traditional sense of unity allows you to publish your content out to xcode or Android Studio it actually generates projects for you so you can play that content in and look at it on the screen like you normally would using the AR kit combined with you at the unity the map box that rain messed Unity seen that I made I was able to express how I want it What You observe where I wanted that to appear and what size I wanted it to
 in the in the air tonight scene and then place it in that scene and can I guess it really just allows you to bring your classic 3D content that you create in unity into an AR kit seen on on an iPhone
 cloudflare runs 10% of the internet boosting the performance and security of millions of websites you probably already use cloudflare on your sites but we're not talking about using cloudflare today we're talking about building on top of it if you're a developer you can build apps which can be installed by the millions of sites which rely on cloudflare you can even sell your apps they can make you money every month
 your users can login or register to your service inside your app they can get a real-time preview of your tool live on their site and they can start paying you monthly all from within cloudflare apps they can go from never having heard of you or your service to having it installed on their site and paying you in seconds visit cloudflare.com SE daily to watch how you can build and deploy an app in less than 3 minutes that's cloudflare.com SE daily thank you to cloudflare for being a new sponsor software engineering daily
 okay well let's let's go to the map box because that's where you guys work and I think there's some very interesting Integrations across these different tools that were describing cuz I think we're kind of taking a scattershot approach and then will bring them together to explain what map boxes and what kinds of applications people build with matte box like a location services platform and so what that kind of tales is everything from Matt what maps to geocoding which is location search to directions and routing so that's like driving directions walking directions and biking directions as well as satellite imagery and we also have excess wear platform you can host and manipulate that data on the map box platform and to get access to that platform we are like we're SAS company so we have a rest API and then we have various like web native iOS
 Android and unity sdks as well as a few other I CK's to allow access to that API and all that data and the our web platform
 a lot of people in the mobile space come to us for an alternative to Google or Apple Maps SDK that they can drop into their their applications and they do that because the maps that that we provide by those those SDK clients are I really highly customizable so like literally every pixel of the map everything love all you can customize to be whatever color what you want to go use whatever font you want you can inject content into the map and maybe even more importantly can inject data into the map on likes to use the host host that kind of arbitrary data servers are on your own and the map when it's rendered on the phone is right here is a map and the user sees that there's a lot more behind it so all this arbitrary of data that you've associated with various points on the map can be. And rendered in different ways like 3D buildings and with the of various types of overlays for for data visual
 am I think that we've seen on the unity side is we store all are a lot of our map data as Vector data so using kind of polygons points and line segments to build out what constitute like Rhodes building a lion's points of interest things like that and since Unity itself is a renderer we've seen you need developer is really take that data and really manipulating ways that are pretty low level on customizable for them and so it's been interesting exciting to see what happens when you give people access to that low level data I know this conversation is mostly about a are but I'd love to know a little bit about how map boxes built because you thinking about it more it seems like a really complex API tool set to build you know if you're doing things like building really detailed maps and you know
 hey guys I guess just talk a little more but how how like how that's what it what goes into building a mapping SDK it sounds like so much of data that you have to keep updated for example like I know Google Maps for example I've talked to some people who work on that I think or if it listen to some interviews about it and it's there's so much upkeep involved in in keeping location data up-to-date and and so on you can just talk about like how engineering at mapbox Works in and how you keep an API competitive with Google and apple you want to talk about maybe serve leading up to the SD case and openstreetmap and stuff and I can kind of take it from the from the GL & Noble side sure yeah so below Benton AR platform team and our satellite team so this is so I think want me to think about that box is just there are like the SE kaise that give access to the DA form and in the pop of myself
 a lot of back in service I programming so for our kind of map data we Source are GIS mapping data from a number of different sources of the largest one being OSN which is open street maps it's kind of like a Wicca PDF but for map so individuals can go and contribute not being in location for their neighborhood or municipalities wall sometimes I upload their looks Epic Records and we also have a large data team that contributes stayed at to open street maps as well and so we have a pipeline to ingest all that data on like a constant basis I think the turnaround time for something being live in edited in osm to being live in our mailbox map says something like 10 minutes so it's a constantly updating kind of live map that we are we do QC and validation on and that all I see is Ada is hosted on AWS in like a g is based a database and
 so when you make an app request each arm apps are broken down into individual tiles based on where you looking in like what level of detail you're looking at and so that goes into AWS and sends you kind of the tiles at your request and those tiles get stitch together by the renderer weather that's your browser weather that's the Geo Bender in one in our native sdks that gets together as a mosaic to make a map on the satellite imagery side and also far to be like roster maps and said about your data that's all like roster images that we store and are delivering to u.s. individual raster images that gets pieced together just talked about at the end of the day that you know everything that is the backend is kind of communicated to the mobile SDK is in the form of a vector tiles which is a way of describing to the mobile SDK rendering system what information that needs to know to be able to to draw the map so instead
 just sending images over that make up the map and stitching them together it sends a compressed data stream is as turned into drawing Primitives by the by the rendering engine and then those eventually form a map and all of that coat is in a cross written across platforms cplusplus implementation for for the native mobile side so are Android and iOS and cutie cute platform bindings all share that that coming Hood Base main job is interfacing with opengl and drawing that the map and then that that imitation is wrapped in platform-specific code an api's to make it really easy to use so instead of having to take R R C plus plus cross-platform engine and plug it into their mouth they can take that wrapped up in a nice Objective C plus plus rapper in on iOS for example
 not your gets exposed very nicely and in a swift API so it feels a lot like the kinds of of map SE case you'd be using incumbent on the platform like Apple Maps and and and Google Maps API eyes and I think it kind of goes full circle so once developers take the map SDK and use it in their application for your showing a map that information that the way that users interacting with the map pack the problems that they're having so we surface waves for end users to be able to no issues with the date of that they're saying there's some anonymize location data that sent back that we use for things like traffic report traffic speed and things like that kind of contribute back to her or navigation stack so it's really I kind of see this environment where they know what's happening on the start of the day that I've sent to the server and used by the maps sdks on the on the client side map applications on phones is kind of intern the plug behind the date
 kids are able to get from from end users is plugged back into the system and it works really well that way so why did I mention that focus on that part was always on maps other parts of the platform include like Jay location searching so that's geocode searching and sharks and routing and one of the things that were thinking about especially in relation to a Arc it and they are in general is kind of thinking about location services in more than just rendering a map and thinking about like places and points of interest as kind of geodata that people are interested in that don't necessarily be I don't necessarily need to be rendered in the form of what you think of as a traditional map to some of the things so the information that is available in these better tiles are also like metadata about buildings I like the name of the hotel you're at the address of the hotel also like the any parks that are near you we call that like land use so Parks waterways Lakes
 things like that are all available to us data and so thinking about how to render that data in a way that doesn't look like a traditional map or like in ways that are fed to your information via AR is something that is exciting for us explore as like a platform many reasons why I would want to use a mapping API with augmented reality for example let's say I'm running an application on my augmented reality glasses and I'm just walking down the street and I want to be able to see interesting things they are a long way you could eat like you mentioned at the I think there's a Yelp application that where you can basically hold your phone up and see information about different restaurants around and I mean the reason that you know where those restaurants are your smartphone knows is because it's using some sort of mapping API and it knows your location or at least you can tell me if I'm wrong it knows your location
 what's your geolocation relative to the original location of restaurants that you're looking around at so that it can serve serve you know information that superimposed on your on your vision talk a little bit more about the integration between augmented reality and mapping and how that translates to project you guys worked on so copper tooling company so we want to make it easy for developers to to make those kinds of applications and I think a our kid is a is a piece in the puzzle that now allows us to build our own STK is and hands hurt libraries on top of so you know that that Yelp application and other similar to that were relatively difficult to do without larger engineering teams or or bigger budget with a Arquette and data and tools from from naproxen and others I think we're really going to see that that kind of use-case democratized and
 a lot more easy easier for people to access and I think we've been focused in the last few weeks at least I'm thinking about specifically about libraries you additional missing pieces that we can add to make that kind of thing easier an example of that would be what they quit they are kid like we talked about before the session is started in the assuming everything goes well you can tell where it is with respect to where the session started and that's near that origin is at 0 0 0 and 3 of X Y and Z space but as the phone moves around any of the Delta from where it started as noted in meters but if you wanted to draw a breadbox over the top of the building that's visible in that scene that Redbox may represent a building that you have from that map data that is expressed in the latitude and longitude so the challenge then for the developer would be to say while I know where I'm at and latitude and longitude and I know where that building is in latitude and longitude
 how many meters is that away from where I am what direction what's the bearing of that point in space and how high up how tall is it above ground level and how tall is the building in do I want to have the box float above the building or in the sidewalk right in front of it and do I want the box to have survived label and what kind of information do I want to to say about the building so all of those types of things are those are the kinds of tools that we will build that it to make using mapbox data to augment AR kit actually really easy to do and then you're then we'll see what what developers build with with the things that we can make to make their lives easier
 and yeah it's kind of like a high-level the way I've been thinking about it is that a our kid is really good at creating experiences based on another room you're in and the kind of environment that's a media in front of you but I think the really compelling about Matt box is that it can provide you with a contraction or formation of the world that goes beyond that room so like things having down the street things happening across the city across the world and connecting bat to a Arc it is kind of where we're at and what we're thinking about as a team right now
 well let's zoom out even further and talked about the broader implications of augmented reality and how this is going to look over the next couple years the first of all speculation do you guys have any understanding of where the go to what the go-to-market strategy is going to look like for augmented reality like if you have any ideas for apple is going to roll out this stuff how Google is going to roll out the stuff and maybe the implications for developers were thinking about jumping into the space I can think of a few opinion is that what's been made available to the offers right now is to purposely been put out there to is kind of a test it to see what happens in to see what kind of content people create in the kind of warm up warm up the market a little bit I think I think it's really good in a lot of ways like I'm looking forward to the App Store this fall on the way that I said I haven't been in a really long time because I think it's going to be a lot more
 like it was back in 2008 when they were just kind of a lot of goofy silly things that people are making and people are just going to kind of explore the space it's every time your people have been working in the space for a long time working really hard to make this possible but the fact that it's going to be so easily accessible to so many developers is going to be really interesting to see I think I am I think will be a lot of things that have come and go but over the course of the next year or two and even in the complete absence of any lasers on phones or special glasses I think that probably start to see some focal points in that market and some some really interesting use cases as far as that goes like from the software perspective I think that games as an obvious one that's been talked a lot about already I do think that even though it's a little bit of a stretch to serve outdoor outdoor points of interest finding what we talked about as interesting but also wayfinding and yellow certain use cases for for navigation at least pedestrian navigation maybe even by
 that may be a stretch without the right kind of hardware and then as far as a larger go to market strategy for the platform Fighters I do think it'll it'll probably come clear as the the market to reflect what kinds of apps make sense in this space and and what don't but your real dedicated Hardware that doesn't look too silly that it's that allows you to experience this these applications without having to have them so obstructed like they are now sort of the screen with people have been working the space at the smaller companies not Apple and Google I think they're excited by the prospect of this as well just like getting more developers interested in a r is good for them because you'll have more people thinking about the techniques and the use cases for AR and just having more developers that are knowledgeable in that space will help I'd like the
 independent like hardware and software creators for a are simply like a like Rising tide raises All Ships situation different tool sets that are important to the world of augmented reality AR kit Unity mapbox what else is changing in the developer tool space that's exciting to the two of you in regards to a r and location at mapbox the ones that you just mentioned are probably the most important to us I guess I'm going to see to watch the gator that you asked me for them. They are kids feeding and see what people are doing with him think about what did they use to do it like I have some knowledge of how I place content in in from the physical world
 on the scene but there's something was out there that are really truly amazing I think if they're probably be at pieces to the puzzle that I just don't know yet exciting because they are we are at a point where that's easily accessible to a large number of people are both on the development site in the end-user side I think one area that will be interesting to see what comes up is more ways to interface in a are right now it's like a touch screen but things that I've seen around or like a stylist or one that allows you to allows like the device to get feedback either you know through motion or like through camera detection another kind of input devices I've seen is like a ring that you can scroll with so yeah just itself is a new kind of interphase and just thinking about more ways to get feedback
 okay so the clothes off you don't have kind of a random thing that I want to do I don't have it done in the past but they are such a big shift in you guys have been thinking about as much as anybody lately so I've just got kind of like a rapid fire thing five or six topics and I'm curious of how you think augmented reality effects each of these areas so maybe you guys could could take turns respond to these I've got like 6 or 7 let's just go through them real quick okay so first of all YouTube I can't think of a way that YouTube changing too much other than as a place to to share the kinds of things that you're doing yet they're like a gxr content sharing platform if you're wearing glasses you can like be watching a YouTube video while you're walking down the street and not interrupt that not the safest thing but I do way to interact with YouTube
 side note I walked into a telephone pole earlier this year when I was looking at my phone they are glasses too I've seen some horrible videos of people getting into accidents and it's too but so you see more people walk in the Philippines right you're saying is to do like remote podcasting so like you could have an avatar or a person from a visual perspective you can kind of like hollowgram in someone and doing podcast remotely but having both people show up on the same screen
 advertising I think probably I we've already had already seen some maybe they are kid demos about advertising but I think it'll probably be a potential explosion there where applications existing social media applications that have advertising platforms will allow know what will make it possible for advertisers to to post content flexor like billboard by content in the real world I'm sure they could be gamified to and people would probably be at least have some sort of scavenger hunt to find something or see something about a brand projected in it in a 3 space where you are summer in the city that you're in a billboard that shows everything two different people
 okay so lastly how do you think the the augmented reality shift will impact Snapchat and Facebook and will they respond to it in the same way or in different ways kind of already in the game especially in the with Facebook and Instagram and Snapchat Snapchat users are encouraged to to use augmented reality to filters to decorate that the damage isn't and videos at their that they're posting so I think that that won't change cuz it's already happening I just think maybe it'll change because this the sort of thing will exists at Lee easier for developers to add two other applications so it'll be just a little bit more normal like a larger base of users will be more comfortable with with adding that kind of content into their applications and I can kind of getting back to advertising maybe a larger set of advertisers
 would be interested in an augmented reality intent on on those applications and I think probably the way that Facebook and Snapchat are thinking about augmented reality is that creating like a more passive user interface so that you know and users are constantly engage in the platform I think that's something that Snapchat especially it tries to do more of of getting a user's bore like opening up the app all the time so like if you were in an augmented reality kind of future where people always have are used to like having interfaces that are always on Facebook definitely you know is a logical Choice there but like any Snapchats would love to be like in that kind of conversation as well as well it's been great talking to you I have really appreciated the range of topics from the map box to all the engineering building blocks to your speculations on the future so
 I look forward to seeing more out of map box hopefully more demos related to augmented reality
 look for a job more efficiently with indeed Prime indeed Prime at flips the job search model and lets you find a job more efficiently even while you're busy with other engineering at work or coating your side project you simply upload your resume and in one click you get immediate exposure to companies like Facebook Uber and Dropbox the employers that are interested will reach out to you within one week with salary position and Equity up front don't let applying for jobs become a full-time job itself with a deed Prime the jobs come to you the average software developer gets 5 employer contacts and an average salary offer of $125,000 through indeed Prime it's a hundred percent free for all candidates there are no strings attached sign up now at indeed.com SE daily
 thank you to indeed Prime for being a repeat sponsor of software engineering daily and if you want to support the show while looking for a new job go to indeed.com SE daily
