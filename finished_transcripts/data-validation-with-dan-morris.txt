Transcription: data validation is the process of ensuring that data is accurate in many software demands an application is pulling in large quantities of data from external sources that date it will eventually be exposed to users and it needs to be correct radius intelligence is a company that Aggregates data on small businesses among other things in order to ensure that business addresses and phone numbers are correct radius uses human data validation to ensure that their machine gather data is correct on today's episode shrenik automata host an interview with Dan Morris about human data validation and how it fits into a machine learning pipeline before we get to this episode some quick announcement if you would like to advertise on software engineering daily send me an email Jeff at software engineering daily.com there are 14,000 Engineers listening to the show everyday so it's a great place to advertise available jobs are new
products and if you're a developer looking for an open source project to work on software engineering daily Community has been working on a project called software daily we're building an open-source news and information site about software if you're interested in that check out software daily.com he's also check out software engineering at daily.com to join our slack Channel you can search for old episodes you can check out the back catalog or you can sign up for our newsletter software weekly with that let's get to today's episode data validation with shrenik automati and Dan Morris
life is too short to have a job that you don't enjoy if you don't like your job go to hired.com se daily hired makes finding a new job enjoyable and hired will connect you with a talent Advocate they will walk you through the process of finding a better job it's like a personal concierge for finding a job maybe you want more flexible hours or more money or remote work maybe want to work at Facebook or Uber or stripe or some of the other top companies that are desperately looking for engineers on hired you deserve a job that you enjoy because you're someone who spends their spare time listening to a software engineering podcast clearly you're passionate about software so it's definitely possible to find a job that you enjoy check out hired.com SE daily to get a special offer for software engineering daily listeners a $1,000 signing bonus from hired when you find that great job that gives you
respect and salary that you deserve as a great engineer I love hired because it puts more power in the hands of Engineers go to hired.com se daily to get advantage of that special offer and it's thanks to hired for being a continued longtime sponsor of software engineering daily
 so you give a caucus work Summit 2016 I'm using human data for validation for people haven't seen it so the big premise there is that so much about my dentist science is predicated on this idea that she learning is this magical wizard tool that can solve all your problems and largely true but it operates on the assumption that you have really good quality data
 and in the world that we working with business data firmographics no contact information that sort of stuff that data is very rarely of the cleanliness and caliber that you actually can just plug right into a machine learning algorithm sell a big part of our day today is making sure that we do have awareness of how good our data is and that we can prepare enough of it and it was Queen formed that we can actually train machine learning algorithms to bridge the gap between a little bit of validation and the full Universal validation which is really incredibly costly in human cat talking through the full data Pipeline and where validation kind of fits into that whole whole process the company is a predictive marketing company
 ultimate product is designed for businesses to better identify the customers that they might Target effectively from the universe of all possible customers so to do that the engineering team has to build a graph of essentially every business in America so that we don't need to rely on our customers data for future Rising business records and so to do that we start with data from tons of different sources well it's not tons but near dozens and each of them has their own opinions each of them has their own source strengths and weaknesses at the types of data that they specialize in delivering and so are challenges to sort of consolidate all of that into one canonical source of like ground truth or at least our best estimate of what that's worth
 untruth of all of these businesses is and so the validation part comes in because we need to we didn't know what what how much of our sources are actually giving us accurate data which fields are more accurate than the others which sources are better at certain fields in certain values and as well as on the end of the pipeline how good are we doing you know how accurate are we at kind of preparing this final version of Truth and is it better than our sources are in generally it is that's kind of the whole point otherwise what are we doing
 but that's as far as the actual pipeline goes we essentially take the raw data from all these different sources of course acquiring it and parsing it and cleaning and sanitizing it is is a big part of the early stages of the pipeline and then we build a graph of all these different records to actually match those together which belong to the same business with these sort of subgraph so we can create a single instance of business and then resolve all of the differences in opinion about the attributes of that business was we have that in place and we essentially have a single record for every business in America for every business location I should say I'm there we can build another craft that actually joins the businesses of the same company of the Apes are the locations of the same company together based on their shared attributes and then we have not only
 all the business locations in America but also the other companies and organizations and a bit of understanding of their structure in the relationship between each other
 so how does the others there's millions of small businesses in United States how do you how do you do validation on moonspin solecito do the mall so what kind of statistics and what kinds of techniques do you guys do to understand like a good this source and this property this lucky no sampling some amount of it is is enough for you to manually yeah well I mean it's kind of a classic confidence interval problem so the the statistical estimate of how many do we need to sample to have this confidence intervals pretty straightforward then the challenging part there comes from like knowing if we can just truly sample randomly if it actually there are some sectors of the economy that matter more to us so it's kind of where the product management kicks in and it's more than just an academic problem because of me
 you know restaurants are a more valuable Target to our customers who are buying large trying to Market to a really broad range of businesses so restaurants or other service providers are other kind of companies that are more valuable should kind of be weighted more heavily in our accuracy estimates if we're connecting the scientific accuracy with product accuracy it is that we don't have to sample and validate everything some of our smothered like date of providing companies
 they don't have machine learning they don't have data science have just a mess of call center and so it'll actually get phone numbers for all of these new tens of millions of businesses call them all and some sort of a monthly or yearly recurring cycle ensure like if you can have confidence that your validation procedures are working properly then that is a reasonable way to ensure accurate data but it's very expensive and it requires that you keep doing it because I did a grouse tail over the course of weeks months years and so it's only as good as the last time you validated it but because we can validate a small sample and use that to actually create training data and then trade machine learning models to sort of score and predicts each of these values that we want to assign to a business
 Alexis have comprable are like even better accuracy and to do it every week every two weeks when we build a new snapshot of base of the entire economy so I think our meth is better and I certainly in keeping with the trend of data science machine learning as the kind of better way to handle a lot of these complex business problem right yeah that's what I'm really trying to combine the best of can I see the signs she learning with what do humans can do well obviously in a lot of recipe for new companies are new efforts is like look at it areas where the approaches are either completely data science oriented or completely human oriented and but they're not really kind of marrying the too well for sure yeah there's probably a lot of companies now they're starting to do sorta like human in the loop machine and whether that's purely in the way that we do it kind of valid
 where are these questions are not something that you can just point your machine and say is this the phone number you have to actually have a human interact or whether it's looking me the picture and the human says watch picture of a Welsh Corgi versus a golden retriever next time I try and classify dog picture I'll have a better sense of it and kind of aggressive a good way you guys are on using both techniques to complement each other well so for example I really like that you guys even use machine learning to to go the other way which is basically try to understand how could a human validator is thought I was really interesting for sure
 and that will talk about how there's a huge difference between 95 and ninety nine percent accuracy would say like voice recognition or image recognition that's difference between like a cool trick that you can use and something that you would like use in every part of your daily life and if you like it kind of the they actually created accuracy metrics there for like human recognition of speech and finds it now like machines are actually starting to surpass an actual human accuracy
 which one is speaks this idea that like yes humans are great we are them the word designs to to be humans were not necessarily designed to solve certain kinds of problems were very adaptable and we're very flexible so we can do a lot of different kinds of things but over time we're learning it more and more tasks are can be better done by machines the point of accuracy of a lot of that is predicated on the fact that our human validation is our source of ground truth and because we can't trust any of our individual sources to be grounds tourists are all flawed and various ways certainly are validators are not perfect either but because we are using them as ground truth we have to be as
 like diligent as possible about making sure that the accuracy they have is close enough that we can consider that you know rightfully so yeah I got a question at the end of the talk that I was actually kind of pleased to get because it was something we really thought about a lot and that is well we can't expect all of our validators to be perfect in fact we may not even really have personal relationships with many of them because they are on a team and we work through the manager of that team but if we want to be really sure about some value that were validating does it make sense to have 3 different people validate the same information independently and then check to see if they all agree on it well yeah that that is effective but it also blows up by 3 and so
 AA way to reach that goal without having to linearly multiplier costs it's too how to test the validators upfront with test questions if they're you know what is 100 examples they validate you know if their first hundred we actually seed 50 of those with things that we already know the correct answer too then we can determine how good they are that task and if so if they come through with flying colors and they get everything right or close to it then we know that that that they're trustworthy and so we can trust their further answers alone without having to have some sort of agreement with other about it that's exactly what you just described and maybe because again they can afford to do that cuz it's like freezing Mechanical Turk and it's just like simple five cent Ten Cent ass not that big of a deal that's it I was just the same
 play some people with the same task and see if they agree but seems like this is a much more effective potentially technique when actually you know passes quite expensive to get to the scaling problem like it's ever everything that we do as we don't really large scale and and linear doesn't really cut it in terms of cost terms of time so we have to find ways around that another interesting thing to is that given kind of the nature of these human validation problems let's say we have a people are making phone calls to businesses you have 3 different people call the same business and ask them the same kind of questions these are not customers of that business they're not they're kind of in a sense wasting a little bit of that companies time
 and of course I want to minimize that part of the design is that we want our our validation questions to be as quick and painless as possible both because we don't want to waste anybody's time that much and because we wanted to be really clear and accurate if we have people make me full long conversations then that's inefficient but it also kind of pollute sour Clarity of data when we want the question should be simple is this the right business is at the right address you know it was the right phone number something is really clear and simple that is hard to have any uncertainty about what kind of foods have you guys found that you can validate with humans and which ones you can't sure yeah so phone number is a great example because the very Act of calling it already gives you information so
 the first question will typically ask and it says the number connect doesn't connect then we know well not only just the wrong number for this business but it's the wrong number for any business that might have it connected you do reach somebody then it's is this the right business name so we give them the phone number First Once the number connects then they look at the name and say okay is this such and such business they say yes great we can usually ask one more question like just the right address or does such and such person work there so we can kind of
 try and kill a couple of birds with one stone there will be fine. That's those are questions that we can be pretty confident about the answers similarly websites are really easy to validate for the most part because our human validator can put that website into there no search bar see what's there and it's really clear whether or not that's the right website for the company and for the most part of course there's edge cases redirects there's no parked pages but over time we kind of understand more and more of these common edge cases and connection we bake those into the instructions for the validators so that when they encounter that they aren't tripped up no more complex question
 are things like is this part of a chain and does this business have multiple locations so questions like this will use or web research validators and even given a chance to sort of a search the web for this it can be a harder question to answer because it isn't so clearly defined as you know is there's a yes or no it's well what if it you know you find two locations but looks like one of them close is that count what if it's an agent for an insurance company but they seem to be operating independently so there's a lot of kind of
 more complex situations there and even internally it's a little bit challenging for us to Define exactly what I mean by Chain because ultimately we meet we have a particular purpose for this in mind which connects to our customers and they're sort of segmentation demands and desires but each of our customers might have a slightly different idea about what a chain is too so we kind of have to Define what it means to be a chain and then do the best that we can to communicate that to the validators but there's a lot of challenges there
 and then there's some things like a headcount or Revenue which are really difficult for anybody any validator to determine for a company that's because companies don't necessarily want to disclose that information so so basically the easier it is to find information is based on how much a company wants you to know that information out of data enough for sales and marketing efforts is there kind of a human human data validation on there and look at that you guys could benefit from
 in a sense yeah there's this Urban network data fact that I think is one of the stronger points of our business proposition and that is that our customers their sales teams are marketing teams they have a lot of interactions with these businesses as well and if they are well-documented the CRM software records and they give us permission to use the nuts come interesting because a lot of companies these days are very kind of tight with their data Securities really big important thing in anyways a company have had made a lot of efforts to make sure that our Securities very strong more so than I think most of our competitors this point because you realize it in the sort of the modern data climate you have to have that trust in that security that is your going to let someone else have access to your data that you know they'll keep it in Good Sam's mail to keep it secure and security but as well
 sort of usability sell some customers of ours don't want us to use their data for anything except for giving them better results and so that's fine we'll do that others are more allowable for us to to say use that data for validation but not for enrichment so if they know that company has this phone number and they have used it to talk to people at that company and stay have to have dinner records would have confirmed validate that then we're allowed to use that if we already know that's the right number for the company we can say okay we have confirmation there for wool
 ensure that but if we don't hit record for this company without that phone number when I allowed to actually attitude there so it's from an ethical standpoint we do a really good job of making sure that we're not reaching anyone's trust in engineering standpoint it's kind of interesting to actually in code that sort of ethical and to make sure that every datapoint we have coming into this pipeline course there's billions of them hundreds of billions of them the ones that are sensitive need to be through the entire pipeline label is suction handle appropriately existing tools you guys have used or what tools you can have to build for yourselves to handle that kind of stuff
 tools that are the pre-existing for validation I think most of what would fall into that category or more services so Mechanical Turk frog flower what have you those indeed are kind of alike single solution for common validation problems but they are expensive and there's certainly this rid of overhead of translation and all that so as far as tools gowiwi built all of her own for short experimental framework and playing processing into experiments course we know a whole lot about a company with a phone number but for the validator all they need to know is the phone number of the name the address. So don't framework that we design is about transforming those data points in one of validate into both doors are the simplest Essence for
 actual validation process and retaining all of the information on our ends that we're going to use later for either building training data or running analyses of sort of aggravated validation statistics to take all of that and then prepare the data and aggregate both for validation and for our own analysis and then also when it's complete actually bring all of the labeled data back in process it and integrated our pipeline so that was all something we built in racing pipes Park which is a great tool for the task killer because it is no spark so we can scale it up to as much as we need but also in Python so we can build it quickly and it can be kind of maintained by our data scientist without necessarily really like hardcore engineering going into it
 continuous integration allows teams to ship software faster snap CI is a continuous integration tool built by thought works and you can go to snap. CI / software engineering daily to find out more snap knows all about your get branches and integrates seamlessly with GitHub snap can run your test in parallel for fast feedback and snap allows you to model your build is a sequence of stages from the fastest tests to the more comprehensive ones could figure some of your stages to be automatic and some TV manual in case you want to have more control over your deployment snap CI in bodies the lessons that thought Works has learned from 20 years of software delivery the same lessons that have been written about by Martin Fowler and Jazz humble check it out at snap. Co / software engineering daily again to check out snap. CI and support software engineering daily check it out it's nap. CI software engineering daily
 what what kind of related tools or services do you think should exist or do you guys wish existed that wouldn't help make the job easier we are certainly working on but is is challenging for a few reasons is kind of like a validation dashboard so if you're imagining you are a human validated you you may have a list of tasks that you need to work through and but it's really ideal if you just have one thing in front of you to time so it's the dashboard that gives you very clearly here's what your task is right now for this one example gives you clear buttons to press for all the possible outcomes you know if there is needs to be a text and put it gives you the simple text input and kind of simplifies that whole process so you can work through them with really efficient speed but also very accurate input
 certainly all of the date of this label to return to us needs to be parsed into a format that is usable and so the more flexibility there is in the input the more difficult it is for us to make sure that is the right quality then put so so having a dashboard form would be really nice and certainly to extend that further A8 dashboard that allows our validation teams are the managers those teams to actually manage the full experiment allocate examples to their workers kind of keep an eye on the actual quality of validation and the efficiency their workers will be really great but it turns out that the teams we work with Amanda cases kind of have their own solutions for these problems built-in and they're really reluctant to let us come in and say oh we're going to build you a dashboard and you will then use it because you know they did they have experience with this problem they have something
 works for them and so that the kind of adapters between our pipeline in their pipeline is a challenging problem ultimately we have some we have a solution that works and the most important thing for us is certainly the accuracy in the speed that we can get this validation done and so we've got teams that work well and we've got processes that work well but ultimately it would be really cool to have a psychic instant pipeline where we could actually kind of spin up a new validator quickly and then allocate tasks ourselves
 maybe over time we get that at that direction but you know we're still very much a startup and so we we kind of tackle the problems that are in front of us the ones that need to be done and then when I get to a good solution we we run with it and move on to the next problem and so right now are our validation pipeline is Flowing pretty well and so we can know for letting at work and where were focusing on getting a larger pressing validation a large-scale and then you were able to train models and you realize that they hadn't changed all that much all that frequently until you're able to actually reduce your dependence on human validation for that one attribute or feature that something that's going to come up at all
 I think because we were able to run those these violations at a scale that is not terribly expensive we we still do most of my primary validations for every Bill be run so about every 2 weeks are our primary builds go out and a big part of this too is not just for building machine learning but actually for analyzing our own Acura season so for that probably really is important that we have accuracy metrics for every single build and so that that's one of our major use cases for sure a big part of the talk that I gave was now yes you and validation is cool you know it has its challenges he was kind of the technical approach to it but the fact that we can use the same data points for both this key analysis that lets us know if we're on track where we need to focus our efforts and also to train
 machine learning that continues to make are accuracy better over time these are two very important components and both need to be there for so even if our accuracy is high and stable forgiving field we're not going to stop validating that because we need to be aware that we're still there and we for that matter you know all the sources we have our other companies essentially and we don't have visibility into their internal processes use their logic their decisions if anything has changed a lot of times that is just passed forward to us in their data without knowing anything so
 so big benefit of the sort of positive feedback cycle is that we were robust to those changes because we're just retraining perpetually with new information anime you know if something major changes without us knowing about it may take us a couple of Cycles to catch up but we have enough sources that are redundant and robust so we don't expect any single source is not going to make or break at this point so yeah but as long as we're staying on top of it then we'll be safe from that kind of fish they also I mean as an engineer I'm really focused on on building and on improving on making this like really cool Pipeline and process work but
 we're here we're surrounded by you know product managers and Executives who have their own priorities which are currently in line with ours but they're not going to read our code and say okay I like this code this therefore happy about this they're going to say well what are the results and so if we can constantly show the results and that they are their strong and they're improving and that kind of buys us the freedom in the flexibility to focus on the things that the we know are important but they're kind of harder to approve or to convince them they require a lot of kind of balance those longer-term engineering goals that may not necessarily have an immediate metric response but that in the long run are going to be a really strong model and they're going to allow us to do a lot more things
 accept the fact that we have consistently good results and that we built this pipeline that can prove it that helps to buy a stat that frosting at that time so going back to the validation dashboard and some other things you mentioned working with these managers it seems like there may be some benefit to bringing some of these people kind of into into the radius company structure instead of having it work outside of the company so how do you think about a little bit of everything for the last basically year-and-a-half that I've been working there I've tried different things ranging from having sort of independent consultant validators that actually kind of works sort of In-House to these very third-party teams and
 at at the scale that we need right now which I guess you can call it kind of a medium scale it's it's not the scale of are they providing competitors who just got in everything but it's certainly not something that we could actually just hire a handful of people to do all themselves so for that reason it is pretty effective right now to have this have third-party teams whose managers have a lot of experience in this problem in this field and two can get us to that scale we need
 I don't foresee us scaling it up much higher because again kind of the value proposition is that we don't need that. Yeah it's possible that something would be wrong if if you do need to kind of get that scale right cuz if the whole promises that you can combine both of them well then you shouldn't need as much human validation is our competitors that we have for some kind of more high-skilled values I guess you could say who can work on more kind of curation problems that are more challenging more difficult things like what is the headquarters location of this company that not only needs to be determined via web research but also needs to be in put in a format that is immediately usable for us without having to have one of our scientists or Engineers actually serve revalidate and standardize that address so
 but unfortunately it's kind of one of these problems if you invalidation in that people who would be really good at that job tends to be a little over qualified and they probably would get bored and they would rather be working on something else and so it's kind of hard to find good quality people in that middle range of them. Not to say that I killed but this is something that you know you could just give me a good first job out of high school or you know that this is something that you can work and you can you know perform well without a lot of experience training but if you have that experience and you're good thing then you probably would be good at other things to that name or a challenging
 we don't really have you involved it is but they do have this Army of stylists and those people need to be somewhat fashion literate and skilled job which makes more sense for their product really interesting that they essentially a like fashion company have a really enormous data science presents so scientists an even more stylish to sista yeah it was really impressive actually it's pretty cool style is more challenging than simple data accuracy for personal fax hasn't projects for things I don't have an immediate value but maybe of the long-term interest if you could look what are some what are some of those or what is one that you find especially interesting that even working on or would like to
 yeah so kind of the big push that we're working on now is maybe we speak of the radius business graph is our core data you know
 proposition and we do indeed have a lot of graph prophecies in a lot of graph you know algorithms that don't allow us to do some really cool things internally but we haven't really yet surfaced a lot of that to our customers in the form of a graph at this point so yeah I'm working on now is to actually
 process more and more by data in this format to the point where we actually
 all of the information that we have can be and should be related to each other in that graphical format it just a natural fit for the underlying data itself sound to to build it internally where we're well underway and been many of the like problems that we have dealt with are now done in that graph form but to take that one step further and actually kind of have this living breathing like crap Vault knowledge that we have acquired over time and to translate that into really like even more valuable insights that we might not be able to do a Tapper business level
 it is kind of the next big challenge I think but again you know where we're at startup we are very focused on the problems of our current customers to do a better job of solving their problems and delaying value to them and those of kind of our future customers as well you know what what are the as kind of marketing automation marketing technology in predicted Mark becomes more widespread as the people who are the chief marketing Officer says understand more about data and machine learning and the value of can provide and have more confidence in like giving up some control of things that they've been doing for a long time and Trust in that they're going to get good results from these new job start date of nerds then we'll have the freedom to deliver more good Solutions and
 solutions to new problems that are still very much cumin prophecies so I think that the big thing for us now is that we we build a really strong data model that is going to be robust to a lot of future problems that we haven't even thought of yet and I think that having this big graph of all data we have is is a great fit for that and yeah the application seems like the piano
 thanks to sinfonico for sponsoring software engineering daily symphonica is a custom engineering shop where senior Engineers tackled big Tech challenges while learning from each other check it out its symphony.com SE daily that's s y m p h o n o. Com SE daily thanks again Stefano
