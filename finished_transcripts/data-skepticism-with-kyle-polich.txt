Transcription: with a fast-growing field like data science it is important to keep some amount of skepticism tools can be over hyped Buzz words can be overemphasized and people can forget the fundamental if you have bad data you will get bad results in your experimentation if you don't know what statistical approach you want to take to your data it doesn't matter how well you no spark or tensorflow or anything else and if you are passionate about the work that you're doing you're unlikely to finish any of the projects you start and this is true whether we're talking about data science or anything else Kyle polish hosts the data skeptic podcast a show at the intersection of data science and skepticism as a podcaster Kyle takes himself seriously and he's prepared for his shows which I admire and appreciate having met him recently at the Microsoft build conference he's a great guy he's a great host and I look forward to doing more podcast with him in the future in this episode
Kyle is interviewed by Sid Ramesh a data engineering correspondent for software engineering daily I hope you like this episode
 spring is a season of growth and change have you been thinking you'd be happier at a new job if you're dreaming about a new job and have been waiting for the right time to make a move go to hired.com / SE daily today hard makes finding work enjoyable hired uses an algorithmic job matching tool in combination with a talent Advocate who will walk you through the process of finding a better job you want more flexible hours or more money or remote work maybe want to work at Zillow or Squarespace or Postmates or some of the other top technology companies that are desperately looking for engineers on hired
 you and your skills are in high demand you listen to a software engineering podcast in your spare time so you're clearly passionate about technology checkout hired.com SE daily to get a special offer for software engineering daily listeners a $600 signing bonus from hired what do you find that great job that gives you the respect and the salary you deserve as a talented engineer I love hired because it puts you in charge go to hired.com se daily and thanks to hired for being a continued long-running sponsor of software engineering daily
 calculations the host of the data skeptic podcast welcome to software engineering daily to be here so you're the host of data skeptic podcast interview Professionals for sinus related to the data science field your background and I started out primarily working on a eye with a focus and motivation systems why was doing that I was also simultaneously kind of starting to look here and adtech I spent a number of years there left that and have drifted around for a couple of different Industries in general working on just you know Software System architecture and system design how we can integrate data science tools and machine learning doing you know actual implementation when I call end-to-end from figuring out on paper how are going to solve a problem to how we realize that is technology doing a lot of verification and monitoring and just you know kind of ml deployment General well with so many things going on what does it mean Focus
 these days my main focus is around some key machine learning problems and I'm working on at the moment uniform sample there is a site that I'm helping do some spam detection on so we can build a little bit on the shoulders of giants who done spam work before but there's some unique things and challenges there that are taking up my time these days so not to get into the topic people give a lot of definitions to the data science field but I'm curious to know how do you define dating sites in the phrase is science you know so for me science and being scientific is following the scientific method and that's generally like 3 high level requirements to do that first of all whatever you're pursuing is hypothesis-driven and a hypothesis meets the three criteria that it's consistent with the available data you have and generally that's trivial for a data scientist to do the second is it needs to be verifiable in some way it makes two has to make predictions that can be like a Navy test where you try something and see how it works
 can be pulled out sad some K fold in that sort of thing but again get a scientist tend not to have too many problems with making predictions the 3rd and I think most important criteria is that to be scientific something has to be falsifiable so whatever work you're doing whatever problem you working on it's often easy to come up with you know some sort of model that seems to work in the use cases you have but the use cases that are working or not the important ones it's the ones that are going to give you Insight or sort of break your model that are important so for me someone who's doing data science is working on something with data and really following the scientific method in however there executing it so who is a data scientist in your view
 I mean that's tricky I think there is about as many definitions is there are YouTube videos answering that question at to me it's anyone that understands that data is what informs us about smart decision making and you know follows logical processes and doesn't go with your gut or their Instinct but goes with what they did is telling them so long as the data is correct you can be someone who is you know a PhD with a bunch of post ox and incredibly smart and do that and you can also be someone who stumbled into this and is it Wiz in Excel on just knows how to ask an answer good questions and just think that you have been through it so I look tools for data scientist so you call your podcast data skeptic what is so important about skepticism that you wish to highlight in relation to data yeah so when I see skeptic first thing to be clear I really mean scientific skepticism there's a lot of people who misuse that term for example people call themselves like vaccine Skeptics but the over
 whelming scientific majority tells us that vaccines are perfectly safe they do not cause autism so people like who call themselves Skeptics there are deniers I'm really saying you know that you want to be a scientific skeptic and it's a very busy and idea it's that you should have beliefs that are commensurate with the evidence available to you so how did your podcast come to be so can you explain how did it start yeah so I think it's you know a couple of things that all came together I've always haven't had a love for the audio format since I was a little kid I was interested in you know doing a lot of stuff with burning deep ctr's and getting content to my MP3 CD player that I had back in the day long before they were podcast I've always enjoyed the medium and kind of wanted to contribute something to it and you don't like Rihanna I've done a couple of different things in the data science field something I've helped out with on a couple of occasions is doing some m&a activity like mergers and Acquisitions soda case for a company's thinking you know hey should we
 get a contract with the third party company should we just buy them or should we build something internally asking questions like that and when I don't work like that often I found that there's like a hot new startup were the seven portraying themselves that way saying you know you should buy us for a bazillion dollars in our solution will plug in and it at least in one especially agree just case you know we went through this very good see demo that looks really good and when we got under the service to start kicking the tires of what was billed there was literally nothing there we really reverse-engineer the whole process in in a figure out how it was working and built-in mic about 10 lines of code and so you know guys this is all your you have here why would we engage in the service and come really far in these discussions over investors involved in all types of Finance people looking at this deal on it collapsed when we realize that that company just had sort of this house of cards and I was asking myself questions about how did it get this far and in that situation it was that you
 very smart business people who didn't understand the technical side and people who are good at marketing and kept throwing around terms like machine learning and Ai and that got it to this pretty Advanced stage before you know we haven't looked under the hood and saw that you know the use case they were telling us about wasn't actually the in fact the case and I'm being a little vague there cuz I don't want to be liable about anything but the general use cases there at that we have all these emerging tools and Technologies I could say we're in like a new industrial revolution of data science and in a lot of ways and just because we have things that are doing really amazing Advanced things for it doesn't mean that those same methods are guaranteed to solve any problem if someone comes up to me and says we can cure cancer we're going to use machine learning to do it that sounds like we perhaps you will perhaps you won't but the fact that you just compile the model doesn't mean that model is correct and useful and I started to see a tendency for people to say oh well they use data science are the uses for casting package it must
 correct and that's only half the story you know that the method can be good in the implementation can be bad or the garbage in garbage out from the data so I wanted to be a source where people could learn about my field but also place that gets people to ask questions because the truth has nothing to fear from scrutiny and we need to you know not be intimidated by Concepts we don't understand it I think everything a data science is in my opinion pretty straightforward and easy if you have a good teacher or the right book or just something explained in a clear way and there's no reason everyone can appreciate those principles and be smarter about you know what we trust in and what we believe in that just because something was built with the methods We Trust does it mean that it's guaranteed to work out that's very interesting and no other podcast you have a very interesting format that you do a longer interview type of episodes and then chartered many episodes
 which are Coho stall to your wife Linda every alternate Peak where you take a topic and give a high-level explanation so what made you decide on these two show formats
 so I always do there be interviews and effect for me personally that's the most appealing part getting to talk to all these interesting people are at least having an excuse to do so, but I also really wanted to cover more fundamentals as well so take we can say we're just going to talk about boosting and then explain that in really common everyday terms that any person can understand that they can walk away and go implement it but enough that they say I like it with this concept is for how to use it some of the pitfalls and I couldn't really figure out a good way to do those more fundamental things and until it occurred to me why don't we do the short explain or episodes and that's how the many episodes came to be so how do you choose your topics for the mini episodes most totally by whim it's whatever I have an idea for a nice way to present something you know some of the thymus I develop an episode that is there to help prepare someone to under your listeners to better understand the next episode you know recently like we've been doing some interviews about generally or general
 generative adversarial networks cans so I thought well this is kind of a new topic in the literature why don't we do a mini up so that explains it a week before so that people have that in their minds when they go to hear the interview maybe they could appreciate it better if they listen sequentially so I'd like to say every week as planned like that but sometimes we're just deciding to record one afternoon and it's whatever we can kind of come up with that day well I must say that I often find the conversation between you and your co-host of more of a professor and student which makes more interesting topics Auto statistics statistics or methods of data science are I think things like machine learning than statistics than optimization and then there's a long list it's difficult for me to prioritize what's the most important concept after that but those are kind of the big three and so I can't imagine really someone being an effective is a data scientist without at least very basics
 mystical knowledge you could even make a case for an eating more than statistical knowledge so I also see a gap in a lot of people getting into data science especially people have like a software background for whatever reason they can offer and slip through their training without getting much statistics so I try and be a resource in that way so long with your podcast you also have some interesting projects like the open house project SML causal impact cordless nailers what is the SNL cause an impact Project episode we did and I worked with Karen Blakemore on that I'm so causal impact is this really interesting package in our minutes based on this paper I think some research using Google put out that's let me see if I can give you the basics in a nutshell the idea is that if you have a Time series let's say the number of visits to a Wikipedia page that has some pattern like in a maybe people read it more on the weekends or less on the weekends can also have some Trent someone that's rising in popularity let's say up
 nude and it's going to be a hit in 5 years there's going to be this upward Trend then their seasonal Cycles whether those seasons are weekly or monthly or annually or things like that and lastly there is you know the residuals out of that construction of a Time series the day today fluctuations you can't explain so naturally you can't assume that the recent history predicts the future but an interesting idea is what if we took a bunch of things that are related weather those are stocks that are similar like IBM and Apple and Google and Microsoft stocks and we looked at how they Trend up and down together which does happen that's why there's things like index funds things that are similar seem to move together but then when something breaks out from that it can give you you can use those other kind of cohorts are or you know counterfactuals they call them as a way of measuring what was the impact of that difference so an example might be or the example we were interested in was what if a band appears on Saturday Night Live does that give them a big boost and pop
 Clarity I'm so we wanted to use causal impact to test that theory or really to measure what is the impact of being on Saturday Night Live and then it's part of the process we also build the really most accurate built this are shiny app where people could interact with the data set so we actually found in that case just a jump to the punchline that the didn't seem to be much boost to that appearance so I was always appearing on SNL either doesn't boost your popularity is a band or maybe the band is already so popular that whatever the Boost is is a below the statistical noise threshold now that all presupposes that are methodology is good which is really the skeptic apart if you believe that Wikipedia page views are good proxy for popularity that are methodologies good I think that's not a perfect proxy but an interesting one so there's a lot of things to still be said about what what you know being on SNL does for you is a musical group but that's at least what the project was all about
 don't let your database be a black box drill down into the metrics of your database with one second granularity text provides database monitoring for my Sequel postgres redis mongodb and Amazon Aurora database uptime efficiency and performance can all be measured using vividcortex vividcortex uses patented algorithms to analyze and surface relevant insights so users can be proactive and fix performance problems before customers are impacted
 if you have a database do you would like to monitor more closely check out vividcortex. Com SE daily GitHub digitalocean and Yelp all use vividcortex to understand database performance learn more at vividcortex. Com SE daily and request a demo thank you to vividcortex for being a repeat sponsor of software engineering daily it means so much to us
 I believe it was just two weeks ago that you are you were talking about the open house project so what is the open house project open data group named it liberating full grain transaction-level real estate data for analyst perspective home buyers data scientist is like we like to say that generally dated curious Linda my wife and I we went were about to buy a house full over I guess a year year-and-a-half ago we started getting in the market and I was really frustrated because I couldn't get access to the data I wanted to use my skill-set you know I couldn't run regressions or do any sort of modeling because the only things I could find online were generally current listings filtered the way some commercial website wanted them filtered I want to look at historical Trends and you don't get really granular to zip code levels and when you want that full grain data it just wasn't really available anywhere at least in an easily accessible way despite it all being Pub
 information with a few exceptions across the country so after being frustrated looking around for a while I thought hey maybe I can make this into a project so open house was created we've built an API that allows people to push data we built a crawler and some parsing interfaces and it's actually going pretty quickly at the moment and the technology Landscapes evolving a little bit but in general we want to be a source where people can come and get access to that full grain data so they can ask smart questions and get smart answers when it comes to doing any sort of property things like the what is often the most important financial decision anybody makes in their lifetime buying a house so how can SE daily listeners contribute to the open house project will the best way is to go over to open house project. Co and then click on get involved we have a list there of some you know easy ways to get involved more advanced ways one of my goals in you know after we put out the episode is creating ways were people can make what I call the for our contribution everyone kind of wants to do
 open source and help out but very few people can commit 10 hours a week for obvious reasons so and it's hard to get into any project from scratch you know it just jump in and understand the whole code day so we're working pretty hard on our end to make it to create accessible tasks anybody can do and you know where in almost like an alpha beta stage with the lunch now we have really good coverage in a couple of areas like Los Angeles and parts of Pennsylvania but it's pretty sparse as well so we're in a dead exploration face we can use a lot of help there and I would say a few months down the line is the database gets a lot more full resolution of the date across the country we'd love to have people using this in applications and doing really refined analysis and and building stuff on top of it great well I must say the open house product would be quiet just a lot so no to talk a little bit about data processing in the Enterprise data processing has multiple steps name d in just store
 but often times data cleaning is the process which takes the most time even more so with unstructured data so why has data cleaning become a separate necessity yeah the famous quotes is somewhere between 70 and 80% of a data scientist time is spent doing data cleaning I actually hope that the community the data science Community can start to use better terminology in the future because a lot of things fall under dated cleaning Summer Good summer bad cleaning sounds like a chore and sometimes it is like when a data scientist has to spend a lot of time fixing mistakes developers made and how they lock something or are they unpredictably change the way things get stored but cleaning can also mean like removing outliers or it could be in a things that just need to be transformed and very careful way so those Transformations and the data set up are things that aren't so much cleaning as they are structuring in a basically the algorithms that we use each come with their own set of
 assumptions and peculiarities part about being good at data Sciences knowing those things really well and how you best prep the data to be to enable an algorithm to do its best job so some of that falls under cleaning and that's just a normal day today so I think the reason we think of it as such a big process is because so much gets put under that umbrella but yeah it's that you know all those steps that take you from the rod do you have to producing some novel result or at least the step before the modeling which gives you the novel result just to kind of get an idea so what are the tools you use to clean data so I'm not sure I have a great answer for this there's like a really long list of startups and bigger companies that have a lot of tools in the space and all summer or great for specific use cases I don't think there's any clear pack leader there at least not for me to be perfectly Frank I do most of my data cleaning you know that is either like speaking out what needs to happen or writing the scripts myself to do those changes and I'm using a lot of bass
 tools for that just kind of playing around in my Jupiter notebook or something like that and once I have a picture of what needs to happen then like how do we automate this can we use you know Lambda architecture or things like that are questions that kind of become the answer themselves at least for me once we have the plan if you try and go to quickly to Tool sometimes you get a lot of assumptions and this garbage in garbage out Factory takes place but to be honest I'm usually doing a lot of that clean up manually at first until I know what the steps are and just say so to talk a little bit about the statistical population of your podcast popular discourse off turn on data seems to send up I don't knowing how to use computational tools but computational tools out only one aspect of the three prong native data science there's a lot of fires four people are just like you said previously to invest more time on software then on the other two aspects of data science major statistics and domain knowledge so what is your do you want that
 I'm not sure if I know exactly what you're asking so you have tools like Hadoop spark Kafka and aboard soup of you know this there's a lot of full stack data science and nothing bad. Data scientist just a bunch of software tools when in fact you have often on your podcast you have taken topics which are not soft yeah it's kind of the letter to application but just the main dahlij to me like Siri for example of the episode on Ocean on oceanography and then you have one on I forgot the name of the person but you have another episode did you talk more on the application then of course you do a lot instead of sexy so how much should one who's wanting to become a data scientist makes a big mess on assault right because often times I see the discourse a lot related only on soft bed I mean tools will come and go
 and there is a lot of good information available in terms of like blogs and in what have you that you can find out like you know the latest about spark like I barely cover spark at all anywhere on the podcast the person that's because you can find resources out there but it's also because that's not very Evergreen you know new releases keep changing things and it's also to really understand the tools you need something visual most cases it's an audio podcast it's hard to tackle it but I think the other half of your questions like where should a person put their energies and for me personally my advice is to focus on methodologies over the tools now you have to know the tools to get things done but your domain knowledge and knowing the methods will kind of in my opinion leave the path towards accomplishing something and if ectomy knowledge can often be the really big differentiator and once you have a plan figuring out how to execute it usually kind of Falls in place in at least in my experience so that's why I even though I'm constantly trying to keep up with tools and see
 what's new in when other people are doing once I know what I want to accomplish usually did the tools are kind of secondary and easier so I just sexier Topix Li many episodes explaining machine learning and statistical methods now why do you see a need for that everything I know about machine learning is really really simple so you can either assume I haven't learned very much or you could assume that you know I'm the most brilliant person I can understand it easily I don't think either of those things are true cuz I don't think I'm just silly all that smarter special the thing about learning and in this goes beyond data science but especially within my field is the literature can be really obtuse some of that is because it's moving fast some of that is because it deals on other literature that assumes you know a lot of things and I'm at the point now where I can pretty much pick up any paper in my field and I don't struggle so much with it but I remember lots of days when I would you know I read something 8 times and I still wouldn't get it
 so I wanted to be one Avenue by which people could come and you know learn about stats and in machine learning those things and more accessible terms because I think the the core intuitions are really what's key to being successful and they're all pretty simple if they're explain well the problem becomes when you know the the Wither describe is just not accessible to the person trying to learn them so relative touched on the reading the paper topic I do have a question on that so but before we go there how important is it to know statistical learning as a topic to call the one that data professional you have you Taylor Hasty's the infamous introduction to statistical learning and then you have that use our CDs in Springer so professional
 so I mean dated professional to me sounds like a much broader term that can include people like database administrators are ETL engineers and realistically no stats is probably required there but for someone to be in a data scientist I mean you have to know at least the basics of what's covered in your the AC books a great one if you want them or in introductory Source I would say open interest to tistics for sure is required you have to have everything covered in there and it's a free PDF for very cheap book if people looking for a resource but yeah I mean fundamentally most of data science is rooted in some way in statistics so I people have got to get comfortable there leading figures and data science have phds some and computer science some another field but they do have a dog crate level accomplishment and unit touch on this topic before and I often do find reading papers difficult to say the least Valley the word I was looking for was intimidated
 Tosca just not but just out of my reach at least at the present moment so how important is it to comprehend academic papers because there's a lot that's coming on the topic for Aspen and data scientist
 yeah that depends really on what you want to do with your career I mean for the foreseeable future a person could have a really good career knowing one technique you know you been a very simple technique using it well and migrating from business-to-business just repeating that process you know you could get really good at a B testing and help you know dozens of companies in your career figure out how to improve the sales funnel on their website something like that and you could do that successfully without learning too much because that's you know a good skill that the market needs like I said at least for the foreseeable future until Sunday I figured out how to do that and make sure that task obsolete but for me I think either one of the joys of life is learning and I see that very strongly in people who want to call themselves data scientist it's you know A love of learning finding new techniques and growing as a professional and for that at some point you're going to hit a ceiling where are you've learned all the literature that is old and you're starting to be red
 you take on getting more cutting-edge things or newer ideas that haven't yet made their way into textbooks or very simple YouTube explainer videos or underneath the skeptic or things like that and it that state you know that literature goes into the archive in into other journals and things like that so maybe not day one but as you grow as a professional at some point people need to develop inability to read academic journals for sure are there any papers that you would recommend like that you did have a specific recommendation when you are doing the word cloud topic on visualization so engine don't even know a lot of topics on papers a lot of many episodes sometimes even the longest episodes so are there any recommendations that you have for people wanting to get started on this to experiment
 yeah so I think it's you have to fall back on knowing where you are already so everyone comes from some academic background I presume even if that's as simple as like you have a high school degree and you went to some coding bootcamp for 2 weeks that's great and that's a good start it's different from someone who spent 10 years in school and has a Ph.D and that doesn't make the boot camp person inferior just means that they're on a different place in their Journey so what do you already know and where do you want to go next are Yorkie questions and you don't forget people in my academic work a lot of what I did started to rub up against the game theory literature I was totally unfamiliar with it and I really struggled reading econometrics papers in fact I have a lot of criticisms of the way he kind of metrics people write papers I think they do a bad job often and how they write equations and things like that it could be much more clear but of course I say that as someone with a computer science degree they may say the opposite about the literature in my field so over time I develop that muscle but on the flip side I could pick up
 computational Theory paper and I had the sufficient background to understand that and appreciate it so if you know where your strengths are read the literature close to it and ideally it's kind of like on the path you want to be on but you'll find that when you start to know a field you know maybe half the people publishing it and it publishing it it and you'll start to figure out authors that you like the way they are right and that's a good introductory way too kind of I guess get familiar with your reading growing and being able to read papers better and stuff like that so I've come across a lot of talk on using deep learning models in farming Netflix for feature extraction with examples and images recognition text classification but it's not that competitive those applying really understand it well enough are you done many episodes explaining keep running and related Concepts so how important do you think it's the understanding of the underlying mathematics before
 find it what can I say something is potentially little controversial here to be frank I don't think you necessarily need to understand a lot of the underlying Theory and deep learning to use it at you know there's a lot of really cool work going on for how we can make deep learning models more interpretable or should have probe them you know I read an interesting paper while back the basic idea they had was to understand how image recognition system is working that you could randomly occlude that is block out or blur parts of the image and see how that harms the accuracy of the predictor and that's a very big black box style of approach which is kind of something I want to promote here a little bit we are coming to the point when these networks are so big it is really difficult to figure out how they're working now there's a Cool Tools out there for sure that let us inspect different layers and kind of see what area is there working on it there should definitely still be working interpreting models we shouldn't give up on that but for a moment let's just say
 we give up on at the model is so vast in size and, and compute cycles that it's almost hopeless. Identify how the intuition is an abstract level of How It's Working that doesn't mean we can't you don't learn things about it or test it at that point that system is very much like another human being I can't necessarily know all of your motivations or how you're going to think or strategized but I can test that scientifically like an experiment so let's say you have a black box model that does sub that's using deep learning and us some important task let's even say a medical task where is critical there's life or death situations here and all the training looks really good the cay full validation looks great we don't for sure know if it will generalize now in a perfect world yes we'd like to know exactly how it's working but if for some reason that's off-limits or too hard we can inspect it like a black box we can try and fool the machine and there's good work going on in the other fooling images side of deep learning but basically we can kind of go back to the falsifiability that
 important principle of being scientific how can we break the machine in that will usually tell us where its edges are so if you can build a black box of some kind that does something useful and you spent in Vestal all the time trying to show that it doesn't work and you fail that's good evidence that you can trust that system and at the end of the day at least on the Practical side I really concerned about solving real-world problems and implementation so if you could do that as a black box and Soviet interesting so I'm guessing you up yeah that's supposed to be working just in the data field what trends do you see in different data-intensive Industries you have detail you have health care and then in finance you have automated trading Bots and they have the fintech phenomenon so what are the fence you see in in the data field
 yeah I don't know that I can tell that I have in my career touchdown enough Industries to speak really broadly I've never worked in fintech or healthcare for example but I worked a lot and he Commerce so I know something about the trends there but maybe I can just talk more of a macro level and say that it obviously deep learning is more prominent to all the time spark is becoming more the platform of choice I actually have 2 predictions that out of these are controversial but I don't hear as many people saying these as I think would be commensurate with how strong I feel that their correct so I'll give you 2 predictions here I suspect that serverless architecture or planned architecture if you use the AWS lingo is going to get more and more popular especially as there's better tools to do change management and stuff on it like that I also think I understand maybe my more bold claim that chatbots are going to be ever on the increase and that 5 to 10 years from now chatbots will be the new user interface and for that to happen we're going to need smart data scientist working behind the scene
 how to make them operate so can you elaborate a little bit on chatbots now this is a topic was just taken on like a fire band in the past 6 months you have so much being did not it like never before and it's a very interesting topic to so can you absolutely so what has changed at least in my opinion in recent times is all the plumbing has been worked out there are a couple places to do this I don't want to give one my vendor preference at United agnostic to all that but there were many tools out there that will get you up and running and building a Hello World by in about you know an hour where if all your Bot does is Echo back with a person says I'm his he's dumb it doesn't do anything but being able to create that deployed to Skype to run over SMS to put a plug-in on your website basically to go into slack to communicate over every possible Communication channel that problem has been solved all that technology all that plumbing is available so now the question is what do we actually do with it
 you know if people are familiar with the Eliza model that's a milestone in the AI in speech stuff that's an old one in kind of a funny story that I encourage people to look up to say I think it's been talked about enough we can skip it here but the the hard part next is going to be how do we put intelligence behind those spots so another Trend that is important to why chatbots are growing in Pocket popularity are API marketplaces and cognitive Services basically people are building models and providing them at very low commodity cost for use so for example facial recognition even though it might be fun there is literally no reason for anyone to start from scratch trying to build facial recognition today you can go out and use the services that will do that for you for you no less the fractions of a penny it makes no economic sense to try and build your own model now and some of that is also because the cost of doing that spinning up the depot any hardware and running all the training someone's already done that now there's
 interesting things to be sad that we can get into if you want to or not about you know how do we use transfer learning allow some of those basic models to be extended for my specific use cases but by and large there's all these two sitting next to the bot framework that I can pick up and do natural language understanding and parsing and sentiment analysis that works pretty good in a general-use case so the update availability to integrate that in lots of places and spend things up fast as I think what started this revolution what's going to really make it change and take off it and of course obviously you got to giving that to Siri and Google Assistant any sorts of tools that are doing great and they're doing great not because they're a I but because they solve very specific tasks really well I'm always telling my phone like all remind me tomorrow at 3 p.m. that I've got to do something or remind me that Sid's going to do the interview tomorrow and it knows these even though I can say those things in lots of different formats it's not trying some silly like regular expression with
 matching it's such an intelligent stable to parse those basic domain specific tasks so if we can do that businesses can start solving problems that are specific to their domain I imagine some place like a bank 80% of the visitors to the site just want to know their balance or something simple like that they have in these very basic questions that the chatbot can probably handle so we'll see industry adoption because of that but also the ability for smaller teams to do deep learning work and to you know ticket take advantage of some of the advancements that are going on in NLP is what's really going to ignite the trend I think so do you want to see The Strain continuing on to the finance field even more so in context of the automated painting but the the financial advisor but so do you see any evolution of Destruction here
 I'm absolutely open to being wrong but I don't see any disruption there and I think some of that comes from me being very cynical about Finance I have a very game theoretical perspective on a lot of finance and I talked about this once in awhile on the data skeptic blog but my basic premises this if someone knows something like let's say there's a breaking news story that says apple found a bunch of gold bars in one of their warehouses they didn't know they had will immediately apple is worth more money so the stock prices immediately going to shoot up so the only way you make money is if your first to that knowledge and that's why we have high frequency trading and all these kinds of things in the barrier to entry is so high no small group can get involved in that so you have a couple of big players that are a really fighting amongst each other eating out the in a fractional percentages of some advancement they've made in some mathematical model unless you have private knowledge which doesn't have to be inside or trading but means you know something no one else knows
 the market is more or less noise in my opinion I think I invest almost exclusively in just index funds and things like that so if the market doesn't admit any signals that are predictive then nothing can be productive and I guess Mike or thesis here is that the market doesn't admit very many things
 your application sits on layers of dynamic infrastructure and supporting services data dog brings you visibility into every part of your infrastructure + APM for monitoring your applications performance dashboarding collaboration tools and alerts let you develop your own workflow for observability an incident response team was like with all of your apps and systems from slack to Amazon web services so you can get visibility in minutes go to software engineering daily. Com data dog to get started with data dog and get a free T-shirt with full observability distributed tracing and customizable visualisations data dog is loved and trusted by thousands of Enterprises including Salesforce pagerduty and zendesk if you haven't tried a dog at your company or on your side project go to software engineering daily.com
 slash data dog to support software engineering daily and get a free t-shirt our deepest thanks to Dad a dog for being a new sponsor software engineering daily it is only with the help of sponsors like you that the show successful so thanks again
 so no awesome X data tools include are pythons Scala and other programming languages and sequel doesn't get a lot of place except for in ATL applications and I'll bet it still being used and relational databases stole the model now what's your opinion on the importance of sequel in the age of Adam python you're making me feel old here because I'm now the cranky old man saying no sequel super important everyone's got to learn it just the way people gave me that same advice about for Tree on you know 15 years ago maybe sequel will go away but I highly doubt it I think relational databases will never go away you're too useful they solved specific problems very well now what happened was we had a decade or more of relational databases being really awesome and a great persistence layer and everyone use them cuz they were reliable but not every application is a banking app you don't need acid compliance and all these things so it's people start to realize you could relax those cuz
 that's when we saw this emergence of all these other tools and especially in with big day today become more important how we going to deal with the world in which the cap theorem is a reality in those sorts of things so sequel regardless of what the underlying technology is it's a wonderful and Powerful language it's very expressive and mini busy been any business people non data scientist with no technical background can do amazing things with just the basics of sequel knowledge so wild data is not inherently relational to begin with in most cases it seems to end up that way in a lot of applications and it would be truly surprising to me if you know more than 50% of the world's structured data in a database is was ever not something that could be queried by sequel so with that for that reason and for the fact that still so prevalent business I think everyone should learn it also if you're going to be a data scientist equals the least of your worries it's pretty easy to learn and you get a lot of big bang for your buck out of
 cuz that is the keys to the kingdom of understanding data and most companies so it's really important topic so I just wanted to us and ask about so what is that in a Sprint data scientist should have you already put sequel on the on the bottom of the list so what would you have on the top 5
 top five I think first have a plan for your career and it's good general advice but just saying all I want to be a data scientist well that's great that's like saying oh I want to be in technology will what do you mean you can be a front-end designer you can be a systems architect even if data science is now an umbrella term so I think you need to plan ahead what do you want to accomplish in your career and that should be a combination of the methods that you think are really interesting and you want to work with and the domains you'd like to work in because why you can get by with only one of those skills you know being really knowledgeable about health care can get you may be a good job and you catch up on the methods later or vice versa but combining those makes you a key asset someplace so I mean top 5 skills really depends on what you want to accomplish if you're interested in text audio video images you do need to go they learn deep learning but if instead you're interested in I don't know you no more like
 Remodeling and turn analysis and improving conversion funnels in e-commerce deep learning probably is not going to play a role in that maybe some small role but fundamentally there's going to be a lot of domain-specific feature engineering to do and you want to understand the algorithms like xgboost in rainforest and logistic regression and those to solve those problems so the tools should there the problems you have should drive the tools you use not the other way around so in terms of name the Feast of pretty put on as the number one priority for Aspen and it's like would that be hello or would that be too my deleted knowledge of wildebeest what's your pic into such a broad umbrella I guess I would say if you got to put one thing on top it's probably statistics because so much emerges from that you learning basic statistics isn't going to teach you anything about mapreduce
 but there are things about mapreduce that operate you know probabilistically so it seems like stats are kind of fundamental that's why I guess I put those in the top so the break the glass ceiling of office of field know what does it take so who's qualified or you know what does it take so I think this is kind of a different answer for every person given their background for the I'll try and give me the most general-purpose answer I can give and that's enough to figure out what you're good at and then go on that trajectory so wherever you like to be and if there's a skill gap between what you need to do those things and where you are now so start applying the great thing about David science is you don't it's not like a chemist where maybe you need $100,000 worth of equipment to do any non-trivial chemistry experiments you can do data science with the technology you already have so pick a day to set of problem
 the charity you can help with or better yet a small business that you know your cousin's car wash or someplace that has some data that you can volunteer or work on the cheap and just start working figure out what the problems are and then look for methods to solve them and you're going to get a lot further just by doing then by worrying about what to learn because the doing will create the necessities of indention and you also have something to show that you don't break the issue called the glass ceiling which I presume means getting a job and getting into the field that's going to be a lot easier with a portfolio of work then you know a claim about how many books you've read interesting in your opinion what would be a good data science project or if you have like a list of a measly guessing that you would have a lot of opinions or ideas on this what would be a good data science project now I just want to set the contacts here you have a lot of open data available so for someone who would want to get started on this
 what what what could be something about you the most important thing about a project is that you finish it and most projects are a lot harder than anyone anticipates when you start so the key is to be practical I think also the best piece of advice I can give is that you have to do it about something you're passionate about if you open up your cities local data portal I live in Los Angeles are open data portal is ranked number one in the country by some survey and there's a lot of just kind of stuff in it like I pulled on the dataset recently for street sweeper day too and I played around with it for a few hours and it came to nothing cuz I didn't have a question I didn't know what I was doing with that I was just kind of looking around and that's okay maybe I would have found something and maybe if I had been more clever that day something might have come out of it but have a real problem that's interesting to you so if you're interested in jazz get a data set on Jazz and do clustering or do whatever Explorer task interesting questions about it if you're not passionate that projects probably
 not going to get finished it also helps to have something that isn't necessarily clickbait but is interesting to get people to look at your project and give you feedback on it so you know something on the Olympics when the Olympics comes around is probably a lot cooler than I don't know the the the best place to buy a hard drive or something like that so I would also say you want to get a debit data set if your you know earlier on in your career get a dataset that's already prepared it's easy to have a big dream about crawling some site and parsing out a bunch of data but those things will slow you down pretty fast but I'm guessing that you do know on the different courses that's available in Coursera the alarm on a text that's a lot of udemy so in your opinion how would you rate in someone who's wanting to who's eager to get into this just indulge in any of those courses and get significant roles that he could get some paper at them
 to be honest I'm not sure I haven't taken too many of those and I mostly kind of have created my own syllabus whenever I'm learning things and I found my way you know that way obviously I get a lot of benefit out of watching YouTube videos so I Stumble in and out of you know Udacity courses that way I think overall the real thing is to find the medium that works for you I learn pretty well through audio and I will send you a ton of it while I'm doing chores or at my desk for just about anything so I get to enjoy lots of podcast and learn that way I tend not to do as well with textbooks you know I buy them aspirationally but they're intimidating you know 500 pages are going to sit there a while so I tend to biased toward let me read a few papers let me watch some videos I like and you know even though I don't have any direct recommendations off the top my head it's about finding the the channel that works for a person you know to their learning style so I think
 be a great disservice if I don't ask you the question what are your favorite data science related text books or books even I recently I am almost done with the Deep learning book by good fellow banjo in Portville it's it's excellent I take issue with actually a few parts being a little unclear but overall that's the premier textbooks oh definitely pick that up Russell in Norfolk for a I I've already mentioned open intro elements of statistical learning assertive gold standard those are the main books that are coming to my desktop my head okay so now we're coming to the end of the interview and I would just want to ask some open-ended questions I've sometimes come across the idea that 50 W is a nice to have if you have an update then you can make something of it what's it opinion on that
 all the historical data on every Lottery that's been running the United States for the last hundred years it's very unlikely you're going to build a model to predict the lottery there's just nothing in the training data that is predictive of the output and being able I think maybe that's what separates in my opinion like a junior data scientist from a senior one someone who can step back from a problem and ask questions like what do we actually expect your what's the upper limit unpredictability how well will our training day to correlate with our objective function knowing those sort of glass ceilings if you will and your data set will often tell you you know do I have enough data here to learn the to learn a useful model is the day to even accessible so I like to think of data often with analogies in either biology or in like industrial settings so in biology we have all our five senses and they're pretty good but they're not perfect I mean for me hearing for example this is one of the more fallible ones there are tons of times I think I heard something in front of me and it was behind me and all those sorts of things
 so it in an industrial setting you have you know sensors all over the place taking temperature or whatever meeting measurements they need and the manufacturer of the sensor will tell you the precise conditions under which you can work you know the sensor fails below a certain temperature and it's measurement have a very specific low standard deviation all these sorts of things that is the way we have to look at our data set if you're waiting for some e-commerce company one problem will be that people create new accounts can you link those two accounts washer to some degree but not perfectly and you can cook you them and do all that sort of stuff but they can be Multi-Device at some level that problem is not solvable perfectly so you have to know kind of how good can we get it where did the trade-offs lie if the business needs to invest a half a million dollars to improve the tracking you have to be able to prove out that that investment will give you data that allows you to make smarter decisions and get something out of them in fact there's a nice little mnemonic for this value
 information equation says what is the value of some information and it's all about the decisions you make so let's say you were going to buy a car and you have the option of getting the inspection or not you can buy that you can choose yes or no to buy the car with or without the inspection hopefully you make a more informed decision given the inspection so take the utility you'd have from making the decision with the inspection subtract the utility you get making the decision without the inspection and then subtract the cost of the inspection in that gives you the value of that information and being able to apply that will tell you a lot about like you know knowing if the dataset needs to be clean more improve more and if it can be I think it always comes back to that cuz I really worked on a data set that didn't have some issue and how it was recorded that came from choices human beings made not to say that there was people made mistakes but especially at startups you know you you're constantly changing and doing what you need to do to get things out the door that will leave you a pretty sky
 are data set in general so do we want to try and repair it fix it move forward asking those sorts of questions are really what are going to set the bounds of your success great so you so what's the best advice that you would give to a assessment data scientist I would say there it's figure out what you want to be doing data science like I said is so broad it's kind of like saying I want to be an athlete okay you want to be an athlete pick a sport once you know your sport figure out who are the leaders in that sport how did they get there and that's your roadmap go do everything those people did and you know as you get about halfway there start to ask questions about if they were on the right path or not or if or if their path is the right path for you okay so what is busted by someone ever gave you never gave me I don't really know
 I don't send a tabulating mistakes I just try and get back on course as quickly as possible Vice
 Navy okay so what's your favorite Sublime yeah well I have at them but Sublime instead of 2 so so what do you have any shout outs for not just books you've already done books by for YouTube videos are podcasts are courses on audio books even that you would want the audience to take a note of this data science podcast out there I know I'm going to leave somebody out cuz the list is long so I apologize to all my peers but data stories partially derivative talking machines learning machines 101 not so standard deviations linear digressions becoming a data scientist I think those pretty much the coverage of it I listen to all of them they're all great each in their own ways to figure out the ones that suit you as a listener
 and then it is a one-off cuz this is a new show that just came out that I'm liking there's something called science solved it which is been really good podcasts then videos and in courses and stuff I just thought I wanted to refresh your recently in computational complexity Theory so I went through a course on YouTube That's from the MIT opencourseware and the lectures were excellent so definitely recommend that if you're interested in computational complexity videos there's a lot of stuff out there we talked about some of the bigger names there's one that's newer that I just discovered called I don't know how to say the something like Cruz get Scott and the second tagline which is probably easier to search for is in a nutshell it's not so much data science but it's fantastic science content so and you don't believe me background their well-told good animations and what not yeah I guess that's a pretty good list of recommendations you have any recommendations of any books like nonfiction book
 00 audiobook Stephen nonfiction but if you're looking for more like armchair reading or the kind of stuff I read on flights IGN 11 the physicist is one of my favorite author she's written three books the first ones called How the Universe Got Its Spots the most recent one is called black hole Blues which is all about ligo and the one in the middle which is a work of fiction that's the very you know like breaking the fourth wall at times and really good is called a Madman dreams of Turing machines and it sort of follows the fictionalize versions of girdle and Alan Turing and some of the other Giants of the you know scientific literature and whatnot so I guess for more that armchair reading yeah go check out June 11th and I'm thinking skeptically off and with data so that's my tagline that I tried and on my shows with I guess it comes down to this data is really bringing us what I think of is a new industrial Rev
 ocean in many ways it's almost magic in some cases anyone who is Anna maybe 25 or older like myself can remember a day when search engines were absolute garbage and then suddenly Google and it is easy to kind of gets to to be trusting and say like oh technology is going to solve every problem because it's solving some really hard problems and doing them in really interesting and very effective ways but what I don't like is when somebody say somebody says always solve the problem and we did it with machine learning and that's the end of the sentence as if you know that just made it intrinsically correct saying because machine learning her because a I am having a useful tool does not mean that what you did with it was the correct usage or or is effective in some way so I think David scientists need to ask inquisitive questions and go beyond the exaggerated headlines and talk about how we can empirical etest things and measure our claims so date is both the toolbar
 which we in the methods of data science are the are the tools by which we can analyze claims and it's also something we want to be questionable of when someone has his data and says you know I've come to this conclusion based on this data does the date of really address the problem what were the methods implemented in the proper way so I think it's two sided date is the most powerful thing we have or one of the many powerful things in our Arsenal for solving problems but it also is not to be used without some for thought and skepticism is great to have you on the show thanks for coming and it was great talking with you Kyle I really appreciate it thanks for having me I'm a big fan of the show so it'll be weird to hear myself on SC daily one of these days thank you thank you
 artificial intelligence is dramatically evolving the way that our world works and to make AI easier and faster we need new kinds of hardware and software which is why Intel acquired nervana systems and its platform for deep learning until Nirvana is hiring Engineers to help develop a full stack for a eye from Chip design to software Frameworks go to software engineering daily.com Intel to apply for an opening on the team to learn more about the company check out the interviews that I've conducted with its Engineers those are also available at software engineering daily.com Intel come build a future with Intel nervana go to software engineering daily.com Intel to apply now
