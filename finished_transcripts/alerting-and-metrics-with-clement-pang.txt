Transcription: an alert is a signal of problematic application behavior when something unusual happens to your application an alert can bring that anomaly to your attention in order to detect unusual events you need to define the norm so that you can then Define anomalies in order to Define both that normal and problematic Behavior you need metrics metrics are measurements of the behavior within your application metrics get created from logs and other data these high volumes of data get aggregated and collected into easily digestible metrics disaggregation process that reduces that data to metrics is often called a metrics pipeline
Clement Pang is the Chief Architect of wavefront a company that builds metrics and a learning software for Enterprises such as box and lift Clemente joins the show to discuss how these large Enterprises use alerting and metrics and how to build a company around metrics and alerting since he built a company around metrics and alerting which is called wavefront
 and this also includes the data engineering that was involved in constructing at the metrics pipeline 4-way front and how other companies build their metrics pipelines we've done so many shows about monitoring and devops and data engineering you can download the software engineering daily app for iOS to get all those old episodes you can easily find them by searching within the app for topics that interest you and you can find new topics and new episodes that might interest you as well based on your listening history and the recommendation system that we have built been up of the episode you like you can get recommendations based on which episode you listen all the way through to so we can get smarter about which episode might appeal to you
 and if you want to contribute to the software engineering daily open source ecosystem you can go to github.com software engineering daily the IOS app is just the first project to come out of the software engineering daily open source project there's several others we've got an Android app that's on the way it's contesting right now it'll be out soon we've got of course the IOS app your Swift developer objective-c we got a recommendation system and a web front-end so we're working on different projects at all areas of the stack and anybody who wants to contribute is welcome you could join our slack Channel you can go to github.com software engineering daily or you can always send me an email with any kind of feedback suggestions for the apps or cure if you're curious about how to get involved so I look forward to hearing from you Jeff at software engineering daily. Com
 and what's going on with this episode
 spring framework gives developers in environment for building cloud-native projects on December 4th through 7th spring one platform is coming to San Francisco far is a conference where developers congregate to explore the latest Technologies in the spring ecosystem & Beyond speakers at Spring one platform included Eric Brewer who created the cap theorem Von Vernon who wrote extensively about domain-driven-design and many thought leaders in the spring ecosystem spring one platform is the Premier conference for those who build deploy and Ron cloud-native software software engineering daily Lister you can sign up with the discount code SE daily 100 and receive $100 off of a spring one platform conference pass while also supporting software engineering daily
 I will also be at Spring one reporting on developments in the cloud native ecosystem I would love to see you there and have a discussion with you join me December 4th thru 7th at the spring one platform conference and use discount code SE daily 100 for $100 off of your conference pass that's SE daily 100 all one word for the promo code thanks to pivotal for organizing spring one platform and for sponsoring software engineering daily
 client paying is the Chief Architect and co-founder of wavefront Clemente welcome to software engineering daily thank you today we're going to talk about metrics and alerting alrighty you work at an Enterprise analytics company that you help start and metrics translates into business value in a lot of ways let's start by talking about one of the ways that metrics translates into business value which is alerting how do large companies think about the process of alerting
 sure so I think when we started way front we have the idea that Enterprise monitoring should be based on metrics and their lunch choices there you could be old school way is kind of just checking to see if the machine is awkward Allen kind of just paying him to see whether it's there or not you could be looking at logs syslog or just seeing where it went what outputs of area systems are are in hitting and there's metrics which is just punched and measurements of whatever is going on in your system it could be interest Rock sure it could be CPU Kabhi Ram how much disk space you have left how much traffic is going in and out of your network but interesting metrics are business metrics like how many transactions are being processed how much you know dollar is it is is is going through the system how long is it taking for orders to be fulfilled in MN what not to those are the kind of the KP eyes that died in modern digital Enterprises that's we called them are very interested in and we find that are especially our customers today you know they are many times you know SAS comfort
 is or online businesses where up time and customer experience are very important to them and so they are using way front as a platform to monitor those metrics and basically threw alert making sure that you know everything is it is all get a hunky dory when when they are running their services and or their platforms are what are some of the common alerting mistakes that people can make weather at a big company or small company store sure are a lot of the existing alerting and a lot of it is threshold be so you could be just saying you know this CPU over 80% and then you realize you know when you did I could push it became over 80% but you thought well it was good because we're doing Accord push and then gets hot for a little bit and then so you treat the alert and it became a 85% and then you forgot like well but there are some cases where 80% it is an issue right there that these kind of very strict or
 Ridgid Carnival learning is not what businesses should really be hurting on and that's why I hate you know wave front has a metrics platform is not just you know what a traditional times he's database would be we have our own language which allows you to basically craft mathematical Expressions on the data and transform it using the existing to do sensible alerting so basically all you can say if I deployed code and you know the moving average rooting median of the CPU changes significantly compared to you know a day ago a week ago you know then alert me or you can say you know I often times you're not running just one single machine if you have you know all the times I could deploy in the most of the the servers get get hot anyways or you can say in at in a member and in a in a class of machines are classes of services you see a particular node being especially hot and that variance tells you there's something interesting they're so alerting I think the
 common mistake is it I'm trying to Lou to is you trying to capture not a threshold or or just a first-order behavior you're trying to capture what's what's really behind in so that way about it you are actually alerting on a behavior that you want to be be informed about tell me if this is a accurate description of metrics this idea that you have a large influx of data and a metric represents a function that stands in the way of that data or you can Fork that data to the function in the function is giving off a higher level abstraction of that data stream and it's giving you this numerical representation of how that data stream is changing over time that functional abstraction on top of of incoming data that results in a
 number and you see the number changing over time which is an accurate description of a metric is that that's right that's very correct because often times are not the actual raw data because you're basically measuring system so the measure that the system itself could be changing every millisecond right but you could you could think of your function as you described as a box where it's observing what's going through in the system and generating some kind of metric out of it the most common form of symetrics are for example like gauges kind of like your speedometer on your car so if I were to take the speed of your car every 5 Seconds you know that's a Metro even though that that speedometer could be just swinging back and forth during which is very common in in these days where you tracking request you even could be tracking a latency with with a counter and that you know what you were the first to rid of you could actually get the rate and I'm going to get interesting things out of that very recently I should say is we also sing histograms being pretty widely deployed which is base
 Play It's observing every occurrence as a pass through the system but generating some kind of a summary of that data so you could very easily computer for example the mean of whatever that's coming through a black box but you could also pretty smart things that you heard about that that stream of the year that's blowing through by looking at how you could been the data right if you have a algorithm that could decide how you could bend them into sensible buckets and count what is in all those buckets and have some way for that bucket to be preserved then you could do interesting things like just looking at me know P 95 on a single on on the stream of the following through but also combining multiple of the sister grams into a summary so that you could actually get the full P95 or the real I said the real P95 in the real P99 update games that's coming through multiple systems in your deployment
 as we draw towards a discussion of how to use metrics and anomalies and alerting us some context it's 17 there has been a lot of change of the last several years about how developers and operations interact at a typical Enterprise especially because there's been this rise of tooling there's obviously infrastructure as code and then all of this other really nice tooling it was built on top of that really in a in a compressed frame of time 3 to 3 to 4 years or 5 years since the infrastructure as code movement so what's the modern relationship and I know it changes so fast that's why I want to get your take on Sherman and relationship between developers and operations of typical Enterprise they are off
 finding that their developers are the one that act that's actually managing the the infrastructure itself and so one of our customers is a big ride sharing company and in the city and so they're probably only two they really want to have their developers be the one that that handles on call and so they decided very early on that that would be no just a very clear segmentation off unit developers and operations folks what it means is that when you write code you were thinking of how you're going to monitor it you're thinking of how it's going to run in production and if there is shoes in production you were basically on the hooks to deal with the issue and I think that's kind of a kind of an extreme form I would say of of devops are the most places have developers and they have what we are now drumming is as devops which is kind of an overloaded but it it does signify that they get in in the industry as a whole the idea that developers do engineering and I T folks do operations is slowly beginning to blur
 and so developers themselves wants to be kind of involved in the deployment of their of their code of their software and operations want to have an opinion on how they're the code is structured it in an architectural sounds so they know how to operate it best and I think metric is kind of in that juncture because melters want to know you know this is kind of a very miserable thing when you actually see your code running production people clicking on it and it actually you know working and giving you know a good response early or the customers enjoying the piece of paper that you wrote right so the the way that developers get that kind of feedback is through you know get some kind of matter if you know whether they could be logs it could be you know just maybe even a tweet on Twitter on Twitter that says you know that this feature is awesome by large a lot of customers operas that our customers think they could bring that into a system such as boyfriend
 just got to be to be sorry. I'm so used to be so they can actually see what's really going on to their code in production and all the times they make improvements as well as you actually see how the counters gauges histograms to measure are going to a different parts of the ecosystem you know where delays are coming in what are being called very frequently you know you had actually guides you as you do optimization as you do to the system spends a lot of time thinking about it so what I'm what I'm trying to explain here perhaps is a parrot and kind of what he what it what a lot of the work he has done something that stands out from the crowd often times but the picture that the dev. CTR uses is if you look at a picture and you see you maybe a bunch of owls dancing together now.
 and I'm one of them is just strangely taller than all of them like that is an anomaly I think the human eye is very trained to see patterns and so you could stare into an office and you can see someone you're wearing a different colored a shirts or you know I don't know you can look into that I think that that's kind of the definition for an anomaly so the computer themselves actually think of anomalies very differently these computers are not very Visual and see when they look at when you actually give it charred at least for the current iteration away front it is not looking at the image of of the graph and saying well that's there's a dip or there's a dip among a group of machines and you know that's it that's an issue the Vietnam aliyan in computer sitting in computer this often times you know a deviation from Amy and a set of deviation that's that says it's because it's comparing to the
 Oracle data that that's lagged and and we noticed deviation I could be that in NY front we have hope winter is where you could forecast into the future and basically doing triple exponential smoothing and you're basically saying you know if I hide the most recent data points and I do my 4 casting on that data and then I look at my mule data and I see a deviation from that of all of that are kind of mathematical definitions of anomaly so there is a sense of you need to be able to nap and I normally in your business which could be you know something just for example for a ride sharing company in some kind of a case where in a particular zip code people are not getting rides you know when they used to get rides that's an anomaly but how can you actually catch her that I normally first of all you got to be measuring and hopefully with with a metric and then hopefully through you know mathematical transformation comes out with a way such that computers which understand numbers can
 detect that that's an anomaly that the the anomaly itself is it is really capturing what you want and not just a bunch of noise and then that becomes a useful alert for you to be alerted on
 if you are building a product for software Engineers or devops Engineers consider advertising on software engineering daily there are 24,000 Engineers that listen to software engineering daily on a daily basis and if you got a product or service that you would like to get into the ears of those developers would love to have you as a sponsor you can send me an email and Jeff at software engineering daily.com and I'd be happy to tell you more about our sponsorship options and some of the success stories we've got many repeat sponsors like hired.com datadog mongodb amazon-web-services these are big companies that know how to Market to developers and they have their advertisements run on software engineering daily
 send me an email Jeff at software engineering daily.com or if you work at a company that you think should sponsor software engineering daily tell your manager and have them send me an e-mail thanks again to listening to the show and all the listeners who support the show by checking out the advertisements you are much appreciated now let's get on with this episode
 it's important to talk about anomalies because we work in a world where Computing is in some perspective non-deterministic your building on top of infrastructure where you are making the dip knowledgement that this infrastructure is unreliable that's the whole inside of the Google infrastructure was that we're going to use cheap commodity nodes and we're going to expect at these notes you're going to fail at any time and this was popularized and we build all these abstractions on top of this unruly at this inherently unreliable Byzantine infrastructure but you know what no matter how many abstractions we build it's still a complex and an it to some degree non predictable NADA term
 Mystic environment and or we treated as not deterministic because it's so there's so much of variability there's different levels of the stack where we can talk about anomalies you articulated a higher level one where you're not getting rides in a certain zip code we going to that could occur for any number of reasons it could occur for because there's a bug in the software or it could occur because your CPU is is spiking because the machine has a Noisy Neighbor that's unrelated to your business or you could there could have been some problem here. Where should we be you have metrics that are being spayed off on your business so like eating in a week you've got these logs coming in and you build metrics on top of them and then you want Define anomalies and you want to define a norm
 for your system of metrics in order to be able to alert on those anomalies in the stack should we Define anomalies well I think it is almost everywhere that could be if you could be Define anomaly. As you said finding Norms it in the infrastructure it's also Google as you said popularized the idea that. Kind of Applied in some sense it in AWS where people are going to the cloud or any public Cloud I should say where they could shut off your machine is at any time and there's not a lot of insight as to how the network it's office performing and buy a large wrong just wanted to use a lot of sass Services I think it used to be that it's between by versus build or buy versus Bills versus open source it's basically Now by versus build
 open source versus ass right so you could basically use a service like way Franz you know like sangria to send emails like today it's your system because you're dealing with a third-party which you access through an SDK over the public internet right so that's why we haven't said you know you would have Gathering everything that moves so everything up that you know it down all the way down to see if you met tricks or even on AWS or example for boyfriend you could you can pull metrics from AWS that they provide the tells you about how hot from their perspective your machine is I'm not just from you within the machine when you're just pulling the operating system and they obviously have measurements on their storage tear on their Network tier and so you can actually get get information about that I want to have all that kind of information gathered and and processed in a single system like we're friend then you could actually then start to do
 correlations across the Stacked right at the examples I use again is an example you know you have an issue with rides dropping in a Bojangles zip code in a can you actually trace it all the way down to let say you know cluster of server is at that's actually experiencing an issue and then perhaps to a particular back and infrastructure that's having the problem again through exploring that Treads and I and the going to looking at my service at solve and then discovering you know is there a particular release does that release cause a particular issue that the component that perhaps hopefully it's also measured and we're monitoring or if it's an issue with the infrastructure it's all for example of Noisy Neighbor as you said you know you can measure see if you steal at the VM level to see if they're there was a neighbor that it's there or looking at us metrics to see you know what is the disc packed itself and then seeing that said that that might be the conclusion to that problem too
 you don't you don't really care if this car tag but nobody's being impacted I think that's also kind of a reason why we come from the top level kpi because this is the underlying infrastructure is just so Florida and end so often times but noisy that you just don't want to be alerted every time when when there was an issue down the stream so when there is an issue on the talk to you and that's where you were you having alerts that that's when you want to wake up people that's a very costly kind of contacts when should I you want to be page 5 people there is sleeping and they wake up and there you know a little grungy and you're not impacting anyone we don't think it's weird you know it's not a monetary issues on a customer experience issue that you know why I bother right so I in your infrastructure or at your back an application Level that you can start to look at you know can we find a root cause and if we can find that would cause can we infer or deduce how to fix it and it was
 Friendly's after you you actually try to address the issue you know is there an improvement in the root cause metric that you're that you're seeing and hopefully if it dies in the end you see an upstream the fact that your customer Resort where are the dates for level kti's are proving I've had some conversations with writes about monitoring and one of the things that he to find is proactive monitoring versus reactive monitoring monitoring being you're looking at your dashboard and your defining things in advance so I can in the context of this conversation would be defining anomalies in advance should be so you be saying okay if I'm defining if I wanted to find a high-level
 metrics to alert on anomalies for my ride sharing company maybe I'm looking at my dashboard and I'm saying okay things are fine right now at what if things got to this level I would want to be alerted the reactive model would be okay with got this dashboard let's move on to the next piece of software we need to build and then when there is a disaster you how to do a post-mortem and you say okay now let's set an alert that whenever we have an event we're going to be alerted in the future perspective proactive like you know you could easy to like insult people who have a reactive monitoring strategy but he got so much on your plate it if you're doing proactive that's taking time away from perhaps something else some other bad day that you would be putting on to hydrite reacted monitoring
 try to get the middle involves your gas boarding in charting and analytics and all and all that I not only do they ingest you know at a very high velocity metrics into it once you are plowed but they are using us a lot of times will dashboarding heater go to a lot of customer site you know that because we find is kind of that single-pane-of-glass that they put that on his across their Knox and their developers or engineering and operations folks are basically using way from them almost I would have said it's almost like Google cuz in the instead of just asking questions for you know maybe just like as a public internet you asking questions against your infrastructure against your code against you use a behavior to see what's really going on right so that's kind of the discovery phase I think you could do that in peace time so I can we do some forecast dnce are we going to run amp capacity you know if I want to look at you know if my garbage collection in Java process ease you know what quarter is it really doing and what are kind of you know tell tale signs of it it's not
 going well or we need to tune a garbage collection so you could do that all the time and obviously building dashboards on on monitor so that people are aware kind of you know they look up and I can see like more than I thought if I have a question if I bet inkling that we just did it didn't marketing campaign and I want to see traffic is it actually having a negative impact on the system to get his look up and that's that's kind of more but I would say for how I acted that having started having an issue and the ability for a lot of customers to basically Define for any service kind of a baseline number of dashboards and alerts it is quite useful which means you know developers when they deploy new service operations folks or death off so it's basically say okay what kind of service is this and if it actually response to request or if it is kind of a bad service or if it's just the point infrastructure you know don't really know what we're doing with it yet you know they would then say okay now we need to instrument it we need to put the right agents on it when you do if they're already admitting metrics
 Boston Pizza policy where are you know that there is a data Lake that's like Kafka where all the metrics wood would go there to begin with so any new service you know the metrics wood would be there and I'm having that much and being away front means you know there are pecans dashboards and in freak and alerts so which you know hopefully his battle-tested over the years so that when people launched the survey say they're not Flying Blind they have instrument panel is if you will that they could look at their service and if he wants you to add obviously they could set up alerts to basically live there were there is anomalies in in their in their system at part of the metrics pipeline will you refer to Kafka and people popping their log data into Kafka for consumption by various subscribers that's why I would like to hear your purse
 active on what a modern metrics pipeline consist of because it a large Enterprise you've got a variety of different engineering teams you've got those engineering teams are piping their log data Maybe in two different places maybe if you're lucky there's some centralized standardized thing you're popping a log into and then if your if you want to get it into a metric system like a wave front you might have to do something like you copy the data or maybe you just read it once and you extracted to metrics and you store the metrics to tell me about the log data and metrics pipeline at typical high-volume Enterprise of our customers do do that but I think the vast majority of them understands that you could actually treat metrics as a first class citizen when it comes to monitoring so you do not actually have to all
 is ReliOn developers basically about doing pronounce and their code to Jeanette metrics Texas where developers themselves that they realize that there is an infrastructure that's provided in the Enterprise at cell that allows them to instrument their po directly using things using example you on the metric so dropwizard metrics where you're basically Define encounters gauges and histograms directly in your code and through you know I don't know Discovery Auto configuration that those counters gauges and histograms are directly sucked into some kind of it of a system such as a day like such as Kafka and then that match with itself is treated as a single unit if you will and and and flows down that data Lake in two different subscribers including boyfriend
 from my perspective when I when I was actually a Google and I was a Google you know straight up College and so Google has a massive and then super intelligent cluster management system cardboard and it was basically what you said was the using commodity Hardware there is no concept of I'll beat him placements you're just basically asking this is some to run this job for you and it just runs it regardless of where it is and we'll restart it would be are as long as there's machines that I can make it run it on right and it's the very early on the Embraced metrics into everything was just these measurements the sampling of what's going on in their infrastructure and their code and they have their own kind of centralized time-series database which was called Boardman at that time and what they did was interesting to logs is because logs is such a verbose medium which allows anyone to give it virtually anything which may not be metrics it could be no exceptions for
 example of java exception is not a metric is it is a very you know how the delity information about a single event right and so in that sense date they decided like we're just going to drop all the logs probably also because you know if Rocky III compliance and all that kind of issues which Enterprises have to deal with and so are using logs if they if they are basically allowing anyone or even a third party library to Southern me write something on to the devil extreme which could be something that they do not want to be logged in because it's either not metric is not interesting or could be super verbose and you have you done started sweet loggers to make sure like they're just logging stuff that you want right so a lot of our as I said earlier than the companies are really adopted metrics what they've done is imagine your printer which is printing your lock statements you have basically a different system weather weather going to go weather in Ruby weather in Java which are specifically geared for metrics and then
 having developers Embrace those libraries and then having a system to take that metric out ship it to 880 leg and then have some kind of system does consuming it on the table then obviously not everyone plays a Shopkin can afford perhaps to retrofit existing systems or they're using public libraries or third-party software or just you using nginx for example which has metrics but you know it also has a whole bunch of logs and coming down from where you can you tell it's a lot to systems out there that that we could take extra log information and convert that to metric which is I think what you were alluding to before but I think if you're looking in looking I had you to the future of digital Enterprises I think having traditional lock systems likes long door door cloud-based solution like some of logic and also there's a whole host of fast solution these days for for logging in
 Play We believe but metric system is fast becoming a new currency in monitoring and Enterprises are finding that they need to have a system a centralized system in a managed system where all metrics from various two years of their infrastructure come into a single play
 indeed Prime flips the typical model of job search and makes it easy to apply to multiple jobs and get multiple offers indeed prime simplifies your job search and helps you land that ideal software engineering position from companies like Facebook or Uber or Dropbox candidates get immediate exposure to top companies with just one simple application to indeed Prime and the company's on primes exclusive platform message the candidates with salary and Equity upfront indeed Prime is a hundred percent free for candidates there are no strings attached sign up now and help support software engineering daily by going to indeed.com SE daily that's indeed.com SE daily if you're looking for a job and want a simpler job search experience you can also put money in your pocket by referring your
 friends and colleagues refer a software engineer into the platform and get $200 when they get contacted by a company and $2,000 when they accept a job through Prime you can learn more about this at indeed.com Prime / referral that's indeed.com Prime / referral for the indeed referral program thanks to indeed for being a continued sponsor of software engineering daily if I ever leave the podcasting world and need to find a job once again indeed Prime will be my first stop
 you're saying if I understood you correctly that he might want to on the same node where your service is running you've got log spinning off and regardless of where those logs are getting piped you have metrics generation running over those logs on the same node and those metrics are going somewhere is that right that's right so I can get there is a conversion from locks to metric but there's also this concept where the application itself is actually emitting metric to Dawson look like textual information right that. Could be but not meaning to be just spinning into a text file and then we Harvest a text file in that looks that that would be one way to harvest metrics another way to do that would be too difficult over the network as a protocol try to buy a report of cold that you know every service would connect to that are sending metrics in a
 very efficient manner and piping. To a a single system so it doesn't even touch the file system if you will
 okay that makes sense okay so that's so that's interesting cuz that gets us towards our conversation of the system level metrics cuz it if I'm talking about just logging getting all my log data and generating metrics about the the the the service that I'm running and you know that's that's interesting but what I want what I really wanted in some situations is system-level logs where if I had was have a service and I've got 10 instances of that service I want to know the aggregate metrics for the maybe across all the instances of that service near saying that there might be maybe you want to just send all those metrics instantly over the wire without writing to the file system to some centralized maybe metrics no demetric snowed that isn't that Aggregates metrics instances of a given service by describing
 that's one that's one model of that that was popularized by I think it's at see that the stats T-Mobile where you can imagine agents running on all your machines and their measuring CPU and they're basically sending it directly to the wall on the wire up to I'm sorry hold over the network to a Thai rogation node and then having bad perform you know whatever. Find allegations that that you want to do I think for a majority of faces the reason why they do that is because you do not have a system or time-series database that allows you to scale so that you could actually do real-time irrigation of that data so one of the interesting things of what you can do with boyfriend specifically is you could be gathering all that metrics you know not touching the file system sending those metrics across the wire to the metrics relay or the vectrix proxy as we call it and then have it sent to a cloud and that materialization occurs on average about 2 seconds so when you measure it when you sample something you got that data in the cloud you can see it in a charge up within 2 seconds
 you could also have been too interesting irrigations on top of the day. So if you have 5 machines all the way of the Yu-Gi-Oh if you have 50,000 Sheen's you want to say like some all the request rate for me and instead of having to wait what other how to troll log somehow and an indent and do that across safety deposit machines or you could do that on a metric platform and just say basically pool that particular metric for about 50,000 Sheen and then do the mathematical collapsing of that and have that app you instantly on your screen so that's kind of the the power of imagist measurement measuring interesting things have the sent off on it either lake or through the network and to the cloud very quickly and then having a real-time engine that can process time series data and having that present interesting information to the end user whether it's Engineers are operations
 we've talked about how to build metric systems and how companies want to use metrics I want to ask you how do you build a metrix company what are some non-obvious rules for building a metric system like wavefront
 I think it one of these I think this is about kind of the challenges or the other though the journey your boyfriend so I think about four and a half years ago and I think that actually was a response to kind of window when I left to Google and started my first company and I was curious about just how to do monitoring or how it how do companies outside of Google do metrics and at that point you know it was you know novios I change and everything with Allah's was doing log so you need a centralized logging system and so you need to make sure your loss statement look like a particular format so that you could grab them at the end of the of the of the pipeline and then they were slow and they were cumbersome and then okay so you know housing a metric system a metric platform is valuable and not just two companies like Google because we're just starting a company as a start up with you was just a handful of servers we want to know
 show all the all the things that we could measure and we just assume that allows us to store those measurements and two interesting things with it and that was kind of the origins of our way front and certainly a lot of an obvious things and not lot of challenges that that we had face along the way but this early ingestion velocity is one of those things you know our our system internally you know we Benchmark it to have a single cluster taking 4 million points for second and you just think about it for a second like we have to be able to if you're writing to disk it or you write your database for that matter if you're running form Lillian Rose per second that's that's a non-physical and how to work that you have to do if Ross we have to figure out how do you know how to do that because metric system you know you're measuring so many things and you want to have all those measurements available when you need them usually you know what you mean you're kind of root cause analysis or when there's actually something wrong going on you want to be able to look at those metric since you want to be gathering them you want if you have a system that scales that can take off
 what data so the initial. A lot of the work was to make sure that we have the ability to ingest a very high velocity and that we wouldn't have an unofficial ceiling and so meaning we have to have this rate it's just don't you have to dispute a storage we have to have the ability to have high availability so that when we actually do work on the maintenance work or just upgrade work on our system that you know the system is it from the customer service active against it for example a tissue or nothing try to beat her up so that we could do work on the on the other side and so we paid a lot of attention to to making sure about that we could take that fire hose that you will be one of the interesting things that that we learned as we very early on the side of that with the the relay on the proxy will buffer locally to disk and when we built the service on like a traditional service where you know if maybe just use an example maybe if Amazon goes down for like an hour you know people will complain people will not be able to place orders but
 he comes back an hour later you know not everyone who who was going to attempt to buy something within the hour when it was down will you suddenly all login to Amazon at once and try to me to place that order that that that they were going to place with them that one hour window right there there's likely going to be a surgeon traffic but you know not exactly where you know an entire hours worth of orders is compressed into that one minute what we do see who would wait front is exactly that behavior because we always kind of say there's a damn there is a reservoir of metrics that's now you know that's cute. But I don't want the customers and if we have an issue if they have a networking issues they have a deployment issue we we are also either conjecturing and I'll head that there is a a damn of metrics that's that's being queued up on their side and our system needs to be able to handle that surge right it is just will not this is some will not will not return to normal until that
 entire let's say that the outage was for an hour until the entire hours worth of metrics is dq'd onto our way from cloud and so if you're designing your system you got to be designing for that kind of worst-case scenario so that you know because people want some metrics and people want to be able to let you know go back fill it kind of a historical metrics that might be missing due to whatever issue that they had with the proxy or with their I was there connections ingestion side that that was a very long lessons at that we have learned to come to where we are today and then on the inside is also interesting because we we work with snowflake which is just a public data or cloud data warehouse company and so there's certainly no strangers to query optimization and I know that and they use weights when does monitoring school and events at some point no we told them like you know that for him is now becoming a decree and then because people opposing
 more complex queries against us so we now have a boyfriend also have a query optimization problem not exactly because we have sequel queries but we have our time series. That are coming in and we are parsing them and you could you could do very simple naive ideas about how you could ask you the grade but more and more often you know we're doing multipass Conakry optimization we are having you know dynamic programming platters actually look at you know how best to execute that Corey and I think that part itself is often times lost on people who think you know I just need a Time series data base kind of almost like I just need a I just needed my sequel instance where you know I I can only issue very simple sequel statement against it the issue of of having a metrics platform is not just to be able to take that data but you actually be able to ask interesting question against it and be able to get meeting for answers very quickly a ride so we we put ourselves to
 a bar where we said we want fries on average to return under a hundred million second call me back under you know hundred milliseconds are in shorter than a blink of an eye so that when people are dealing with metrics they could get answer is very quickly so a very quickly that problem then becomes you know how can we capture the intent of the Grave is often times the query contains a whole bunch of operations on it whether it's your moving Windows logistical operations missing data functions doing the flags at Leeds on the toilet and we have to figure out your what is the best way to execute that query against all the different tiers of dinosaur is that we have and combining that data and then streaming apps and having it all appear on the uses browsers as quickly as under the second and so that
 they have to look at or are they have to consider when they're picking in metric solution I was talking to somebody about dashboarding and one thing that they said was sometimes if you're if you're building a dashboarding product that can be a problem if you're reading from for example a data warehousing solution like a red shift if your if your dashboard is reading from Red shift in your red shift performance is problematic then the son of the users going to blame the dashboard It's actually an upstream problem is that ever a an issue with when you were building wavefront where you had it in your customers who had Upstream issues and then they would end up blaming wavefront it worries there in NFL head of that in perhaps you know if you're into created with a certain piece of technology say hey we're having lag from this date of
 Winer being a mattress company we could have metrics even on the metrics themselves the one of the things that that we often times measure at all of our proxies is kind of the delay the are the difference between the time sentence that we're seeing and wall clock so we could actually detect you know for a customer right now they're saying okay why did this alert not fire you know why is my chart not working correctly usually on the right Edge because that's a bleeding edge of update on and often times we could then go into our metrics all their metrics I had to actually take a look and see okay well we we see that for those cut Datacenter I know there's some like that that we are observing that's that's not normal that's in a knot compared to what we were seeing before it's a look at that time stamp every data point because that you know it we're measuring a a double and then I N store and time stamp and
 the number to basically said when we got that number you know that that you can see that that that explosion in in traffic but that behavior which is when we see that day. But often times we could basically infer from higher order metrics that there is an issue in the pipeline there's a some change in behavior that actually cause that Upstream system to change a very often times we will blame because we both the dashboarding tool and the backend right so we're both the storage query engine and all that plus we also build the front end but often times you actually what we actually flying kite Clinic kind of strangely is that sometimes it's actually that uses browser is because we are shipping so much information to users browsers that if they if they have some kind of a plug in the insta is installed on Chrome that's inspecting like every in football to every dong element to do some kind of interesting things like password manager sometimes
 Calgary that when they are doing got that they actually slow down the the front end significantly enough that they think there is an issue with the back end but very often times actually nowadays when we actually people report that their browser is slowing down that they would that we would actually say can you give us a dump of all your plugins so that we could actually take a look and see if maybe that's actually I would run it incognito or something like that and I'll try a different browser and it and what not because we do so much red ring on the client side that we run into basically bugs in in the open-source browsers that we have to report it or basically tell that used to like hey we know if this is an issue this is the last day the chromium bug that that you can use to track this and then that's a different by Technologies all the way to back in technologies that you know anything in that chain could be an answer to why this isn't slowing down
 our time is short hair I want to wrap up by asking you what's in the future for metrics and anomaly detection looking and investing heavily on doing things like automatic on all the time now in early detection forecasting and even on me to others and maybe I'll definitely self healing system as well I think as a mattress company we have actually never deleted everyone's data even though as on contract we probably have retention time that requires it to be at least a year or a half or so but yeah we basically discovered in our in our system that we actually do not need to delete data because storage of gigabyte to terabyte of the air so cheap these days it's a computation it's it's a combination of logic to store data and all that. That's expensive so having all of that data being available and and and because we are so fortunate to work with so many companies Through The Years with alerts
 we actually have labeled data sets of you know time series and kind of time spans where customers themselves have think that they are not Melissa looked in recent years that can we actually look at that data and just basically say you know why applying learning algorithms on that aren't on the on the on the label data that we could say a new customers when they are on board without them actually putting any other words into the system we could actually detect issues in in in there and their input data as are again I was thinking person in the streets off Woodward progressing we often times said you can we actually then have you know chaos monkey plus plus where you know it and aai is actively trying to break the system and a system which includes wavefront is actually trying to defend against it ends and defend your infrastructure outages even outside
 Packers defend against code bugs and what not and have the system be able to infer you know at least two alert on on pot on system sound issues without the user kind of as you said before I like doing reactive condom on a train and then ultimately having the having the machine learning be able to generate Solutions joke that we kind of sore because the sun runs out of disk space that's probably enough what what generalizations probably a joke RM RF 10 for something that you know who stopped over all of our logins it was probably feeling up to something that people do anyways like when they are when they react to certain kinds of situations or restarting nodes on Amazon is kind of a pretty common thing that people to which we do track we have all those events in the it in anyway front if you if you decide to send that to us so we could actually infer that for these
 metric that are coming in we know that it's an armless we know that in the past a human goes in and restart those machines and so we could actually then say well the imagine that you get page instead of saying that there is a problem you actually get page and said there's an 80% at 80% chance that this could be fixed if we just restart the if we just restart the set of machines do you want to proceed and you said yes and then maybe the Lord clears and if the system is confident enough then maybe perhaps if it detects that you know 90% of the time doing this fixes the issue that it's just going to do it on its own as kind of a first line of defense and then basically page people only when it's necessary so that's kind of the things that we were thinking about refund when it comes to the future of metrics and just automated underwriting and all needed and automatic deviation
 sounds very promising welcome in for coming on software engineering daily spin great talking to you I think this is a really good conversation a lot of dense material so if you text a lot
 thanks to symphono for sponsoring software engineering daily symphono is a custom engineering shop where senior Engineers tackle big Tech challenges while learning from each other check it out at symphono. Com SE daily that's s y m p h o n o. Com SE daily photo for being a sponsor of software engineering daily for almost a year now your continued support allows us to deliver content to the listeners on a regular basis
