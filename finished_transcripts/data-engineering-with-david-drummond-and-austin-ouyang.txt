Transcription: life is too short to work at a crappy company that's why I software engineering daily is proud to be sponsored by hired.com the job market place for software Engineers if you accept a job you hired they will give you a $2,000 bonus but is an extra bonus to our listeners you can get an additional $2,000 that's $4,000 total if you sign up by going to software engineering daily. Calm and using the link on the right side of the page to sign up hire.com will set you up with five great companies for interviews are companies like stripe Facebook Uber company's you would actually want to work for where you can go and learn The Cutting Edge of software engineering go to software engineering daily.com click on the banner on the right and try out hired.com
David Drummond and Austin owyang are program directors of the Insight data engineering fellows program David and Austin welcome to software engineering daily
 so what is a data engineer
 that is a that is a relatively new term that hasn't necessarily found like a single definition but there are a lot of definitions that go around so I guess we can answer what a data engineer is but we can also say a little bit about what I did an engineer isn't that might also be helpful so in the most like at least in my opinion blunt definition is data engineer as someone who is dating a data scientist to actually have an easier time working with the data and there there's a common expression which is you know a data scientist spends 80% of their time you know Ringling data alright and the rest of the time complaining about it but if there's a if there's a good team of data Engineers there then that's not the case that you know the date engineer can
 help build the pipelines that actually process some of the do some of the so-called ETL that they extract transform and load and also do some more sophisticated you know analytics and end feature engineering the kind of take out the the grunt work and allow the data scientist a really a focus on the business logic and you know the more interesting analysis would you say that like I did Engineers programming the applications for a data scientist operate with much like a software engineer is program in the applications for the end user to deal with
 yeah I think I think that's fair I guess the one little difference I would say is that sometimes the data engineer is working directly with an end-user so like it it's a little bit between those and in fact like a data engineer or you can say is is a specialized software engineer who specifically working on on data and so sometimes that end user is you know your your customers and sometimes that end user is a internal customer that such as a you know analysts are data scientist and what is the workflow of an average data engineer were the tools that a date Engineers working within the types of problems that a data engineer is tackling day today I think one of them things for her to keep track of is actually as they're working I'm in between like the data and also the data scientist or the end-user is they need to be thinking about scalability and fault tolerance so if even if they are didn't hear in a smaller company or they may just be
 USA like a my sequel database they should be very forward-thinking in terms of if this company is to continue to keep trying like how they would actually want to scale out the infrastructure and also make it fairly seamless for about the end users whether it be data scientist or like I done consumer
 and so it some company is devops or operations or whatever the company likes to call their sort of next-generation sysadmin type of rolls these these people are are in charge of managing some of the backend datos de test act like I worked at a couple places where the the people that were quote-unquote devops were also in charge of doing some Hadoop configuration and this type of stuff does does a data Engineers work overlap with what has been maybe the past 5 years or so referred to as devops
 so I suppose there is of course some overlap but this kind of goes back to that point which I was saying earlier which is you know what there's certain things that a data engineer isn't and I'm in the best case scenario is I would say doing nothing but devops or doing a significant amount of the devops is something that would not hopefully fall onto the responsibilities of the data engineer of course you know what smaller companies maybe that's the best person to take care of some of that stuff but I think in larger companies there is a little bit more of a division of labor and it would be more you know writing the actual engineering write an actual software as opposed to configuring and doing the devil but they're certainly like it certainly the case that a data engineer should you don't know their way around some of the configurations in the actual that box and and be comfortable tweaking
 things to optimize
 how has data engineering changed from the previous methods of unite ETL and data warehousing these terms that have been around for awhile what is new about data engineering yeah so I mean I think as Austin was was describing before the the main difference is that we now have these specialized systems like I do and Spark and new ones that are emerging all the time and these you know no sequel databases that are more and more replacing the the old relational data warehouses in and these tools are becoming more specialized and they are distributed and because of you know advances and and you know the price and capabilities of like memory and ssds these are there is becoming a new kind of specialized approach to actually
 working with these tools and you know you need someone who was going to focus specifically on how to get these distributed systems to work how to make sure that you know when I know it goes down as you know if you have a hundred nodes it's inevitable that one of them is eventually going to go down and so when that does happen you need someone who is very familiar with those and so what used to be done you know what the traditional like ETL job that could be kind of managed and ran you know in a relatively simple way it's becoming too much more complicated process and so I think the modern data engineer needs to understand the intricacies of a distributed system in addition to how to like you know actually run these ETL jobs in distributed systems importance and we've also got this shift towards a more of a wider variety of technologies that were using
 streaming Frameworks in like over the past decade many companies have built out there big datastax with mostly I can focus on Hadoop mapreduce and and the rest of the hip stack but mapreduce has kind of been getting replaced by a stream stream processing Frameworks what is the motivation for that what are the problems with Hadoop mapreduce yeah I think I would like one of the Penguins I guess I do my produces that it works great on a lot of data but one of the problems is that a lot of each process of when is doing the mapping in the reducing it's all working with the hard drive itself so every time it doesn't process it must have read it read from it and then after it doesn't process sing us a ride it back in on this iteration dust will take a long time especially if you have specific algorithms that need to iterate on a very large do this at over and over again maybe like thousands of times and I could take maybe even week
 compute I'm so now people are trying to move more into one isn't going to the memory Computing or even just like the stream style of computing with memory getting cheaper as well it seems like that's kind of where the industry or a lot of people are trying to move towards these types of Frameworks that can quickly do iterations on very large data sets and this concludes likes park and fly
 and so if I want to add streaming functionality into my Straight Up batch batch processing framework just Hadoop mapreduce is this the type of thing that that I will need to be doing is a data engineer this is my responsibility to to add the streaming functionality to a all batch framework yeah I think it's part of the dead in his responsibility to also be like evaluate these tools so it is always very scary to just say let's go ahead and migrate completely over to a specific technology so I think it was Stephen part of the date Insurance roll to try out various tools kind of like beta test them to see how well they can potentially work in production and then by benchmarking them against each other streaming Technologies and weather and decide if it's worth the Manpower time to actually get it up and running to move move that through
 and stiffening of that company size I would say is they didn't hear maybe the one who needs to do all the devops to actually get that up and running but he Century I would think that it would be better to all source to add About Steam as well to take our security
 yeah and in terms of the you know making sure that there's an actual use case and an appropriate use case for streaming specifically I think you know that's something that the data engineer would have to work very closely with the data scientist to to figure out you know does this algorithm actually need streaming like it you know is is there actually a need to have something you up and running and have it like updated every 5 seconds or you know every 15 seconds or whatever that actual latency demands are I think it's very important to figure those out and it's also very important to understand like the algorithm that's it's going to be used it whether it's some you know rather simple effective we just division or if it's some really complex um deep learning machine learning technique you know whether or not that's actually possible in a streaming framework is is a non-trivial thing
 I think that's why I did a scientist would have to work closely with the data engineer to actually Implement these things in and move them to production quality because yeah what works with a small dataset doesn't necessarily scale
 what are the approaches that I've seen with these batch and streaming development is the Lambda architecture what are your guys thoughts on the land architecture and do teach this as a way to to deal with different latency requirements across a big data stack
 yeah so we definitely teach that in the court in like to the fellowship program we don't try to push all the fellowship move towards that but it's something that we bring up in terms of if you do need I like less like sub-second latency to understand what land architecture is and basically not going to take it for granted to explain to them just the complexities that arise from basically trying to combine the batch processing in the streaming process and they can I get the idea that it is not a trivial process as well could you define the land architecture that talk about what problem it solves yeah sure so I sent you the problem in the past was that you have some batch job that runs in the background and I'm a maybe like to take several hours for to compute so as I get some streaming Gator that comes in that maybe like every you can maybe like hundreds maybe thousands of events that happen every single second I may want to know what is happening right exactly right now right
 so in that case I wouldn't have the most up-to-date information if I just run the simple batch job so it's more of using the streaming process their kind of enhance the batch processing of basic to provide a do the calculations for the most recent data that has just come in and you merge the batch and the real time together so that you can get the most the best the clip clearest picture of what is going on right now but with this sometimes it the real-time process could be doing some sort of approximation and you may also be accumulating errors along the way to so with this number I can text her since the batch job I'll always runs over all of the data then it will always be correct itself every time it recomputes again so it's it's the fact that the best job has this huge like this a huge latency to compute trying to combine that with the streaming streaming lyric can be quite challenging
 yeah and two to elaborate I think it's worth focusing because I know a lot of people who discuss the Lambda architecture just you know say it's you know what's its mixing the the streaming in the batch and that's that's all there is to it but this this aspect that Austin was speaking to actually recalculating on your entire data set that that has many advantages so that helps you with problems that you don't require you to look at all your data set so if you're trying to find the number of unique users and it's possible that you know some users have multiple logins or multiple email addresses that's really something that requires you to look at your entire data set and as a whole and so the Lambda architecture if it's very well for that other thing is if you introduce like bugs into your code which as you know any software engineer knows this is pretty much inevitable the Lambda architecture or automatically correct
 finesse by in recalculating like if there was a bug introduced you just fix the bug and then you can recalculate on the entire data set but so the other aspect of this is this so-called human fault tolerance it doesn't account for if nodes you know make a mistake but if you know software engineers make a mistake or business logic changes you can easily recalculate and this works very well with the with the land architecture
 there are some criticisms of the Lambda architecture like I know it's been called into question by Jay kreps who is the one of the creators of Apache Kafka and what are the replacements for the land architecture our adjustments has been called the cap architecture so what are the what are the flaws of the Lambda architecture and what are the the amendments to it that people like Jake wraps espouse
 yeah so I mean one obvious and I don't know if you fly might be too strong but like an obvious setback drawback is you know if if you don't have data that needs to be recalculated or where it's useful to look at the entire data set all at once then like you know if you're just trying to you know count for example if you just counting it doesn't hurt to just add in your new entries you don't have to go back and look at the entire dataset to to figure out what the new count is when when more data comes in you just add it on if you do have something like that in this is perhaps a little bit Overkill and in the obvious obvious downside is that so that is this a Lambda architecture you know it might be like it might work for everything but there's some used his words Project Overkill and the downside to that is now you have to maintain you know streaming code and also batch code
 out there Frameworks called you know for example of Twitter has the summing bird project which helps you do this that you write in one abstraction of code and like it gets turned into both real time or both streaming and batch code it gets implemented for you but one of the real downside is having to maintain and write two separate code bases
 yeah so what I think you know that the idea behind the the Kappa architecture is that you know you can ignore the batch system all together and just have one simple system the the streaming framework that takes care of everything for you and I think previously this had been you know a lot of people would have said this is not possible but I think new technologies in the you know the the the the fact that streaming Technologies are getting better as making this more and more possible and I think it's also like the use case so if a company that doesn't do much analytics of like maybe 2 years ago it may be worthwhile to go towards the pure have architecture of you can have a full streaming storage and you can calculate things as they come in and in real time but there's no need to store data that's much much older than the stuff that you would ever need to
 find your trainer system on so compared to like other systems where you do want to look at five or ten years ago you need to have that point batching maybe something that's one is easier to wrap your head around
 I was just at a conference called que con and there were so many talks about all these different streaming Frameworks there was a spark flank Sansa store stylus Heron there were just like so many do you guys have a good idea for how these very or which ones you should choose for different circumstances or you know I guess when you teach data engineering at Insight maybe the idea is like you said more to just compare that you know you were teach the engineers to be able to compare these different Frameworks I know what are your what are your thoughts on this vast multiplicity least in our point of view we always try to keep things as simple as possible so it say in the streaming world that they should see it as more of what do they actually mean
 so with spark streaming for example that's more of a it works still on a batch Primark but it's doing this sort of micro batching but with that that means that you can only get down to assert my latency threshold which is probably about half a second at the fs essentially so if you need to keep updating results and like half a second or more than one spark streaming could probably do the job for you however if you need something something that's much lower than I can say for example like if you're in an attic and you need to be able to provide the correct adds to a specific website within like microseconds then start doing it it's going to fall behind too fast I'm at that point you're going to be needing other Technologies which I'm more of these pure streaming it's basically for each record that comes in you do a complication and you just get an output immediately so this includes storm Link Up All In This category as well and
 it's up to you like we want the palace to take that into consideration in terms of how to pick those kind of Technologies now within those subsets they would have to look more into detail of what are the benefits on the trade-off for that
 yeah an end I mean like you know I know there are new technologies and you know they're there this is always the case with beta Engineering in and part of that is comes from are you know I think the data Engineers are fully adopting the open-source mentality but because of that there's like new tools emerging all the time I think if you want to like just put it down to a short list I think that spark streaming and storm are kind of the go to Technologies and what this division that Austin just described of you know true streaming versus micro batting and then personally I'm just really excited about the the Flink project which unlike spark which kind of operates in the batch framework and then also has his micro matching afflink is a stream processing at at heart that can also happen to do batch processing so I'm really excited about a Flink but it's still it's still hasn't been why
 adopted so far yeah it's so funny what you guys said about the ad Tech use case literally the last interview that I conducted I'm not sure when this one will Air I might just tear it right before this one but was an interview with this ad tech company where he he was talking about contrasting the different streaming Frameworks and he literally said like like early on they level 2 down to storm and Spark and they're like weighing the different trade-offs between the two in the word add to company and Spark has this problem of micro batching and literally it's the same example that you just gave me so pretty funny interesting so I mean these different streaming Frameworks they Define the processing aspect of data engineering but there's also storage what what are the storage
 Portuguese and principles that data Engineers need to know about
 yeah well you know this is this is one of those difficult things and I guess at a high level there's two main use cases for for storage the first is distributed file systems and I think the clear winner here is you know the Hadoop file system not not to be confused with you-know-who Dukes mapreduce framework but the half I do hope that is and you don't charge of taking large files chopping them up into chunks and replicating those are in a distributed fashion so it is Fault tolerant I think those are distributed file system like you know a normal file system they're great for very unstructured data I like you can literally put whatever you want in there they're great for basically serving as a source of truth that is to say you take your most raw data and you just dump it into a place like I do file system or
 if you want to use it you know Amazon's S3 I think that's another great alternative but you just take your Rod data and you dump it in there and then you can do some further processing the downside to file systems like that is that ultimately that flexibility and that durability comes with complexity and so when you want to actually access the data you're going to get it in seconds instead of in a millisecond to the relatively slow so then the other major class of storage would be your databases or generally speaking datastores depends how you want to classify it but distributed databases tools you know Common ones that come to mine are the ones that are based off of Google's big table which is you know things like Apache Cassandra or hbase then you have you no more like search oriented tools like elasticsearch
 what should I allow you to do I'm some pretty amazing things with both geospatial data but also of course text based data the main idea behind these Technologies is that you give off yellow and I guess he's all fall under the realm of no sequel you know not only sequel you give away some of that flexibility and you find a technology that because of the way indexes is really Taylor to one or two specific use cases and so that that is the difficulty is that you now have to Taylor the storage at least for the database to a specific use case and maybe you might even have more than one database or more than one you no way that you're using your you know a different careers require different use cases different access patterns and so you might need to optimized much much more in and kind of Taylor to a specific database and so with that said I think most applications
 I use a little bit of both the file system to store the raw data but then you would do some some you know some aggregations are some counting and then you would store those those aggregated results in a database for quick access for either enter the data scientist or end user
 got it yeah there was actually another talk at UConn that Uber gave and I'm hoping to have the guy that gave it on the show but he was talking about using elasticsearch just as you described it as kind of a storage layer in in the land architecture so let's shift from talking about data Engineering in terms of what it actually is to did Engineering in terms of where it fits in organizationally and and how you know that how how big the demand for a data Engineers is so did engineering mostly occurs at bigger organizations that have scales and they have tons of data to manage an engineer so if I'm an employee and I'm not at one of these companies that has
 like a Titanic dataset like you know Google or Facebook or something I mean how how do I learn data engineering is there is there a good way to to learn these skills if I'm not at a company that requires data engineers
 yeah so I guess I mean of course there's there's an obvious use case for those larger companies what were starting to see you know when we go out and talk to the the industry is that there's actually a pretty compelling use case even for medium or small companies and I mean I think we know many many did Engineers who are on companies that you know are are under 20 people and and part of that is not just the size of the company with the size of the amount of data you have but you know anytime you you have a use case for a data scientist you also have a use case for a data engineer do to help enable data scientist to you not have to do the context switching of of dealing with the engineering and some of the other things so I guess there's there's always kind of a use case but question a little bit more how does one actually tackle and unlike learn these things if you are at a smaller company I think our whole philosophy and the philosophy behind Insight is that the only way
 learn about these things it's just buy like trying to develop a proof of concept project where you you finds you know you think about what they use case is where you actually need these tools and then you just start exploring it and then building these things are the great thing about these Technologies is there all open source so as it's relatively easy to get started and you can just start in a building out a product that actually helps your company in and that you know uses some of these Technologies in pretty quickly you'll realize I like you you will learn by effectively doing as opposed to just trying to like wait until a proper use case or a something comes up like there's actually a good fit for just be no building the project that that leverages some of these ideas and Concepts yeah and I would also a second. In terms of if somebody doesn't want to start with SE distributive Technologies right off the bat or like state to deploy things distributed cuz it's not it's not trivial thing
 please open source technologies that can just download onto their local computer and in most cases they have some sort of local mode so they can run just on Eye Care on Mac or PC medicine at Sally's get around to playing with a p I figure out how they work of course you won't get the full effect in terms of how effective are they at scale but once you're he wants you already actually can move into that you could use other services such as like I believe I can Amazon web services as your Google Cloud compute and I know I'm much more familiar with Amazon but you could even use spot instances which are basically like you just put a bid price and then that's kind of that price doesn't get hit your instant stays alive and that will cut down the cost of instances that you want to spend up by almost by sometimes even 10 full so you could give you could be looking at like a form of cluster you could probably only be paying about I don't know maybe like 12 or 13 12 or 20 bucks a month or something like that
 and you actually have a life cluster there so you could test out technology such a spark and trying to ride to Cassandra cluster as well and then you can you can really feel the full effects there I'm just a lot of very white like large data sets out there that are open on Amazon S3 but you could try to read that into your cluster I'll try to do some coffee taste and try to write it out somewhere else and sure enough you will most likely encounter some problems that you have never even considered when it was just on local machine
 okay that's really cool let's do some great suggestions for how to get started on our own there's also Insight data engineering which you you guys are working on and I'd love to get an idea for how the Insight data engineering fellows program works and I think one good way would be for David to discuss discuss David you you actually went through the program before you join insight as an employee could you briefly describe your experience at insight and you know talk about what about the experience made you want to join the company yeah absolutely although I will be out that Austin was also a fellow here so you can get his test while but yeah it's the common recurring theme that we we we love to have people who are very familiar with the with their experience by getting
 some of our fellows that go through the program and end up grabbing them on to our program so I was actually coming from a a more academic background and the inside engineering program is is specifically tailored to to sorts of candidates those who are coming from academic background check myself and I really looking to break into the industry as a whole and then also experience software Engineers who maybe have been doing you know Engineering in general we've had a diverse hellos from all sorts of fields system administration front end you know database administrators and they're just looking to learn and get their hands on these Technologies but back to my my specific experience I came from the world of physics and I was working on in a PhD program on Quantum Computing which I found you know absolutely fascinating and I am still really interested in
 but you know is as you probably heard like 5 years out and I was told that like 10 years ago so when I you know I wanted to go into the industry and in really work on something that's much more applied I don't have a real world impact right now and so you know I had quite a bit of experience with the distributed computing but you know on like a on and I really like not not like a big distributed-system like like you see and hear about for life but just like you know running parallel Computing and using some of those in open source Technologies from the 90s and I had applied that in my you know kind of simulations on my research project but didn't really get the experience with the the tools that are actually being used in the industry right now and so when I went through the program basically the way it works is you build a project
 over the course of 4 weeks and just as I was saying earlier you you have this you basically build a proof-of-concept for a given technology or given platform that you're trying to build so for me the platform that I chose was to analyze all of the US Patent data so you know there's going back to the seventies there's there's this wide and and very messy source of data and for my project what I chose to do was to actually clean up all this data and then you know develop some sort of basic analysis so that you could actually builds really cool tools that allowed you to either analyze you know where where Innovation is coming from geographically kind of slice and dice the day. Or you can imagine building something like Twitter but for patents so every single time someone you know
 every single time Google Google you know posted a patent or something like that you would you would get a alert so I found this you know of course this is an interesting interesting topic for me but what it really did was it allowed me to build and I was kind of just a tool for me to actually get to learn these Technologies and build something and insight data was provided me the resources and the guidance from from mentors like you know Nathan Mars for example who you know the the inventor of the Lambda architecture would come in and actually tell us exactly what that is and would would guide us in our projects and so I really enjoyed that process and that gave me the ability to actually learn these Technologies in a very focused and self-directed way and then additionally one thing I would say is that
 our program really also focuses on the diversity of our fellows so we try to bring in people from all sorts of different backgrounds and what that allows us to do is really learning a collaborative way so any time I got stuck on something I know that I can just you know reach out to one of the people going through the program or perhaps one of the alumni who is who we went to the program in the past and things that used to take me like a day of reading a book or you know I would just get stuck on for you know hours I can just talk to my neighbor and my fellow fellow and learn these things and you know just a matter of minutes and so that was a really valuable aspect so you know inside is of course a program but it's also a community of people that you can always go to and get help for it if you get stuck on anything
 show as you said inside is this entirely self-directed project-based learning what's the motivation for for the self-directed process rather than then having classes liked are there more details that seems she's pretty like almost 4 reticle but it's really interesting to me yeah so when I first ran the program I was actually slightly skeptical about the way the teacher was going to go cuz it's all self-directed just like you said and so I was always the kind of person that would always just think my head against the wall so I figured it out and going to the program I started realizing very quickly that that wasn't going to work and that I would have to ask my neighbor for help and I always refer back to like the types of projects that I worked on my personal projects I've done at home in terms of like those timelines and they would usually takes like several months for me to like get those hashed out getting the project ramped-up just took a lot
 time and making a lot of mistakes which nobody was here to guide me essentially but after going to the program I realize that I would never have been able to accomplish the project that I was that I built in the program I'm had I not been around the types of people that were around me at at inside so I think like one of the biggest things is this Collaborative Learning style of like we do not try to take people just like one particular background but having people of expert expertise from all the various backgrounds definitely helped a lot I was able to ask people about front end I wish I had not done any front end a program before I was able to get that through with them pretty much money evening which I think if I did all my own would probably take me over a week and so that really opened my eyes in terms of how beneficial inside was obvious to me until I saw the fellows to
 yeah I talked to several bootcamps doing interviews and the median time for these boot camps seem to be about 13 weeks but Insight data engineering takes only 7 weeks does it have to do with the with a project-based learning or why is inside like half the time of another boot camp yeah and I should even cut that down even further because that the actual time we spend on the projects is actually let's say the first 4 weeks and even then it's the first part of the first week is it actually choosing a project so the amount of time someone is actually spent you know doing their technical project is actually less than a month for sure so it I think we do have a very high a high bar for the sort of technical abilities coming into the program and I think that's what might separate us from some of some other
 cancelled I think are trying to take people from from you know maybe not 0 to 60 but you know very very low bar people who come into a program do have several years of experience programming I think that helps but I really do think that the Project based approach is the way that really drives you to get something done we kind of work on the weekly spread swear at the end of each week you have some in product you know the first week it's it's producing an MVP and then from there on you know you have interation but basically you you are really pushing yourself in and you're pushed by this collaborative process of seeing what other people are doing to really get things accomplished in a short amount of time and I mean the other thing that we I guess something that we really value in a part of the reason why we don't have classes per say is we really want people to learn how to evolve with the field data engineering and
 anything that you know is is tied to the open source Community is something that's going to evolve very very quickly I mean as we saw like when I very first started maybe like a year and a half ago spark was a very very like nascent thing and I mean it's been around for a while but it wasn't quite being used in production anywhere and now it's a very well-established in just a very short amount of time and so I think we look for people who are going to be self-motivated who are going to be self-directed and we're going to work on whatever is interesting to them in and we don't try to dictate like you're now we're going to have a class on Hadoop or now we're going to have a class on this how we want people to be able to pick up whatever tool it is and really push themselves to get something done with it in a short amount of time because I think that's that's ultimately what they they need to do as a data engineer in the industry
 so throughout these conversations I've had with people from boot camps you know I've been thinking a lot about higher education and you know you see these 13 week or 7 or 4 week education programs versus College which is a five-year education program one has it come out of these interviews just feel like gosh like why why is college the de-facto thing I think maybe people sometimes misconstrue me is like being a really critical of college but in fact them or just thinking in terms of like you have colleges extremely long five-year thing and then you have these boot camp at end and by the way you know many people with degrees still have trouble getting jobs and then you have these boot camps that are like 13 weeks or 4 weeks and people consistently can get jobs out of them or
 you guys would have something else to say about that maybe that's not necessarily true but in any case I feel like there is this giant unexplored gradient of Education paths that people could pursue between these two polar ends of the time Spectrum so I'm curious where you guys see education going like computational education is as an increasing amount of the workforce needs to know some form computer science or data engineering you know where it where are we going with this stuff yeah so from my perspective when I went into college like I did my undergrad in electrical engineering I've always loved physics and then that's something I wanted to do when was really awake Electronics as well but I kind of tree to college as the place where I could learn how to learn regardless of what the topic was really
 I think that's where a lot of students watch a game at maturity of being thrown into this big pool up with with other students you have to learn new topics we have a lot of classes and yes there is value of course in terms of what it is that you're actually starting but to me what was a bigger value was every single semester picking up something new and they see starting from almost nothing and then by the end of semester basic knowing a lot about it or even before that too and then I think that carries over it even when you work into industry or you can go in Academia is not being afraid of learning new things I think everyone should be have this like this curiosity and it's kind of hungry too it doesn't matter like what field you're pursuing but you should be wanting to learn more I think that's kind of where you can develop that and that's in college I think we're as CDs over into a lot of these other programs which are these
 short-term education programs where you do need to have this type of hunger and if you if you want Curious like it is still not going to work like these other boot camps can I defeat spoon-feed you these but this material but if you don't have the desire to learn nothing no one else can do it for you so so that that is my take on it and I think either the reason why we see kind of this this dichotomy of like you know you have really short programs in you have you know long academic and end for me you know covering you know what decade but I think the reason why you might not see something in the middle is that there are people who come out of you know high school or you know what after working for a few years and I already have that hunger and just in a really want to learn these things very quickly and start using them in the in the real world and solving those challenges
 I'm like very quickly and I think there's other people who still want to go through that more didactic process and you don't get that experience of a really learning from the you know the kind of one too many experiences of being in the classroom environment and I think there's value to both of those and then some you know certain people will probably gravitate towards more than the other but I think it's really interesting to see this new development of of you know educational models that are rethinking the traditional academic academic one and I think you know they're there is really interesting growth in that middle area and I just don't know exactly who would be the person who wants to pursue something like you know it to your version or something like that I've been site which I would say like
 that's the thing about these programs is there very intense and so part of the reason why we we live in ours to a relatively short amount of time is it would be very tricky to do one of these things for 2 years straight I think that would be a you learn a lot but you would also maybe burn out what are the things I think about what these four weeks or 7 weeks or 13 weeks things where people can learn so quickly it makes me really question the these conventional ideas we have about like brain plasticity where we where we kind of stay like oh you can only learn at such a blistering Pace if you're if you're super young but yet I see people who are who are older who are going through these types of programs and they seem to have a lot of success what do you guys think about that dick do you think there's a you think we have a under arrest
 location of the human capacity to to reformat our careers and our education's yeah I think I think that is a very interesting point and I should also say like are you know our program we've had people who come in with you know you know straight out of their undergraduate degree and then other people who have been working in the industry for 30 years and you know they both seem to learn at the same rate and I think everyone when it comes to to picking up new things and working with Technologies in a very Hands-On way I think everyone can learn I don't even think it's about age I think it's about the amount of interaction you have with the material that you're trying to learn I think if you're just like listening to someone else or you're just reading it in a book if it becomes very easy to
 I think that that's something that is not it it's the interactive nature of it that makes it much more easier to learn it at any age I don't know that's that's that's how I feel I really enjoy and as I look back on my career I think like every few years I have tried to like you know quote on quote reinvent myself or or like really learn a new subject time for me that's that's been something I've always been attracted to and I imagine I will continue to do
 it's the blessing and curse of the millennial as they said sure So I think it's interesting like I've seen some enrollment stats I think on on these boot camps and the number data scientist that are being turned out and all I've seen is just like kind of open to the right have you guys seen like an increase in the number of applications or has it started to flatten how do you see this macroscopically like are the applicants still increasing or is it leveled out
 so we still see it increasing I think there was originally an explosion and you know that the story behind Insight which was originally Geared for for phds was that there was this problem of you know Katie's who could really really smart people trying to get jobs but you know, that there was clearly not enough academic positions and at the same time there was you know all these people looking for really smart I technically inclined people and you know that they found really smart people but didn't quite have experience with the tools and you inside started as a way to bridge that Gap and so originally we saw that like you know it was actually a very small number of a companies that were actually open to this new position you know at the time wasn't even really named the data scientist but at what we saw was you know there is certainly a huge number of people who wanted to get into the field of data science so like on the supply-side there was certainly no
 no dirt there but on the industry side there was there's kind of a relatively small number but then as the years went by and add this new position kind of the Malden people understood that we seen the demand on that also increase and so what we seen his me know pretty much sustained growth for both of the people who want to get involved in the program from the fellow side but also that the companies that want to work with us in our who are looking for these data scientist day the engineers and so so far we haven't seen any dropping that and I think so you know kept going up into the right as you say I would hope you know that things would balance out at some point in that that would you know there wouldn't be just like continued and balance cuz I think generally speaking from my job economic perspective it's better if if things do level out and then people will go into the field
 so far we haven't seen that yet and it's it's pretty interesting to see if it will keep going up that it's also very interesting like so we've been able to do a lot of interviews with you as well but since I joined I've done I think about two rounds of interviews before the program but we're definitely seeing a very common trend of the people who are applying like they're getting a much better understanding of these tools much better than I was when I first came into this program as well so I feel like a lot of this information out to you too sugar Technologies and what came with big data is becoming the barrier to entry is decreasing so it seems like it's becoming more like the more Clayman will be able to understand a lot of these tools without being like this so overly overly special technology thing science and then expanded to a data engineering track
 what's next for inside are there more projects in the works yeah so we actually have a third track which we just started which is the health data science and still kind of you know within the the Realms of data science but we have a program in Boston now which is specifically tailored for data scientist looking to make an impact in the health field and that's it that's a really exciting area that I think is is worth keeping an eye on so that so that's one aspect and then you know it's Austin is actually pioneering another one which were also very excited about another thing that we're working on is we have a lot of people that have been working industry already a lot of them I have no intention of moving into like other Industries there was already looking at data scientist and Engineers but their stock the Technology stock me already please text so just keep improving
 terms of how to do data science and also do the engineering so are you started these data Labs which are the century these workshops to help a scientist need Engineers keep learning about new topics I'm so we have two topics right now I wanted them is the date of visualization save-a-lots which will be we're hosting in New York City on December 10th and 11th which will basically teach people who want to learn more about how to visualize their data that we run a couple of days already and the Silicon Valley it's been very successful a lot of data scientist really enjoy the program get to work with D3 do some analysis and figure out also how to describe that day the story and the other one that we were running on December 7th and 8th in New York City is the spark workshop for those people that particularly are interested in spark and want to learn the basics of the house parking structure is organized also for people that are Engineers are data scientist that may already have a Sparks stack but just haven't really had a chance
 it's not working with it I'm so what we want to do is I do they're just simple two days sessions where they get to pretty much get their hands dirty I'll start working with spark clusters or working with their data visualization so that when I go back to work they can basically just hit the ground running and start start looking with their clusters and so on yeah exciting thing about both these new programs is it takes the same core idea that the best way in the quickest way to learn these these topics is to just start building a tool and you know both of these are you know when the data labs in particular again there there not didactic there's not you know classes per say it's really no self-directed Project based approach and because these people are already familiar with the field there is a week we feel like and we have seen that it can be a very short program and you still got a lot of a lot out of it so we're really excited about this this project based self-directed way of learn
 and I'm really excited to see what sort of directions we can take it and have it work very well
 awesome well David Drummond and Austin or Yang thanks for coming out to software engineering daily it's been fantastic talking to you I really enjoyed it thank you very much and I think it's been it's been great
