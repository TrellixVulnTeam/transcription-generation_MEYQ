Transcription: Apache Kafka has become the most popular open-source solution for persistent replicated messaging in the Hadoop ecosystem what some software Engineers who are working with big data don't want to deal with the configuration and setup of Kafka one way to sidestep this is to go with a managed solution like Microsoft Azure eventhubs Dan rosanova is today's guest and he joins us to discuss persistent replicated messaging and the features that as your eventhubs provides and how that compares to how you might use Kafka this is an interesting discussion about distributed Pub sub messaging and we also get into a great conversation about platform-as-a-service versus open source software as well as the future of cloud software and how that impacts software Engineers before we get to that show. I would you want to mention that software weekly is a newsletter that we put out every Sunday evening to condense what happened in the world of software over the previous week and you can sign up for software weekly or join our slack community at software
daily.com and we're also looking for sponsors if you're interested in advertising on software engineering daily or if you want to try to hire through the show send me a message at software engineering daily at gmail.com after a quick message from today's sponsor we will get to this episode eventhubs with Dan rosanova
 software Engineers are always looking to automate their work software automation let us get more done with the same number of resources investment automation works the same way up front is an automated investment service that relies solely on software to acquire and manage client accounts traditional Investment Services have many humans in the loop advising clients and taking fees the problem with these older advisory Services is that the advice that the services are applying is often so systemic that a computer could give the same answer or an even better answer wealthfront takes a new approach with software-driven automated investment that provides better returns through software engineering Go to wellsfargo.com / SE daily to get a special offer for our listeners $15,000 managed for free when you open your account don't pay commissions and account fees maximize
 games with wealthfront set-it-and-forget-it investment automation check out well front.com SE daily it would support software engineering daily and it would also introduce you to the world of automated investment so you can see if you like it or not wealthfront.com SE daily thanks to wealthfront for sponsoring the show you've been a loyal sponsor we really appreciate it now let's get on with the show
 Dan rosanova is a principal program manager at Microsoft where he works on as your event hugs than welcome to software engineering daily thank you what is an event hub
 as very good question so it's a high scale durable distributed buffer the basically the way you can think about it is like a almost like a Locking System like Africa but purely as a service rather than his instructor
 so what are some examples of events that will be handled by an event hub
 we get two very large categories they're both Telemetry based on the first tends to be application events so things like the health of a specific application especially for large or distributed applications on her biggest customers whose Halo 5 game they do all of the Halo 5 gaming Vlogs through eventhubs so all the Xbox consoles are creating climate region pushing it into the cloud and it's flying through eventhubs the other big category is sort of iot focused and that would be much more applications focused on physical things certain devices creating Telemetry rather than their software quality would be physical characteristics of the devices are experiencing
 sure so Telemetry would really be instrumentation or logging and in the case of games or applications attends to be more sort of like a lot for that type stuff you would see that the Diagnostics logs you would put into your programs I'll brush royalty it really tends to be measurements of a physical characteristics of an environment so things like temperature or voltage coming from solar things like that
 eventhubs it's between Publishers and consumers and acts as a message broker or a buffer like you described it why is it useful to have this software layer that manages events
 what are the most useful reasons is because of you actually don't want to direct dependency between your publisher and your subscriber or producer and consumer because they will have to be mashed scaling speed-wise which can be very hard to do so that's one aspect this year you're getting some some safety and decoupling there and the other is that you may want to read events more than once and that's a very common pattern for us is we see people put a lot of telemetry data into an event Hub and they the average is actually 3.2 times I think that they read on that's because the events on like a messaging system don't get dq'd and go away it's really client-side cursor so you can have different processes reading the events at doing different things with them so for instance you could have a high-speed pipeline which might be doing anomaly detection or alerts and you can have a slower speed pipeline which be doing batch processing or archive something that's less latency sensitive and that way you can you know
 cartoon the characteristics both of what you're doing and what you're paying to get it done
 canonical example of like a publisher and a consumer or a publisher and a set of consumers that would want to consume that same type of publisher data from an event Hub absolutely going back to Halo they read their data three times and the first time is high speed events this is usually things like player matching the second time is for purely just to let me see based and they would like an archive based and they want to save everything forever cuz that's how they do diagnostics over like gameplay experiences and what character is people like the engagement sort of metrics slow-moving data I guess you would call that and the last time I'm not a hundred percent sure what they do with it but I can see if they read it a third time so they're really categorizing rather than making a universal dispatcher which reads the stream and does everything they're breaking out they're processing it to separate readers so that they can each function at a speed that's appropriate for them without creating
 pressure because I want to take slow longer time to process than the other
 Define the term consumer group in this context you bet consumer group is a construct that we created to wrap the set of partitions that you read from it's almost like a
 pass-through of view on a table and it's really there for management of being able to segment off your readers from each other again because this is a client-side cursor based system if all of your readers are reading from the same consumer group heard from Shane pool sort of hard to see who's keeping up and who is falling behind so this way the consumer group konstruct what do things like keep the Reeds separate to keep the Telemetry on the read separate so you can see that if you had three applications reading you see one of them if it's falling behind you can tell which one it is where is if you just have a big open pool very hard you could to see what's happening you could actually get good aggregate performance and very bad individual performance without this concept so it's really just an isolation mechanism for the readers and zooming out on how this looks from a higher level eventhubs provide this message streaming through the partition
 Shimmer pattern can you describe this pattern
 yes a partition consumer you almost think of it it's a Chardonnay taste system really I like everything that really scales big it's all Shard paste and each partition think of is a chard and within that charge you got a little Universe of data that's all by itself and really not dependent on the other shards in the system and the readers just read from one of those partitions of times one of those charts so it helps for a scale-out Secour or scale-out model for both internally and for customers using our service in that they're able to scale to the degree of the number of partitions they have so if you have very very high scale need you probably need more partitions and that's not the only driver there sometimes the limit is pure networking throughput and sometimes limit is how fast can your consumers or your readers actually process the data the receiving some readers want to do things like matching or very heavy mathematical calculations that way
 is latency and stressed and they may not be able to do that much parallel work in which case you'll need more partitions even without having a very large number or a large throughput of day I'll show its purchasing to really focus about Downstream consumption patterns and less than about what's happening inside the event of itself so it we've done several mentioned earlier that there are some similarities between eventhubs and Kafka what are the similarities similarities would be something like a topic forgot that is pretty much going to be a bad Hub eventhubs they are both partition consumers they both have a durable model although in eventhubs it's a strong leader of them I hope you don't get to relax it at all they are both provide similar constructs for this partitioning concept and then most importantly I think there are two platforms made for
 feeling through put that both chose not to use HTTP protocol for very similar Reasons I'm so I think that's an interesting sort of thing to bring up from the similarities side I think anyone who's comfortable using Kaka be very comfortable using eventhubs conceptual either very very somewhere at what are the kinds of problems that existed with message buses before Kaka and eventhubs the biggest single problem really focused around I'm around scale and different messaging platforms try to sell this different ways for most Microsoft messaging platforms we've always favored a guarantee durability model and that means that you're going to have a pretty slow response to to you know to Ingress and egress because you have to really do transactional base behaviour other platforms like rabbitmq and tibco
 free that up I have no memory only base model even if they do some in memory replication between nodes or where you get there is an opportunity actually lose data and furthermore it's still I sort of eight Publix Shopper or a message and Eric type system so for every message that goes in you read it out and you acknowledge the message and delete it when you read it so this is the core competing consumer piece that comes into play that limits all messaging platforms especially ones that need some sort of durability guarantee I could sooner or later what you're talking about whether you're using a database or file or anything else is really contention for Alachua lock and that that amount of contention no matter how hard you try in a single lock system is going to have a finite limit it doesn't matter what that system isn't that the brilliant thing that Kaka did to get around that was to stop focusing on tuning the lock and start focusing on having many locks on many resources so that's not competing for 1
 chapter 1 Resource it's really much more spread out than that so what kinds of messaging semantics are guaranteed by an event or perhaps is there a does this model provide any new messaging semantics from from a new standpoint not necessarily there's some familiar ones so you're going to get something like at least once delivery in an event Hub you will get guaranteed persistence so by the time when you send a message in if it's HTTP you get your 200 okay it's already been triple replicated it's safe and side even if we have a very bad crash to catastrophic failure due date is still there the ones Mantic that's a little bit different in to be very
 kind of talk to get around it first Comics my messaging standpoint is that you don't acknowledge individual messages so you don't delete messages it's a Time retention buffer and the retention age is off in large groups so it's a much more stream focused or coarse grains approach to messaging IM and rather than focusing on reading each and every individual event to the focus is really on Rita stream whole bunch of events and have a lot of readers for each partition or rishard in that street so it's a little bit different if you both system say they do pubsub which is technically kind of true but if you're used to like filters grouting it's not the type of messaging that we're talking about here
 so
 we've been talking about this persistent replicated messaging pattern and I want to go into the two adjectives that are used to describe the messaging so the first persistence what is the persistence model for a persistent replicated messaging system like eventhubs offer are zits to blob storage so were resisting all events through Lobster orange do something we'd written on top of blob storage which is kind of like a not quite a database but it a similar sort of log structure that is imposed on top of a lot
 okay and what about the replication model and that's actually something we get for free for using blob because of Bob does not have a lot of storage does not have an option to not replicate data locally So within a specific DC show or reaching I guess you could say I'll show you everything in Blob is triple replicated within the Datacenter that that date exist so this is how we're building on some work of other sure actually gives us a lot for free or for a low-cost and it's it's a very big challenge that is hard for platform to sell and it's sad and it's challenging for golf going to self as well because there's a loss window involved if you don't have this provided on the platform that you're running on so their waist privates to Hardware like how trade and then their ways to try this to services like lobster charge and we're going to the service approach triple replication across a data center is there
 any fault tolerance for Datacenter failure well but not between Regents this time and it's something we've looked at but when you start to look at the sort of scale or doing and right now we're we're running about the three million request per second range and we have individual customers who who Peak above 1 million requests per second when you're talking to that skill especially since we're talking sub-second processing replication between regions becomes very very cost-prohibitive especially if you want to have consistency a lot of that comes down to order so it's very hard to have order replicated live between regions very quickly and until we get some sort of quantum networking capability that's going to continue to be a you know it direct function of the speed of light and and very very taxing sort of thing so we could improve that but we would lose latency in the process
 could you do like some periodic snapshot of the event Hub and then like ship it to another Data Center and or something like that or would that be useful yeah it's it's one of the things we're kind of looking at it something we do enable for a customer's right now this is actually a pretty fairly usage pattern is people will read from their stream and have a fast reader that's just writing to another region and that way if they have a catastrophic failure they might be a few seconds behind but that's all they're talking about losing is a few seconds of data alter alternatively another model is to publish to two places at once either both together which if you do you'll have all your data but it will be in different orders and the two regions which is a can be problematic for certain use cases I'm or to have your Sanders be aware of a backup reaching so that if they cannot reach to one they can go to another
 so I tried ordering due to what degree do Kafka and eventhubs guarantee order delivery
 oh yes so for for eventhubs there's very strong we have a little knob you can turn on it basically which is very strong guarantee and and that comes with a cost meaning of unavailability cost and basically the default is that we're not going to guarantee order and we're going to spread messages across all the partitions are shards in the system for your event so this way you get the best availability cuz if anything's happening to one specific server in the link or one specific piece of storage will skip it and just go to the next where is if you choose to use ordering and there two ways to do that either with a partition key which is just a value we're going to Hash to to get a new Partition number or you can actually send directly to a specific partition which is something we discourage people doing but there are valid reason is very rarely to do it either of those you're taking
 actual availability dependency on awesome server that's owning that partition and we need to have one server owning that partition because we're guaranteeing order so that events will be saved in the order in which they were sent so you need an Arbiter of order and by definition there needs to be the only one there it's kind of a sore the Highlander thing there The Producers will write events the event hubs and consumers can read from the event Hub when does the event Hub garbage collect messages something I've been realizing our documentation is not very good at describing sent you the first question I get from everyone and so we do this I basically on blocks of data that are 32 Megs in size at least right now that's the number we chose so each partition were filling up at 32 mag block when that lock is full will will seal it off and put a date on it and then we'll start looking
 every so many hours and the default right now is 24 hours and any blocks that are full that have a date over 24 hours will then be deleted the customer can choose to change that to a higher number I think 7 days is our Republic highest limit and we will just do the garbage collection then but the important thing to know is that we won't garbage collect until each of those boxes 32 megabytes in it so if you create an event help with the whole lot of partitions and you're sending very very small messages then it's going to take a long long time to fill each of those up
 so how do you eventhubs differ from Kafka
 yeah the biggest way that they differ would be the biggest most immediate way is that if an observer service and Kaka is software so when you use an event Hub there is the team for Microsoft monitoring the house for it everything's being looked at everything is being monitored health of the machines are not just at the operating system and network level but actually health of the software itself so memory pressure CPU pressure things like that and then through put on the software these things you get for free by using past type service where is if you use a new software that you need to install and configure they're your responsibility to make sure that everything's running right one of the the biggest difference is once you get past no just software that you must run forces a service that you use is that the load balancing and Kaka is very manual so when you create a topic you need to figure out where the shards are
 like which machines and then overtime it's the load changes on your topics you need to move load around on the on the individual servers you do get some high availability from the fact that the load will move on its own it fail overs but it's not like load balancing it's really just load for a failover redistribution and we have load balancing an AR platform so that's something we kind of throw on for y'all to make our lives easier and to make our customer experience a little bit more smooth over time
 so when I get into the the pass vs. software discussion but one more question about the difference between Kaka and the underlying software eventhubs uses HTTP client amqp and I didn't know anything about this protocol before I started doing the outline for the show know what it what is the impact of this difference of of Protocols of protocol for Costco's not HTTP it is so it is a proprietary protocol that's just written for Costco and the the reason they made this decision is the same reason we did which is the hdb I have some very high-level constructs around request response and so it should have limits what parts of the TCP IP stack you're able to use for things like float
 troll or B Transmission and the bees are these are shortcomings that are pretty bad when you get to a very high scale system so our choice to go with the m q p which is Advanced message queuing protocol always largely based on the fact that we use that for other messaging platforms and that it's in ISO Oasis nicey standard and we're all about getting people out of Standards so that it's easier for them to come to or leave our services if they so choose a man so really are Choice there with mqp had to do with the fact that even though it can be a difficult protocols understand the flow control system in it is excellent and it's a credit-based flow control system that gives the sender and the receiver a credit channel in which they can tell the other party that they can go faster or slower in there sending this is actually super sophisticated our clients do it all behind the scenes for you it's nothing you have to really do much to to know about
 give this An Elegant way to to both throttle Sanders when they are exceeding their their purchase quote is a man to not just knock readers offline by shooting tons and tons of messages. Then I'll because of the protocol deep deep down actually is bi-directional and even though you're a consumer maybe you could say connecting to to receive events there's actually a push on the channel happening from the service to your consumer so this is kind of turning around to the sure to request response and you open a request and you get many responses push to you and it it can really cut down on latency times and its fiber really really happy with it and interesting ly htb2 is promising to solve some of these problems but we were really big on going with her we've been using is protocol for 3 or 4 years now we're really big on going to the protocol that we already know that is already standard and that we think will be increasingly used by more messaging
 as time goes on
 you talked about the differences between the event Hub has versus kafka's software solution evaluate the advantages and disadvantages of managed Technology Solutions Merchant versus the the unmanaged raw software versions
 yeah this is a critical question that a lot of people left face I'm in the way I would kind of way I would kind of position this is it that the easiest way to understand these is not understand the the sort of Workforce in environments you already have so if you have the skill-set necessary to run Kafka and the attitude to do it well which is not always the easiest thing I'm then you're probably in a pretty good place with that you can give you can certainly get very low latency out of Kafka you can do great things with it but not everyone can have the resources necessary to run that kind of platform especially in a 24-hour environment in a in a really reliable way so the question is really about trade-offs is how much control do you want which comes with responsibility versus how much sort of these do you want and so when you when you use a service you're having a compromise on some things so for instance a compromise for us
 is the fact that are latency stand to be in the 50 eat it at 102nd range where is if you're running or not in the cloud environment Albany Hardware you could get much lower than that with actual disk access speeds being pretty low but you know what you're bringing with that other other trade-offs like application windows and Corruption that can happen there and also just pure cost of running a wee is a past service or probably less expensive than we should be but you know we we deliver what we think is a lot of value for a very low cost compared to running a non Hardware weather in Cheyenne Serena private Data Center
 we're talking about these managed Solutions I would love to get some idea of how eventhubs compared to products from other companies is it cool if we have like a discussion Love cover the comparison shopping yep sure it's a discussion I like to have another service very fond of him anyways if you're in the neighborhood so I'm happy about that. They started off more different than they are now and they're still there still have some pretty distinct differences the biggest differences are that was always designed to be a sub 2nd sort of system and Kinesis it first was not although there late and she's improved a lot since they've been public
 better first a fairly High latency and they've done a good job for sure to driving that down conceptually there fairly similar they will call partitions as shards they've made a few big design choices that that we did not on purpose and one is that for them you actually pay for the shards you have so you pay an hourly rates for every shard in your in your stream and you can change that number of shards to to scale up or scale down in eventhubs we've chosen not to charge for partitions and you use a different scale mechanism which is just an hourly pay mechanism to purchase through put out which is spread across all of your eventhubs so we don't allow the rechartering but we also don't make you restart so there's no cost recent apps to Rashard mantis as nice as the concept kind of sounded first 4 restarting it becomes quite difficult especially if you have order requirements which we kind of address earlier
 I'll because now you've changed or something's living over time in a in a durable buffer that's going to be around for a while so if you rewind that buffer you have readers were behind reading someone partition Richard now all of a sudden or data will be in a different partition Rashard and soul I have to do a jump between those two so Kinesis does give you the ability to change your shower it's manual you have to restart manually by by splitting and merging charts and then there's another sort of difference to in the tars using this the same QP model rather than the hdb model of Kinesis we've always been sort of biased to very many concurrent requests for AR platform now. Cuz where you were using this binary protocol then let's just go real fast with a lot of stuff and the peace model is more towards sort of put records so putting a bath
 and you get a settlement back that tells you where or how each message in that batch fared where is for us who we do batching as well but it's more of an atomic operation and we do a better job of supporting multiple concurrent requests which Frost can be up to like a million concurrent request so that's it something we push pretty hard on it is is the favor of concurrency over sort of matching
 hey Google has a product called Cloud Pub sub it is this analogous to eventhubs
 Pepsi pretty cool product to actually iPhone I played around with them a lot and it's interesting because it's kind of like eventhubs and kind of like our service best messaging platform it's Unique and I actually think this is really unique because all three of the big cloud players have chosen a slightly different way to tackle this sort of Challenge and so it we don't really have a situation where were you flat out in head-to-head competition with each other and we're all trying kind of different things and then Pub sub is certainly similar in some ways and different than others and the ways it's really different is that allows you to have many many many subscribers where is RR model is less about having a lot of subscribers and more about having a whole lot of throughput I'm So we we think we have a higher throughput model but a lower subscriber density model if that makes sense and then they are also have some other cool features
 they're like a like a h-2b push capability out of the subscribers which is also pretty interesting so you can kind of push two two app engine components further Downstream so yeah we've all kind of taking a different approach they're all very useful in their own ways and I think it's actually kind of cool to see this much Innovation the space
 this really interesting discussion I think many times the lens that people look at it through his is a little more of a hyper competitive old world lens than a more modern contacts cuz like the more modern context is that the idea of quote cloud computing or what whatever you want to call it platform-as-a-service even infrastructure-as-a-service the demand the value offering of these the set of Technologies is so gigantic and so multifaceted that there really is room for such a multiplicity of of different providers and and I think I think one of the things you in a kind of sounds like this it depends on application requirements so what are the types of of application requirements that the Azure stack
 trying to optimize for
 that's a really good question the place we're still targeting which is kind of a traditional area for Microsoft is really in for the Enterprise space or the space where reliability and durability are probably the the biggest concerns and scale sure is a great concern to but a lot of our sort sweet spot is it across all of our services is really when you're looking for something that's secured and Skip and adorable and you know has a has a lot of sort of ability to
 work overtime and be supported overtime so that is really kind of our approach we're trying to make the cloud easier to use that's why we're pushing so hard into into pass and Sass services and not just I had services and I think that's kind of the the the place we sort of set our sights and sort of the way we're really kind of leading and innovating in again like you said it's not that people are going to say that it's just one cloud provider it's it's picking the right tool for their needs and some companies will have different needs and we can provide but we think more in the sort of Enterprise space or even to to the lot of startups the cloud brings a lot of different models with it then we're probably better positioned in in that sort of space especially in in the context of total cost of ownership which is something with our pads and Sass Focus we're really trying to drive down TCO on I-90 technology
 platform rather than just having a should have a commoditized compute platform where is platform that you can just run what you've been running just you know for 4 less money and I'm more scale total cost of ownership yes so this would this is a good one I come from Consulting originally so I always have these things on my mind I mean not Microsoft Consulting outside Consulting so that would be the the cost of a solution over till lifetime so that could be you know there's their costs we all think about like building something in the cloud we all think about usage costs cuz they're deceptively we think they're easily calculated although they're not always and that is a really combination of those things over time the cost to take Subutex rebuild something the cost to takes you for like running the platform and also maintaining the platform so it's really kind of the whole all in cost
 front of your service over time
 to my impression is that the way to actually compare these Technologies is not by just looking at the pub sub streaming service but rather the entire stack around it so you know whatever other Technologies in Azure complement the pub sub streaming service so what are some of the other Technologies in the Azure stack to have synergies with event hub
 I one of the one of the easiest to get started with his actually stream analytics this is a great service we've had out for a while now very close colleagues of mine that I work with regularly they have a really extreme processing Base Service which is letting you run sequel like queries on time Windows of of a stream so it actually enables you do very complex things things that are very hard to do in code very very quickly and easily it's also another path service so you get the added benefit of not having to run a platform I'm in it integrates directly to eventhubs both as a reader so consumer eventhubs and is a publisher so you can actually assemble pipelines of processing that happened to different stages of eventhubs and other Technologies and really cool part about that is that they actually have the ability to write to to not just eventhubs but also to are queuing system to a blob storage
 2 sequel sequel a asure and power bi so a lot of other three like 12 others that I didn't mention but a lot of other assertive Downstream components where you can with the output of your calculations or your processing on a stream or use so for instance that amount of itself doesn't actually do any processing reformatting or word time with no base calculations and there's a way to very quickly and easily but those capabilities in we also integrate pretty well with HD inside hdinsight actually ships with a storm spout that could read from eventhubs so you can use storm on HD insights very easily with eventhubs that she worked quite well together and those are kind of the earth to biggest
 sure ways to go and then finally the last one would be our our platform for
 service Fabric and service fabric is a very cool very powerful distributed computing platform and I guess those 3 would be listed then in the scale of like sort of lewisboro to entry but maybe with some limitations to the service fabric part being the absolute most raw power to do pretty much anything but you know with a lot more sugar coating work you have to do yourself to get it done so we ate half a pretty good Continuum that address is sort of the the code list to the to the pure code distribute Computing and kind everything in between so we're pretty good ecosystem there
 and looking at the different ecosystems Azure and AWS and Google do you see these mapping to specific like a consumer verticals and I know you mentioned as you're going more after Enterprise like how do you see the space evolving overtime in terms of customers that these different Services want to I want to appease
 yeah that's that's a very good question I think for Azure our focus is very much on Enterprise iot pieces like that and overtime will probably Branch out there I could definitely see a bigger space in sort of
 I guess cloud-based social and cloud-based value-added services that are outside Microsoft but running in the Asher ecosystem Google I don't see is maybe being a as developed on the on the tools were integrated Services standpoint and and Amazon it's a student fairly good job too I think that they'll probably compete a little bit more for the market we're going after other trying to wrap up their their pads off rings as well I'm right now most of their offering it's really more targeted towards towards developers or i t admin and really kind of need a mix of the two where is were really more targeted towards the devops audience where you don't have separate i t admin and developer teams you have one team moving very quickly hands and needing a broad set of tools to be able to meet their objectives
 I see a few different arguments when I read about the stuff in terms of where we're going with portability so like I think you know the exact same question like how commodified Willie Services get how easy will it be to move from one cloud service to another support your infrastructure mean if there's this site may be using Docker to magically containerized everything in your infrastructure and throw it in a suitcase and move to you know a different cloud service provider what do you think is the is in in store for the future in terms of like how to modify the services will be and and how intense the lock-in will be
 yeah that's a great question the Locking one is kind of a very interesting it's it's why we've seen a lot of people take this sort of lowest common denominator approach their Cloud Solutions cuz they want this ability to move between Cloud providers and there's there's some value to that for sure it's that concept of it then there's the bigger question of are you actually going to make this move and is it really going to be as easy as you think because when you start off so you're just thinking well okay I have infrastructure running okay you can put infrastructure anywhere but it's you get to specially to a more assertive agile you know of continuous delivery model are your building a lot of stuff to tie this infrastructure and deployment together and everything your building is making it kind of harder and harder to move so you kind of given up all of the free stuff you can get from a single vendor sort of proposition in both all three of the vendors offer things that are really targeted towards their platforms but you might not be getting as much as you think
 it might not be as easy to switch from our standpoint we're trying to build Services based on a standard protocol so it's as easy as possible for people to join and leave our messaging platform I'm and we understand and I should be a lot of customers who run Parts their Cloud work around other Cloud platforms and that's totally fine and now another operating systems within our Cloud platform so we're really not trying to be a Windows Focus service actually working very heavily on on clients for for Linux and both through no to Java right now because we we really see ourselves rather than sort of a specialized bike platform a specific you know Windows specific offering to really be a sort of like you said almost to come out of ties service it's easier to plug in play and I think if you look at our at eventhubs and Kinesis moving between them is certainly possible
 it is not necessarily can be the easiest thing to do but our our hope is with mqp part that overtime or more messaging vendors be in that space we have quite a few already red hat is use GameCube so overtime really are objective is to make it and it's painless for the messaging components for people to either come to you or leave our platform we really think that will push us to just provide the best service possible we don't feel like we need to to use Fender locking to get business this way and we we have some momentum behind that because the you know it's actually being pushed the federal government level in the u.s. for messaging platforms used by the federal government to use the MTP protocol so we're kind of trying to stay on board with with the whole industry there and we're trying to take a more active role in it and trying to really kind of move away from this this idea of this is a Microsoft messaging
 a form to be this is just a messaging platform then you can pick the right messaging platform for your needs you know regardless of the rest of the stack Cloud perhaps I think we're already there are two large extent I think the way that's really started that people have realizes it started with sass I'm so and I think it's bleeding now more and more into a passy type Services I think something like Dropbox was a great example you know where you're you're really I mean you get some benefits by going with one cloud provider but you're probably never going to end up with absolutely only one that mean you tons of people use Salesforce doesn't mean they shouldn't use as your Amazon services with that that's just you know reality
 what's the future of eventhubs
 how we have some fun stuff we're looking at for eventhubs were looking at a deeper integration into the Azure platform itself actually submit equation with outside services and and software makers which will be pretty interesting I think as well and then we're also looking at what what other sorts of problems are people trying to solve related to to Telemetry processing we know that we've spent a lot of time and energy focusing on this whole sub secondary fast data problem and we met it very well for our core big big customers of what we think there's actually opportunity meets um maybe not so fast data challenges for other customers so I would say sort of integration is you know branching out into Thai inches are 100 future path that we are already taken and then start branching out into other service offerings that are complementary would be kind of the other way we look at it
 yeah I love the bright future of of iot I don't have a sense of how close we are to the realities of that bright future like I feel like we're a scam toting towards it and I just don't know how close we are what's your sense of of how close we are to like the brilliant future when our refrigerator is talking to our phone talking to our car and what not
 I think it'll be sooner than people realize and even just within those I think the Innovation needs to happen within those Industries themselves so it's interesting to look at something like a shirts and iot platform Microsoft not really trying to to run the car business and the phone business and you know the television business they're really trying we're really trying to put a platform in place that people in those Industries can run their platforms on and that's the that's the sort of the piece that needs to happen building a a scalable highly-available platform is very challenging and if we if we can do a little bit to alleviate the cost and paint event then will actually rapidly increase the speed at which innovation happens on top of that platform and that's that is what's happening now and I think that Innovations pretty close to taking off and and wants to happen stop
 a lot a lot faster than we expect cuz if we look at this or that the progression of Technology you know a long time in the past you had to actually figure out how you were going to store data and Right Storage code I know I'm a server a long time ago we gotten past that sort of challenge we we just keep sort of extracting up higher and higher levels and we're getting closer and closer to the real value delivery here because you know unless you're on the address storage team I don't think you really care about how storageworks you just expect me to work I'm and if you are doing something like providing smart meters or or you know in home connected experiences you really don't care about that at all has zero value for your customers if your business so the higher we can extract these pieces that the faster that innovational happen and how high can we get that attraction if you think people are going to be able to just point-and-click and develop their apps entirely
 from a web browser will I be able to wire together an entire iot infrastructure just by clicking on things in a web browser
 I think eventually yeah
 is that a goal of azure bad I can't speak to you but I have but I actually think it could be even easier than that at some point we'll get to if you look at you look at the way Bluetooth devices interact with each other and that's been a very very long painful process to get there but it's already pretty remarkable what they do and when we think about what 20 years experience on that teaches we can get too much more simple sort of self-assembly South configuration type experiences it'll be really really expressive really customize I'm in bed really more software configured that hard work and figured so weird I think we're getting pretty close if I think about like an insurance company or a you know some Factory that's producing canned goods
 you know there's there's plenty of people at these types of organizations that are technologically inclined but they are not programmers so they would be able to read some documentation and baby wires and stuff together from a web interface but not necessarily be able to go into an IDE and write code to hack together a full stack app and why should they have to absolutely in this is the the challenges that those people in those Industries they are the ones who will have the ideas to drive Innovation so until we make it easy for them to do that they have to make very risky big baths you know that they don't often pan out and it's it's very hard to get to if you look at the great Innovation Insurance base has been the plug-in dongle for your car you know that's actually very simple technology and it's totally makes sense in the insurance space and all of the time
 used to it is existed for almost 20 years but it took until very recently for that to get moving out every major insurance company offers that ability to change your rates based on your actual driving behavior yeah I see that this is why I like doing these shows about Microsoft cuz it's so you're not to be critical but like it was so easy to be cynical about Azure before I kind of really understood what was going on I was like okay it's yet another cloud service but then I just kind of started looking into it more inside are standing just how big the ecosystem is in this Enterprise you know Nann programmer to programmer enabling it's really interesting it's really optimistic future and I liked it so well then thanks for coming out of software engineering daily it's been it's been really interesting talking to you about eventhubs and the rest of the edger platform
 thank you very much
