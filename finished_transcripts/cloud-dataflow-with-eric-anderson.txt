Transcription: batch and stream processing systems have been evolving for the past decade from mapreduce to Apache Storm 2 data flow the best practices for large volume data processing have become more sophisticated is the industry and open source communities have a generated on them data flow and Apache be more projects that present a unified batch and stream processing system a previous episode with Francis Perry discussed how those systems work in detail and in today's episode Eric Anderson discusses Cloud dataflow a service from Google that lets users manage their data processing pipelines without having to spin up individual servers to run them on cloud dataflow is like the server list movement that we've been doing several shows on it represents a growing shift towards Cloud providers offering services that abstract away the operational challenges of a managing compute nodes this is a really important area and if you have any suggestions for topics around this area please send me
the serverless stuff is really fascinating this decrease decrease and needing to manage your own servers and certainly if you find this episode interesting you will like the previous episode with Francis Perry where we really went into detail of windowing and Lambda architecture and all these challenges around stream processing it's really fascinating area growing importance I hope you like December schedule
 continuous integration is so useful that I've started using it on my own personal projects snap CI from thoughtworks has the fastest setup I've ever seen I registered for SNAP CI with my GitHub account and after a few clicks I had continuous integration pipelines setup for a no JS application and a rails application that were just sitting on my get have account and I don't want my users to experience breaking changes so I want to run a large sweet of test for my application every time I push a change and snap see I will run those test quickly in parallel on a worker that snap CI spins up and takes care of for me what do you have personal projects like me or you work at a company that is looking for the perfect tool to improve the deployment process go to snap. Co / software engineering daily snap CI and bodies the lessons that thought Works has learned from 20 years of software deployment the
 watches that have been written about by Martin Fowler and Jazz humble check it out it's snap. Co / software engineering daily it would support software engineering daily and you would get to check out continuous-deployment snap. CI / software engineering daily thanks for listening
 Eric Anderson is a product manager at Google working on cloud dataflow Eric welcome software engineering daily we've discussed this I think like before I even start software Janet Dailey when we had lunch at Google in Seattle this was back when I was still working Amazon so that was quite a while ago but it's great to finally get it going we had a recent show about the history of data flow and streaming with your colleague Francis Perry and that's a rich topics I'd like to start off with discussing that so from your perspective how have the definition of batch and stream processing evolve in the last decade and how would you define those terms today so they look at kind of been a generations of processing systems
 how do you say you're familiar with mapreduce kind of the initial model for batch processing or processing in general but was in fact batch processing
 most of the data programming model from a previous was very manual you want to call it that you specified every specific and one of the first things that happened with an evolution of the programming model so we went from Maverick style to something more like flu or crunch where where you specified higher-level objectives and processing and then those systems those api's maps to like the day it would translate your high-level logic into a lower-level mapreduce first generation 1 and 2 with patch and then the initial efforts in streaming probably best characterized by storm what kind of best effort many ways they are when I should set my sister and I mean early versions of storm surge actually got a lot better but you know you would slow latency and in some cases
 I did a process and guarantees there was some women City to be happy I am what you could describe in your in your pipelines and then more recently were seeing emergence of I stream processing that is actually an alternative to replacing the patch I think systems like Flink or beam dataflow our arms are making a stream of a First-Class auction for processing description of the chronology and you know it's interesting cuz she talked about how these ideas evolve dead Google and in the meantime they were evolving outside of Google at Carver parallel track could you talk more about
 what are the compromises that the earlier streaming systems were making that perhaps are not being made by systems like flank or data flow or beam in the modern systems are turned and we may play this point but like event time processing versus Cicero system arrival time processing for on the show the initial systems all focus and when events arrived at the system by which is kind of the easiest place to start and maybe the most expensive simple way of processing the day and these did the newer models
 are taking into account the time stamp that comes on a payload and allowing users to describe Crossing logic based on the event time which is more useful and you can recreate sessions and Dimitri reality better so so that's one distinction and then the other is data processing guarantees generally The Ivy early streaming systems were some variation of at least once or at most once processing where at least once was probably most common and what I mean by that is in order to ensure that everything gets processed cuz it did There's chances and all the strippers systems that there's failures on the way and most disturbing system
 at software building is all about handling the fact that you can have failures in any case of failure we just been in a relationship since we would just be run again and it was unclear if I got reported to the service or not but if you want to wait and see that's what you had to do
 write two situations yeah exactly once processing difficulties I think good analogy for those is you know if you want to ensure that something has been processed exactly once it's almost like the the the complexity in the labor involved in doing a three phase commit or two phase commit for a database transaction which as we knows somewhat more overhead then then you might expect for you if you just look at a database transaction from the outside looking in so so you know it's it's it's nice that there are some some abstractions that are being introduced that give us a better guarantees around exactly once processing and you know the the Google dataflow paper suggest a movement away from these Notions of batch and streaming Francis talk about this a lot in the
 discussion these unbounded data sets that were moving towards why are we moving towards this world where we have unbounded data sets
 so I'm glad you asked this is something I am pretty excited about it I think there's two reasons and the initial move time down a day of stats which kind of course play with these early shooting systems we spoke to was all about kind of nice use cases for the wait to see I wanted to know dating now and I know I would get my answer at the end of the day or week or however long it took for my bass Justin's to to finish but advantage to having what you might call speculative information now and this is reserved for situations where
 latency was really critical radiation of of latency there was some system to optimize for like the super low latency on the order of milliseconds in but most were on the order it was and help me make my business Bill operate on today's date I rather than 3 days ago data that was kind of into those some but I'll jump to what I'm seeing more today as these systems mature and ways that they can replace bathroom and use cases
 we're seeing people adopt streaming first just everywhere so it's not it's not an issue case thing it's going to a streaming first system and its track my business reduces my operational complexity I have less kind of us batch scheduling and gating and also reduces my kind of cognitive data complexity I I just know that all my data as I see it is as early as like all my data when it hits rest is as fresh as opposed to wondering if this batch ran when does the next Bud bash run did this job actually get completed
 so I forgot I think I think I got you a questionnaire that
 there's an issue cases but increasingly people are just using streaming everywhere
 right and this is in contrast to what we did in recent years what what many people are still doing with the land architecture and for those who listen to the episode of Prince. A lot of what we're talking now it's kind of a rehash of that episode will get into some due to new content but I do want to go a little further into some of the same things that we talked about with Francis because I think these are really important topics in there things that listeners are probably confused about or have questions about even if they listen to it before why don't you explain what were the problems with the land architecture what were the drawbacks of using the Lambda architecture and you know what do we get now that we're kind of moving beyond that and having it in for those donutland architectures this this way where you have stream processing and then you have batch processing to reconcile the problems that might have occurred during stream processing so maybe you could talk about how we're moving beyond the land Ark
 so deal and maybe had two problems one was first just complexity and duplication and then the other is the fact the organization now has to deal with two sets of data and it's unclear what's the source of Truth so going back to the complexity and duplication you'll have basically two streaming systems processing systems you have your batch system in your streaming system and again with the early framers or even today most data processing systems are tuned to either bachour streaming so now I do have two systems for the different systems and up until recently you had to each of those persons how do you need AP I generally be traded api's two systems that are specific to how they ask you to data
 so you have your meaning to distribute Computing systems they each have their own API and she probably need two teams and familiar with the if I find serve been written in each system
 so that's that's just the complexity is that you could give duplicated amount of work to process your data in order to to to to to process one set of data and then the other side of this is is the fact that now your business is dealing with two sets of data as well so you're making decisions today you know in near real-time about what they're telling you knowing full well that that isn't actually very accurate or or it says limited accuracy and at the end of the day you're going to get Bosch data or did a week and then it's your hospital like reconsider way they made the right decisions and there may be some confusion with him to worry about you know there's multiple numbers being passed around for the same thing
 so I think that those are the two things I see is the fit the bigger drawbacks hear our system complexity location and and the kind of organizational in a confusion around so we had this land architecture that was built to accommodate our streaming systems that may have had some problems and then now we have newer streaming systems that resolve this problem that we had with the original streaming systems where there's this potential for for duplicate processing there's this potential for event time skew which is the difference between event time and processing time so let's talk about that that ladder feature so how do these newer stream systems like data flow get over this event x q how do they accommodate this problem that arises where there's a difference between the time that a no
 event happens and the time that that event is processed
 yeah sure sure this gets at the heart of the issue when it was starting so early she took a follow the same path as batch wishes you can process it once you know it's all there
 well let me start by saying generally with deer processing you on Saturday data and 2 aggregate data at you you specify some bound on on that grouping I usually it's just time that I could be like the satisfaction I use recession taking time for a moment the system using using system time could just wait 5 minutes and it is ask the the time everyday shinano process the most recent 5 minutes and it was kind of just like that I would wait until I had the known data set in front of me and I will process it with if I move to event time it's unclear when I have the last 5 minutes of events because they may not have arrived they could be late
 we're late is some relative term that's not too useful right here now but they may not be at my system when I think it's probably about time to process the last 5 minutes
 so we have to introduce introduce some way of deciding when to process data and the three concepts that emerge in in the day flow or B model are windows triggers and a watermark which healthy reason about when data when it's time to to process navigation when it when we thinking of events are here to make a meaningful a creation and users using those things Windows triggers and what and Watermark can articulate I'll let you know the universe of possibilities for how to handle this lag and data between the Bedtime processing time
 got it and we talked about those in more detail in that episode with Francis Perry about to get into some more discussion of what you are working on more specifically you are the product manager for cloud dataflow up until now we just basically been talking about data flow and data flow is this paper that came out and it's it's just dreaming system from Google cloud cloud dataflow is slightly different it's a hosted version of that system so I'd like to get it to talking about what this does the business model has officially Google's Cloud strategy explain what cloud dataflow is so earlier system it requires use of the be more data flow sdks
 so it ended up being project is our kids are open source that's the case I would describe him jobs and make me ask you. Number of Runners at as we call them or systems and one of those is data flow of data flow
 so Claudia flow is it is fully managed in a sense that all users need to do to be to use a flow is just submit their code to service and the service takes care of deciding how many resources what kind of resources need to be deployed to turn that job and then tuning and monitoring the excision a job so that it's optimize and and then end up returning the results to you and in the way used Best Buy so it's it's it's a bit more hands often the most
 approaches data processing what are the challenges around resource management and performance that developers conference this with you know if if I'm going to what I had to roll my own my own servers back in the day you know I think this is is analogous to how people are managing many of their data processing pipelines today you know you you you you host your own or you had or you hosted in and Google cloud or AWS or whatever your own spark system or storm system contrast that with what the experience is like if you are using a hosted version cuz it because it's kind of a subtle difference yeah so so while fertile circle with we can talk generally about hosted versions but let me also stocks before you about it later folks it's slightly unique in one aspect in that
 we kind of gotten rid of the idea of clusters so normally when you from the point of the user
 you are deploying and they are processing job you first replace a Cluster meeting you you kind of allocate several machines you install the framework of choice on those machines and then and you can figure the cluster your specifying if you're in the cloud you're choosing certain instance types that might be optimized for the workload at 11:10 to run on the cluster and it you enter choosing a number machines that fits with how much you want to know how expensive you how much you want to spend on on these jobs and how quick you are the jobs done so so that the business decision to have to make are embedded into the how you kind of configure this cluster
 jobs you you submit them to the the framework the sitting on the cluster smarter flank whatever other than executed and you're monitoring the performance of the execution to check to see if you need to adjust the cluster configuration like perhaps you realize that your CPU realization is low and so at a certain stage of pipeline you're thinking maybe I'm I memory bound romallo bound and so you may adjust your your instance type c or the resources you put in the cluster to to fit you are processing maybe too much detail there
 so it with the flow rather than first grade in a class there and then submitting a job you just submit a job to the service and then we we we spent up necessary resources at the time you sent the job we just spent at the end behind the scenes
 process your job and then tear down the machines there still some you know you are still need to be cognizant about some level of how their job is being executed and and what's the best way to specify how the job should be executed but we're officially trying to remove those but they need to think about those things more and more right that's great explanation so if I am a developer who already has some mapreduce jobs or storm processing or some spark or some flank how do I get started with the manage data flow service what is the onboarding process going from having my own jobs in a specified on my own machines to getting it moved to the managed service
 and let's go let's think about this I'm going to hang I'm expanding questions maybe in two ways so one is if you just wanted to run that particular job today on on cloud Running Man service Google offers this product Cloud dataproc which is similar to other managed to Duke's park services providers you could go there to just run your job today the other dimension to think about would be if you wanted to to move towards using the beam API the V model and you already have a sore arm Swagger Flink
 at your disposal as a as a cluster or is it system you could begin to map some of the logic you know right some logic of your original job in being an executed you beam on your your your local system you already got set up so those are too kind of intermediate steps towards dataflow I would imagine but but to get to your original question that the first thing you do is witch's map the concepts of your logic in your current pipeline to the V model which we found as demonstrating some examples we published is is generally fairly concise a lot of
 a lot of the kind of code in Denver Varsity in current pipelines are are accommodating for some of limitations in her pipelines so if using the remodel you may find it's pretty straightforward way to write her your work and then user experience is simply you would probably get it locally first family best practice to to confirm that what you think you've written in your pipeline is in fact what it's doing and you can check with on some sample data things are working great we just change one flag in your local execution should to tell it to submit to the service and then it would still run that that like python or Java process locally but it will prepare pelo that we then submit to the Google Cloud API and execute that job I did a full service
 so I climbed beautiful seems to me like it falls under the purview of this kind of this serverless idea is not exactly the same as most people are using that were these days are you jelly talking about Google Cloud functions or AWS Lambda but none-the-less in Cloud dataflow you have removed the idea that you're dealing with servers that is no longer a concern of the developer and the stuff is kind of bleeding edge it's it's not been heavily adopted to my knowledge I mean there are people who are who are adopting and everybody can recognize the improved economics out of it but I do get the chance to the general people are a little still a little gun-shy to adopting fully managed services in adopting serverless type of stuff what who have been the industries that you're
 adopt Cloud dataflow most aggressively yeah yeah it sucks EXO baby just a comment on the services bit sure and we week we go back and forth about calling David full service service server list the but yes it does fit in many ways in that category station and also it's unclear as these terms go with them and I'm very excited about where the siding so yes you're right in that it from user experience you just worry about code and you don't worry about execution you have to think about how execution is happening
 the the other part about who who is adopting dataflow as as may be kind of related to who is adopting serverless thinks it's maybe a similar to early Cloud adoption it's generally we're saying it from
 did you tritional or our situation but the startups the kind of digital natives the people who are already on cloud providers this is this is like less of a leap for them to offer two examples on Spotify and has been very vocal about their enthusiasm for dataflow they were in fact written a Scala rapper on the job SEK which makes for many people they have to be more approachable it's very there rappers are similar to spark so excited about what they're doing and lots of other companies and I'm from your retail start-ups like Zulily to
 financial services companies like there's this group FIS Global that is using data flow to actually analyze every single stock transaction on the US Stock Market pretty amazing so I guess we're seeing it first found one dimension is it is early doctor's to Cloud which is officially been kind of Silicon Valley startups but also this other dimension of people who just need really have really big hairy big daddy problems like this FIS Global Group who's using to analyze the stock market they just
 they don't make them the time what they were trying to do without having a managed service in the in the time frame they wanted to do it and ended up using data flow
 that's interesting to have they talked more about that use case or maybe you can talk about the Spotify use case I'd be very curious to hear how their experience has compared to when they were managing their own their own clusters of of flank or what whatever data processing system they were using you know cuz I just love to hear about the operational burden that has been removed streaming Pipeline and the dogs called that look like there's a off and ingestion Q if you want to call Dad or a buffer and then there's the data processing component and then off in it eventually gets persisted somewhere in some kind of analytical database Warehouse
 and Spotify head-to-head he was first introduced The Big Break which is a potato warehousing solution that is similar service server there's no you can't even specify anything about configuration you send it sequel queries I have a neighbor they were very excited about big furry and then when we entered is pops up and data flow to them
 yeah they jumped all in on sending basically all events user events after Pub sub and and then processing those events in car data flow and writing them two big braids and accommodation means I have I capture like my event system is simply an API like I just push it in San API my data processing system is I write code and I submit to a service and an indication of streaming is just running all the time without any kind of operational load Sands monitoring to see if any adjustments need to be made and then finally writing two big braids again is just submitting code to a rest API that there is the rest API appended to the table where you can dance to it sequel queries
 so that that's been the driver for Spotify is that they they feel like not only can are they getting world-class products work with but they don't have the operational over head of of teams that are maybe know where to put his it changes to be signed like a cluster was like we maintain Fleet Custer the spark cluster and it wasn't clear that they just seems had been the time to actually innovate on the the pipelines which is really where you want the work to be done instead they became kind of unnecessary overhead to maintaining so Spotify as an illegal to redirect those efforts into to moving the needle on the business and now Spotify is also well known for having migrated to Google cloud from AWS not too long ago
 that somebody was in there moving to the cloud and it was unclear you know should we go double down Google right and so did I guess it is kind of questions do you need to be on do need to have most of your infrastructure on Google Cloud to use Google dataflow
 oh I know so that's a great question so the certainly The Way We Were first started I think what you're getting at is there some part of data flows requires input and output sources support from input and output sources and the initial sources we supported were of course the Google Cloud sources of those rare initial customers were and we knew we can make those great cuz we are working with the other teams and now and it recently we've expanded to contributing additional input now for the source support and this is this is falling under the open-source being project community so we're saying people can Shiba Inu is support for new input and output source is all the time in case of streaming there are within
 project does not Costco support if there's Kinesis support we have customers using both of those anyway we could go on and on about the other systems and services this is a point of connection between two different Cloud providers which is which is interesting to me cuz I haven't done many shows about this heterogeneous Cloud architecture that seem to be moving towards this world where their yard and it is going to be like heterogeneity it's not like you're going to be in one cloud provider and you're totally locked into that cloud provider it seems like the direction that we're moving in is you are you know in 10 10 years or so your stuff is going to be just you're going to use a cornucopia of different managed Services maybe your piping your data from Amazon S3 through Kinesis to Google tensorflow
 and the end I'm just curious about what your vision is for how that might look interesting is that there's a bit of a fallacy in and how Enterprise adopt these technologies that we can be think that people you know it migrate or they rewrite things which happens but it's generally a lot of work and we've found some customers and it usually where I see people adopting the new stuff is always in the Greenfield projects the things that are starting new or when you have enough it when you were rewriting at reassessing stack anyway I was with a customer yesterday
 who they want you to introduce War Machine learning into their kind of data stack and so they're reassessing the whole day to stack and send me everything star game to being redone in the NS where is pretty good considering using data flow and I'll probably start with Kinesis and then move further Upstream on Google Cloud
 so so what year what does the future look like I'd I see as far as it's like crossed Cloud situation yeah I see people adopting the the best fit technology for their needs
 as as as as new project it's been up and then once they hit some kind of you don't know if they feel some gravity towards a cloud provider or solution it made my great legacy things at some point but generally yeah we're going to we're moving fast enough that we're going to be in another kind of multi environment world for awhile as teams adopt the new the new and they don't spend the time to sail to migrate the old thing immediately
 Aluma is your data pipeline as a service with a Luma you can create custom analytics with Amazon redshift Aluma is a fully managed tool for pulling from different data sources MySQL postgres elasticsearch Salesforce many others the code engine of Aluma allows you to write custom python code over the data stream to clean and in Richard data and the mapper allows you to control how your data is loaded to your data warehouse if your schema changes use the auto mapper to handle that change to find out more about iluma go to Aluma. Com SE daily with a Loomis customer analytics you have a holistic end-to-end view of your business join your marketing data with your Salesforce data for example and discern the true value of your online marketing campaigns go to a Luma. Com SE daily to find out more that's a Luma. Com SE daily thanks to Allah
 for being a sponsor of software engineering daily
 you know I think there was a. Of time and we're still somewhat in it where people are maybe a little gun shy when it comes to using managed services that that smell like they might get locked in like if you get locked into dynamodb it might be that the Amazons amazon-dynamodb and might be similar to feeling locked into Oracle and people are really cognizant of this but my senses that these these carburetors and you can crap if I'm wrong about this is the cloud providers are are getting cognizant of this and they are trying to do Architects their newer systems in a way that perhaps there is not as much locking and the switching costs is reduced be
 they get the sense that they're dealing with more sophisticated customers I maybe you can't speak to competitors but perhaps you could speak to what degree that is true with Google this is this is particularly poignant as Cloud becomes mainstream in the Enterprise so for some time clouds been so kind of start up for lack of a better word FedEx in a digital native or Claddagh or sore startup tech company thing and it makes these people are moving so fast that the risk them isn't a locked in as much as it is like not yet not growing over the course of the next month they're very near-term side door lock in the next 3 customer and search their optimizing for product performance now as opposed to like cost portability and long-term
 I thinking but as we move to Enterprise customers order or maybe more thoughtful customers as as Cloud matures and people are now thinking longer-term about their situation yeah lock-in is is becoming a bigger concern
 we saw for business isn't passing quickly forgotten you know the vendors of yesteryear trishul databases and that they would lock in customers and so-so Google cloud is doing some interesting things to mitigate those concerns so One Is our commitment to open source I think you're seeing that we kind of weed with an open source project and then we'll bring in managed services to help make a running nose open source projects fantastica Google this is true with my kubernetes and google-container-engine Truitt Apache beam and data flow announce that we want to do some things around machine learning that would align with an open-source tensorflow project so this is
 this is one way we think we can make this the lock-in decision for companies easy you adopt the latest and greatest open source projects then you come to Google to have a great experience running those knowing that if things work out for you can always bounce interesting the war-cry machine learning in tensorflow that you referred to
 sure it's so I'll do my best to try and stick to what we can ask publicly which is near Jeff Dean was on stage at a Google how to advance earlier in the year to mention that we wanted to to sing at that point like a private Alpha for cloud cloud machine learning platform
 and that platform I guess has several parts one Google is is releasing its own api's back by Google's on models so there's a there's a vision API where you can submit images and objects using a vast image detection model there's a I want to make sure I didn't these are all the poking out but there's a natural language processing API and there's a
 speech API
 all I want you to submit just data and then Google Maps that I can't like labels and categorizes that data based on are models so that that's my little chunk any other truck is running your your tensorflow code on on Google Cloud I want to things that was also announced was the fact that Google uses tensor compute units in to see if any future HuHot offerings involved I'm trying to set tensor Processing Unit TV use
 and and also and then the other part was the the managed service that helps you run tensorflow so I think that's still a nice important of private released to some customers but it's exciting for sure sure so is what degree is tensorflow is running a managed tensorflow service similar to running the cloud dataflow service I think so what what might imagine I manage technical service looks like
 if you follow the the pattern of a slow day flows you just used to me your code to service him and the service is all the execution work you could see something like that for tensorflow it should be you write your answers level processing graph to the service generators kind of two parts the answer for work I think in this is a bit outside my domain but there's the
 the actual processing of data and then there's the maintenance of models so you'll have them a model with intention flow that you'll either be creating with or without you. You'll be modifying and and there should be some presumably some version of models it's unclear to see how much how much of that is taken care of for you so given that you are a product manager on the cloud dataflow team you know obviously the user generally does not have to know what is going on behind the scenes in terms of resource allocation but since you're the how do you have been involved in that in that process like how you manage it like the discussion with the engineers about you know under what circumstances does do we scale up or down for a given job
 maybe you could just take me inside the product development process for cloud dataflow
 Sure so so what would you think about this is so we have a high-level like product Vision that is kind of our North Star in many ways of what we think the World At Large wants in general I've been processing and that kind of goes to this we use the term no Ops or no knobs which is used to your code and then we just we take care of it from there within Google the most of the engineers were tentative flow has previously worked on that our internal systems flu map of this and deck direct me there with configuration knobs as we come in and work cited offer future where there's people have to configure things by the pipeline that should be Auto detected by intelligent system so that's kind of weird when you can we find you know I an engineering work together to refine that vision and that we
 I'm once a quarter is it and it is as are planning process goes we would take a look at what's the next chunk of stuff we want to chip away you know where we at today where do we would want to come tonight score to the East Coast Division where are where the rubber meets the road I guess is is in the process of launching features so the product team we engage with current customers and work on getting feedback about what's working what's not working and we trying to steal that key back into the not not necessarily a common product they're asking for extra we should give them but they're asking for X Y and Z and all those things actually could be solved with a sushi delivery made for them and so anything a prodigal get together and figure out what a looks like
 and and that will go into what we call it an early access release and then if we go back to those customers who wanted XY and z
 and say so here's a usually caught up just can't imagine this conversation what's goes in a case of I think you brought up auto-scaling for example we're in the process of releasing auto-scaling for batch is now
 fully enabled by default and they're in the process of bleeding auto-scaling for shooting pipelines and so yeah we're right in the thick of getting feedback from customers about how they are experiencing auto-scaling is tuned where is this not behaving the way they would expect and then we'll go back to the engineering team and see if there's ways we can adjust in respond to this concern some interesting so we have done a bunch of shows about the evolution of the kubernetes cluster management system and how that evolve from the lessons of Borg which is Google's internal cluster management we've also talked about how tensorflow evolved from the previous system known as disbelief and the impression I get from the story of these different systems is that Google has this constant urge to roll the lessons of the past into a new system and so
 ham with tempered with disbelief tensorflow with with boards Cooper netease to win one of these systems updates is happening like if you move just bleeped tensorflow or from millwheel to dataflow what what's the internal migration story from one system to another that big do people have freedom to move or are they just finished voting with their feet do do people have to be encouraged to switch how does that work there certainly usually the freedom to to move there's a yeah there is also I think some discussion within the the group is a lot of debate about what we want to see out of our Merchant systems because I think we recognize that
 like certain you know I guess what I'm trying to say is
 teams have come to dataflow I said we'd love for you to support these things that we can move today a slow and that's where were you could say they should just wait to see what we build and then choose to use it if they like but it should internal customer dogfooding process that goes yeah exactly and an internally I think we all believe it you know if you are well supported system serves people better than lots of pretty supportive systems and and so there's people are voting with their feet but then they're also not judging you know what their preferred system in the direction I think serves their use case which generally serves everyone better as we get more informed about how people using the system soon accommodating them
 does is a win a migraine just having from an old system to a new system does the old system get maintained like if there's somebody out there who still doing disbelief maintenance or somebody who still doing mill-wheel maintenance
 so I can't speak of course of disbelief but in the case of flu and Mill well we're still running flu and no well within a Google over also there's an effort kind of like we've done with with being work we're separating the AP eyes and the program model from execution and we're doing what we can to bring those customers running on Trish on api's along with us into the future by having shared banking systems were possible so you can imagine it work we're constantly making improvements to the fluid millwell customers because we're improving the shared back in portions between dataflow Flume in Millville
 okay I see so you've reference beam a couple times we talked about this in detail in francis's episode what's your vision for the Apache beam open source project and how is that proceeding
 yeah that's where kind of tickled at least I am I should speak to myself about the progress of being so the division maybe has a few parts 101 is chop portability which is
 we're trying to save save the world if you will from we've all been burned by a new emerging technology like processing technology they were excited about I have to go rewrite some portion of our jobs and a new new tag and then there's a mix of job types within organization beam it is looking to be kind of right once Run Anywhere data processing solution so you can which is a bit novel in in data processing open source we've generally the the things you see any up and Apache Foundation are better excuse intentions with with unique api's so it's exciting to see you
 a job for delay solution as Eye Single API does not necessarily bring an execution Engine with it or components division is the the B model that
 which is the date of a model which we talk about some that we shouldn't to be describing your jobs and I waited specific to how the rescue that we should just described them in a general way which is which as we spoke earlier doesn't have to be specific to stream your back is kind of subset of the other and you can generally describe all day processing jobs
 in any single way and in those census being kind of is trying to be something like sequel allow you to describe a job in a generalized way and running anywhere
 I said to those are kind of it the two things that I think about suicide about being a I like the analogy to sequel show you know it's equal like we just did a couple shows about postgres vs. MySQL and you know there are four for a naive database consumer might just be like okay what's the difference between these I don't really care but there are differences in things like you settle things like schema flexibility or you know how the the database handles transactions when it's scales to a certain size and that you know that might have influenced on which database would would be best for you but whatever database you're using probably the select statements are going to work the update statements are going to work the same units equal as this unified language layer similarly beam is this unified language layer for specifying
 how you want things processed that will be there will be handled differently depending on the underlying execution weather execution engine weather that's storm or flank or spark or data flow or whatever is the system that's implementing the underlying processing of the beam the beam schema design processing design so maybe you can explain it what are some of the trade-offs that these different streaming systems are making like if I specify my my beam data processing Piper Apache beam data processing pipeline in beam what's going to why would I choose one system over another pretty underlying execution engine
 that's a great question so so so one one might be a performance question another it comes down to how well they support the V model at is it probably be like like some some cars May support certain features of the B model the others might not as a picture inside people may choose different Runners based on access to that picture and then I going back to Performance I think you'll see systems that specialize in certain forms of low latency systems that will will specializing in data guarantees and Spectrum
 in the factors affecting it for inspectrum often are your desired latency your data shape and so I will see and we're already seeing some Runners that better at certain day shapes and better it at certain latency requirements
 I want what I may be as a follow-up to your question I think it's going to be interesting that we haven't thought a lot about will happen with BM that I'm hoping will happen with Bean is an ICBM Apache Bean is a there are really neat emerging projects execution tray marks for a shooting jobs that don't get the traction because it requires a switch and and so some of the the products that most people use and cards are using them just because of their adoption and because they already are familiar with the FBI's once people are familiar with beam and shined up shined beam I think what we see much more competitive race on how to execute pipelines and we can more easily adopt Siamese Nation projects that are doing really interesting things and they can get a lot more traction the market sooner
 because the friction to adopt them is less yeah so it's almost that time but do you have any speculation on what so not like kind of the motivation for data flow for developing data flow is one of the is a newer execution engine for example was this event times q and solving add event times you was a good enough breakthrough to develop a new stream processing system so what are the outstanding problems in stream processing that might lead to new data processing Frameworks that people will develop that may or may not be being compliant but in any case if it's being compliant you could easily switch from data flow 2x processing system that solve this problem
 so one one problem that that were keenly aware of him and trying to sell her own but I got to do to see how others saw this are how you manage and pipelines that are already in production so you use deploy to streaming pipeline
 and we use the term pipeline a lot in reference to Philippine but you could streaming application and and now you have to update that application or pipeline
 it's the current state of the art for doing that is not very satisfying it's it's typically to playing a parallel Pipeline with it with the changes you want and then adjusting the input sources to to migrate to the new Pipeline and taking down the old one and this affects your right pattern affects your data guarantees 120 is beta for services trying to do for sample is allow an update and place you deploy a new Pipeline and it it just replaces the current one and state is automatically lose from one pipeline of the other
 I currently just this works in the date of service for a limited types of updates and we're hoping to expand that overtime tomorrow updates but I'd that's one place I think it would be a shame to see each other's Runners innovage one thing we're doing on the the batch side that we want to do more on the streaming side eventually
 we called Dynamic worker balancing so this would be an area where people could I make improvements to streaming and that's how how I balance work as my input data changes the way I've allocated work between various workers may may fall out of optimal so I II traditionally eyes at you show me Sissonville spread out key ranges across their workers so then some workers allocated to key range to do allegations in processing on that subset of data but if my key range changes I would want also my
 my workers to then evolve and improperly allocate kind of this new distribution of data those are things at work actually I'd love to see other Jimmy systems also tackle these emerging problems in streaming I want to thank you for coming to the show I'm glad we finally got this together and this is definitely been worth the wait I really enjoyed the conversation and software engineering daily is pretty fantastic
 thanks to sinfonico for sponsoring software engineering daily symphonica is a custom engineering shop where senior Engineers tackled big Tech challenges while learning from each other check it out its symphony.com SE daily that's s y m p h o n o. Com SE daily thanks again siphano
