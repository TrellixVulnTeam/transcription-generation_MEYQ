Transcription: when a company gets big enough there is so much data to be processed that an entire data engineering team becomes responsible for managing this data and making it available to other teams Airbnb is in exactly the situation with so much data that needs a data engineering team Maxine Bill shimian works on the data engineering team at Airbnb where he creates infrastructure and tooling for managing data in this episode of software engineering daily we talked about airflow a workflow scheduler that assist in job processing if you don't know what a workflow is a job we will explain that in this episode Max and I also talked about panoramic say data slicing and data visualization tool that helps data scientist and business analyst understand large volumes of data data engineering at Airbnb on this episode of software engineering daily as soon as we get back from a message from one of our sponsors
Engineers love Automation and well front automate your investing as a software engineer at there are certain processes do you want to execute no matter what like integration tests during a build you wouldn't execute integration tests manually you would use a continuous integration tool like code ship or Jenkins to automate your integration tests wealthfront is a tool to automate investing just like a continuous integration tool runs your test automatically wealthfront can reinvest your dividends automatically and performance tax-loss harvesting automatically to get your first $15,000 managed by wealthfront for free go to wealthfront.com se daily and get started with wealthfront Slayer of automation on top of your portfolio wealthfront.com SE daily check it out it would support software engineering daily and you will get $15,000 in managed for free
if you sign up automate your investing get back to the things that you can't on me like writing code
 Max Bushman is a data engineer at Airbnb helping to develop and scale the company's data warehouse Max welcome to software engineering daily thank you very much it's a pleasure to be here definitely in January 2016 which is when we're recording this podcast what does it mean to be a data engineer a while so I think did engineer is going to be I feel like you know things have changed in the business intelligence or another next world over the past five years or so and I've been kind of the Forefront of seeing some of that transformation I think not only that feel this changing but the definition of the roles are aren't changing quite a bit data Engineers may be used to be called that business intelligence engineers and maybe that was last programming involves setting a date engineer is much more of a software engineer than traditional you know data people used to be
 so that's it a transformation we've been seeing you over the past five to ten years
 using Hadoop since you worked at Yahoo back in 2007 what has changed the most about the Deep stack in that period of time
 wow so does the thing at Yahoo in 2007 it was really hard to foresee that a dupe was actually going to become something from which was sitting at a time not much of it was actually working it was really hard to get anything done on that platform we would wait for the next 24 hours for or processes to make it through the cube and then it would just failed error messages so the fact that is usable is pray the main difference but but I think it's changed quite a bit and one big transformation were seeing right now is going to be the death of mapreduce or the slow that slow agonizing death of my produced it's it's going to be you know there for years to come but but now I know we just see too much wasted I know and wasted Cycles with my produce and people are moving to things like Spark
 the occupation of data engineer didn't even really exist by name 10 years ago and the responsibilities of that role were wrapped up in the job of a data scientist or software engineer up until very recently but even today it seems like that the expectations of a data engineer are expanding is is the job of a data engineer going to Splinter and specialized even more in the future it's like to kind of go to the core of that a little bit so it did engineer is a person at least you know the definition that we have we had a Facebook when I was there and definition we have here at the Airbnb is closer to person that's in charge of organizing summarizing cleaning the company's data
 Austin in a data warehouse and in many cases that includes managing the date of pipelines and making sure so owning the data structures the quality of the data itself as well as the pipelines that deliver this data so that there's definitely a move towards also like supporting batch processing from a Spartan basketball system or streaming and you know I've been having a real time or close to real-time data as well technically like you work an Airbnb what are some characteristics of airbnb's data engineering requirements and and also how are you handling that shift from batch 2 streaming
 resurant we're in the middle of going to defining what are are streaming infrastructures going to look like and we're building a lot of very exciting stuff at this at this moment so so how the role is transforming so this is transition I think a lot of people are going through it and I think a lot of people are starting to go on a through Al and architectures having some element of the data streaming in real time and an diving some some batch process isn't using you know that you got two endpoints to be able to to double to crush check data and due to over but to be able to reconstruct you know the truth as of the role was changing very much because of that tool set and the stock is very different on the batch processing side as it is on on the streaming side and that that brings up
 whole new set of Platforms in in languages and a new set of challenges Siesta Key Inn in this shift what are it like what are the ones that you see is as common among all of the all of the types of architecture that are moving from from a mostly batch to a more streaming based architecture right so I can suck a little bit as to the fact that we use at Airbnb as far as far as where we're going towards streaming and then I can try to relate that more in the industry scale and see what else is at is at play or so so we used a do Platform heavily you know and we use high very heavily tubes that means a did engineer at Airbnb authors a fair amount of hql which is the hive
 language very similar to a 2 sequel no. H drol translate sore compiles into Matt producer behind the scene we have when you write a hive query are hives no pipeline behind the scene that compiles into mapreduce is very expensive it's extremely stable very flexible mostly like easy to read easy to maintain author and the air flow is going to do Glue by which we orchestrate all of our hql and other scripts so fast resting stack would be I dupe hives other people use Pig and something to go do all these components together plus you know one or many scripting languages to to get to get things done in general now on the streaming side
 so casket seems to be very popular and we use that extensively do you need some sort of good serialization framework a language that people use a drawer thrift Thrift so we doing some you know it starts from the very beginning it would be having a good logging framework you know that can generate the fans that will go on one side you know or that will go to Costco and then we can split into your girl and architecture and go on one way past Russ's to Hadoop and on the other side I'm go to work something like spark streaming or something where I can do is dream processing sonar case we're building some automation are some framework that skunk driven on top of spark streaming other people use a stanza I believe so that's kind of an industry-standard as well
 and then you need some sort of database that can I get there in real-time project Auto 2nd and market and extensively use it Yahoo so in a bunch of places so it's it's an open source project with a lot of traction so it's super interesting so it's and it fits very well into you know the kind of architecture that most companies have and it can really play that role of slice and dice all laughing houses on the real-time side it's possible to get data from your head to Cluster to override on your Droid sets that makes any sense will say you miss some events are you want to correct some some things that you cannot capture or change them but business logic you can always go and reef all the data from a dude
 I can do dreads that's what I look like I think about that I mention most of the or some of the industry at movement or common Solutions so Airbnb works at a gigantic scale so many of the companies that are using this type of Big Data stack that you outline did you work at a large Gummy airbnb's is is quite a large scale and and will continue to grow obviously what are the challenges that come from working at the school I mean it does it get to a point where they do you get to a point barely fairly quickly where it's like you know once you get to this once you get the point x any point Beyond exes is just as easy as it is a tax or it or does it does it continue to get get harder it like an in linear relation to to your growth does it does that question make sense
 you talk about like the big scale of everything because I'm coming out of Facebook and Yahoo so you know for me it feels like this is very small data and you like being on this this girl seems like we can scan through most of our data set and we can join you know I we can hashmat most of our Dimension data so coming from Facebook it really feels like I can send out a drop in the bucket compared to a lot of say the startup to use air flow or be envious is a fairly large scale so we have a really good data infrastructure team that manages our Hadoop cluster spark cluster you know everything data related so true it so we have more than a dozen people now you know keeping that working at scale that's really important it's very fun day tional to to you know what a data engineer can do or what it is
 disc into if you don't have this Foundation becomes really hard
 I think
 ask you how it evolved over time if it feels lean linear it seems like you always saw the next problem and you always work on what's most important to you and you know I'm trying to think whether they are kind of stat changes or Plateau words like you're something really big big we need to solve you know in order for us to move forward with the first thing is I kept one key element of say we look at the maturity life cycle of an organization in relation to data so that there's a point where it's really important to get a decent data warehouse right into start thinking about metrics and dimensions and that hasn't changed since the old days of business and thought to what are we measuring how do we think about our business do we have all the data that we need
 Sperry fundation all I would say you don't necessarily mean streaming or you don't need all these fancy things you just need a good source of data are good metrics good to mention and Trust in our internal trust that culture of being the address and trusting the data level details of getting a good data culture as a data engineer your building infrastructure for software engineers and data scientists how do you gather requirements and communicate with those other Engineers you know as you as your building products that are essentially for internal customers how do you think about that
 so all together requirements around around data and work with other departments
 it's it's it's a long process and you know the company needs to be ready and you need to work with people that are data I'm hungry for data and you know provide the needs and it's a slow process I think to have to go from a company that is going to good driven to a company that is a slow process of learning trust and you know I having there's all sorts of people in a business everyday that have all sorts of arguments about how things should go and Indian you know data always wins that you need to have faith and trust in place in order to even as an argument that goes beyond gods or her things like that so
 play some you can make your point for sure that a red button is a green button is better than red. Then by 12.2% you know with exactly two that's important
 since we're talking about data engineer we should talk about air flow which is an open-source platform developed by Airbnb to programmatically create schedule and monitor workflows what is a workflow and why is it relevant to the topic of data engineering
 Rexall this picture of an organization where you have five people working with data there's people that need to organize all this process it to you know maybe for data warehousing purposes just to organize data as an asset for the company or being able to to power internal systems or an internal warfare's or sometime product facing type of that day so you'll be people working with data that needs to offer past jobs and I'd say at least 12 people an average generate you know too
 data processing jobs per week it won't take very long before you have a large number of data processing jobs and very often just data processing jobs I need to work in a very specific order so that means I cannot process data until it's here and maybe someone else wants to use the date I generated to generate another day it's a very complex graph of dependencies across these individual processes and air flow is a system that allows you to Define that programmatically because the nature of these work voice complex's changes quickly and now you think of that you started thinking of bigger organization like like Google or large companies that are beta driven of hundreds of people working with data authoring jobs everyday and this graph of dependency is in motion and becomes like a symphony that needs to occur every hour every day and you need like some sort of
 Orchestra director to to make sure that everyone or every job everyone plays their car at the right time for the right moment to write level intensity and that's very complex so that is the problem that airflow is trying to address is to allow for people to other these jobs and to understand what's actually happening while you know the symphony is taking place every to summarize what you just said there were there was a talk that you gave and you said that airflow wanted to address the problem where companies grow to have the complex network of processes and they have intricate dependencies this is what you were focused on the dependencies and analytics and batch processing our mission critical and that tons of time is spent writing jobs monitoring and troubleshooting issues can you explain how this set of problems impact the end user at Airbnb and
 how air flow improves the State of Affairs
 writer it comes down so I was talking about the trust earlier right so for it I think we we all agree that companies need data driven by data is extremely important for companies to be that a driven we need to have trust in the day that we have until we need to make sure that this process in the right way and that we have we have clarity as to what is what is running when it ran that there's did a quality checks that are in the same way that may be in software engineering units s and then sometimes it doesn't see that it smells funny
 greater to allow them to stay sane and deliver a good product every day to deliver reliable they died everyday the same way that you know for a cook a kitchen that is clean with a state-of-the-art appliances with all the room that they need to work I would have the right tools provided is extremely important to cook healthy meals and time on since racing motor for did engineering we need a set of tools where we can have clarity as to what's going on and I'm just like being able to to to to to produce a product that we know is safe and reliable and being able to keep on doing the work of the day without having to say fight fires everyday you know
 your company has important projects that need to get done the IOS app needs to be Rewritten for Android the database needs to be migrated your continuous deployment system needs to be built the website need to complete redesign will you don't have enough software engineers and designers to get all this work done top towel is here to save you top give you exclusive access to the top 3% of freelance Talent software engineers and designers from python to PHP top tell has the freelance Talent you need to get your project finished on time with top quality in the past we had to worry about flaky Freelancers with poor communication skills unreliable internet connections subpar technical skills show on top house screens for these kind of things and only works with seasoned professionals with tremendous problem-solving skills personality and drive
 here's how it works top towels internal team of senior Engineers will work with you to understand your project scope and your talent needs and they will custom match you with just a few hand-picked candidates this means that whenever you need to add top-shelf talent for a critical project you can be connected with pre-screened Engineers were hand-picked for your needs and the results are impressive top top clients conduct just 1.7 interviews for every higher that they make all you need is to come ready with some decent technical specifications of your project and Taphouse team of Engineers will take care of you from there if you are looking to add critical Talent fast and you need a source you can trust go to top tell.com SE day you can also send me an email directly at software engineering daily at gmail.com and I will personally introduce you to the team at top towel so that you can learn more
 we live in unique times the nature of work is changing and more and more industry-leading companies from Airbnb to JPMorgan are realizing the benefits of scaling quick and staying flexible by working with Elite Freelancers so if you're short on resources for your projects check out top tile.com SE daily thanks to top tile for sponsoring the show now let's get on with this episode
 it's over there have been other dependency-management workflow management Frameworks such as spotify's Luigi what does it take to to build a workflow engine end and how does how does air flow compared to other ones that have come before it
 right so I had to use the along the years have used many different solutions second talking specifically about about the Ouija or maybe I'll start by answering the question of what is it take to build a workflow and Jen so luckily workload management it like contrarily to some station data processing is not as substation intensive so using python for the purpose of gluing gluing jobs together works works fairly well what does it take so it takes I would say thank the common skills that you need to build software right and then it and then as in as in any as in anything I think for the Builder to be intimately to know the problem is trying to solve very well is very important so having work as an engineer for like 15 years now and many different companies
 scales and Evan use similar packages I think that all helps and building a great product that's like going to cutting edge of what they did Engineers want today to get the work done I'm not I said the differences with other system so when I first run Airbnb they were very aware that they needed something better so if we were investing in did engineering when you on that we need data warehouse we needed you know to have it is engineering department so we could solve the problems that we had at the time I could get into more detail it what it looks like at that point in time
 that we looked at that point in time I connected with people on your team here and we looked at the different options that we had and open source world so we wanted to go open source the rest Overstock is open source and you know for all the common benefits of Open Source being able to contribute being able to fix her own problems making sure it connects with her structure well so it's nice there's no socket or plugs you can just write one and make it work for you so it was really important to us so at that point in time we did look at mine and Luigi and Luigi shares a lot of design there's there's a there's a lot of common between Honda
 on the differences in just a moment but we ruled luzianne Azkaban cuz we had people coming from the company's where these two would have been built in are mostly use and we were told please whatever you do do not choose this. Do you still add like not great reputation for people that work there more intimate people were with these tools and more they would recommend us to not use them and I think I think it's unfair to say that I might not be fair to say that anymore because these tools are evolving I'm not sure if Azkaban is evolving I'm not sure I don't keep track of these projects very well but they might a change as follows you for a long time since it's so hard to get these things right on the first try to building these other things I swear something new are in shining armor and and better comes through in one day you know airflow will be there in 2 created
 send button today and my DM you are generation thing
 I'm so so it is designed to stream data and computer data in Python which is something I kind of fundamentally disagree way or think we don't want to allow people to process data and tighten Pizzazz you scared of it becomes quite expensive and I-10 is probably not the proper language and then the proper set of tools to process large amount of data already probably want to do that anymore for that purpose that's one thing I was really important to me to be able to dynamically generate tasks right so if you
 workflow engine
 workflow in some cases you like things that Facebook is doing that now Airbnb is doing is is to be able to do things around generator so if we example at the AP testing framework experiments and stuff that the user experience so we run tons of experiment in each one of these experiments to generate pipelines dynamically based on ovulation files allows us to be more dynamic
 I think so if we look at 2 instead she ate a task in air flow we just ate an object so we said she ate an operator so say hi job I might say I can write a for Loop that will essentially 805 jobs based on a hundred files that might be in the local folder on the Luigi side you have to derive a task in order to create a new task that needs to get into metaprogramming if you want to create a Stein attic lease that was fundamental concept play I wanted a DSLR language on a TI that was allow people to very naturally create workflows can I programmatically you are based on top of durations fascinating so you don't want of the things you mentioned that you said you were you said you could touch on the State of Affairs when when air being when you first
 got to Airbnb, can you describe any more detail. Many did Engineers I think they had three data engineers at a time to that I just joined and one so Eric used to work at the first engineer at Airbnb they started building a warehouse it started doing the things that data scientist would do everyday but then creating a foundation for day. So I started building at warehouse and everybody rallied behind that seeing the value of not doing the same conversation over and over so I started doing this Warehouse people would always access raw data and transform it in different ways so you had to work with very raw ingredients that were sometimes.
 are you sometimes you know missing and somehow out of that recreate some version of the truth and then the different data scientist could not have those transformation and Beast transformation would be redone at every analysis meaning that every metric or every Dimension definition could change in time so then if you don't have a warehouse and you don't have to ask that first set of their transformation to clean it up and apply a set of business rule and fill in the holes that you have then everyone needs to redo that work everyday that's one thing as wasted effort and then yeah the other problem of all Matrix are different than chicken changing depending on who did the analysis in time it's really hard to build trust and data
 search efforts and losing trust which are really bad things if you're trying to get your company to be more data driven so I think people rally the data scientist maybe a dozen or two at a time I did really rallying behind that and identifying the needs like we need more people like him and I'm not even sure they had the title for that role yet and they called it an ETL engineer extraction transform and load as a common acronyms to the process behind data engineering so I got hired soon after that and not worry about it doesn't did engineers and the team
 so you're explaining the the problem set NSN it like at this idea of repeated work and lack of communication some some reduced trust and you know Brett people doing we're done at work my understanding is that this miscommunication and level of trust was also improved by another tool that was developed at Airbnb called panoramic panoramic is a data slicing and visualization tool could you tell me about the set of use cases that you wanted to serve with panoramic X-rays of something around you said it did exploration visualization dashboarding platform that's also open source also written in Python that's not initially officially under the Airbnb umbrella
 officially release as we haven't really written engineering blog post but will soon do I'll be talking about it at strata in Santa Clara I believe it's March 2016 so this upcoming March and this this tool started as a hackathon project in July so it's fairly new to the store really games at making it extremely easy and low friction for people internally to visualize and Rize data share inside and I think you know there are tons of Vincent intelligence tools out there Friday people use a Char do and if there's like so many vendors of these visualization tools where you can build charts and dashboards so panoramix is another one of these tools but it is it is open source I don't think there's a lot of Open Source tools and that's
 and for us the problem that it's always just making data extremely fluid internally but we don't need to write sequel you don't need to know our to know by then you can just you can just go to this website I pointed it is said and start building visualisations very quickly the employees were using for data slicing visualization rights in and they're still using its complementary to a bigger than the notion of sharing and consuming information or data entering Leah still at Airbnb solid with many tools and actually kind of rolling out doing a big push now to give access to everyone in early in and get value out of it but the other tools that are complementary to that
 we also use some air out another open source project out of Airbnb that it says it's a website working rights equal against internal Presto and retrieve CSV files that you can use in your favorite programming or scripting language to to visualize so is that the bar there is you need to know Sequel and you need to add access to the warehouse and then you can make your own extract and visualize it your own way below the barrier there is like you need to open a training and then we need to pay to you need to get a license for you to use it as store in Trinity is not very cheap and sometimes it's a little hard cuz you need to create extract we need to get somehow it pipeline that would load data
 Tableau everyday waste of his last day to consume data and fairly which assumes that you know what programming language should there's all the people that we want to reach to that are not want a slice and dice the winter group I just want to see these metric they want to filter so that's the yusuke's that panoramic to solving with a very low friction super easy to use you I understand the story correctly you tell me where this is incorrect so it sounds like at the time at which you got to Airbnb it was in the situation where the way that people were pulling data and doing ad hoc analysis on it was totally non-standardized and the way that they were cleaning the data was non-standardized
 all these inconsistencies and show the first thing that you did is an organization was moved to a place where you sort of had you got air flow and it's and it helps to standardize the cleaning process in the end of the day availability process and then once that standardized you still have people that are pulling the data off of doing ad hoc analysis in their own disjoint ways and then what panoramix does is it standard that process and it gives people agreed upon format and platform to to negotiate that the data analysis side of things that gives the data scientist is standardized world to live in it would you say that's accurate accurate I think like one thing one change that also provides is ization of of access to data internal anywhere maybe historically you needed to have if you had a question you would have to go through
 a a better scientist and say I've got this this question I've got this gut feeling I'm curious like I would like to have more information about a specific date or something of that nature you could not answer my question yourself because maybe you didn't know sequel maybe you didn't know where the tables were a data warehouse that that has clean intelligible data as well organized that's well-documented so that's one of the acid that allows for the McRib sizing the access the data and then just making it extremely easy for anyone to go .2 one of these days at Sand and ask them questions and that's more word on the inside and that's partly panoramics
 anyone really to be a content creator and create slices which are individual charts or dashboards and from these these charts are dashboard you can go deeper and cuts in urinalysis as you share a panoramic stash for the you share panoramix or what we call a slice for a deeper analysis right so I can send you a slice that represents the number of booking in Paris during this I think this this this lies and look at it and be like oh that's interesting let me zoom in on this time frame and let me Group by where people were coming from and I'll say different metrics got affected by by these recipes Advanced everything becomes the starting point of it deeper analysis
 fascinating so I took another level of technical death on this is deep integration with Drew it and you've already talked about some of the importance of Druid to the data at stack at Airbnb why is Druid show useful from the from the point of view of of panoramix right so what's the project actually started to have to roll to go back into the Genesis of all panoramic started so we had an intern nothing around June that was doing some tests with Druid and it didn't drain was just really hard to consume you have to write a query and they as a Jason Blaha somehow we have to figure out a way so I thought I'd for hackathon I would just build a small you are that would allow us to see you know to say you a line chart and in the fuel filter is a group by their show me these metrics off of this data set
 and this was the goal was behind that was opening the doors to real-time analysis right internally you know we at we all know that that real-time it is like important if not critical to be able to to know exactly what's happening right this minute and being able to ask question about what happened 5 minutes ago with the questions that the batch processing world will answer so I can say is are better or are typical for for a real-time type of data right everything that is offs really that's right I guess you have
 something is happening right now on a set of machines in sisig Datacenter you want to know which missions are affected which countries are affected when when did it start was it take relation is it coming back right now like we just did something is it is it traffic coming back or not is it coming back across the board so that's even for engineering as we know there's always instrumentation I'll just stay there that we collect and analyze the instrument the day that I'm putting you to advance to see exactly how it's blowing and how and whether they're actually seeing what they expect to see there's also a experiments we like to see weather and people are getting a science experiments and whether it's affecting the metrics and bad ways if someone could produce an experiment that is really bad
 and you know leading to people being unable to use the side and we want to know quickly so we can you know turn it shut down his experiment so there's different and complementary to to the other questions that the batch processing where will answer like how is our side growing I can look doing like Road and gagement and all that stuff is like 30 days or 90 days you know year-over-year and that we can do very well with with the crossing world as well as I started with this real time Solutions like wildest website is getting really good and useful and why not you know making a in the warehouse that seem like a very easy next step and as I did that you know I wanted to connect it to presto which is the mean by which we access the data in the warehouse interactively at Airbnb so I decided to
 how to do it using the sequel Alchemy or around the expression language which is a library in Python that allows you to write sequel that can be translated to a dialect of any database mix and expose as well as coming from any other data sources right so we can query my school databases Presto people in the community are already so there's a little bit of community release that people are wearing red shift and people have used Impala and other big connected whatever database they have it also works very well so we can visit Vision can ask dashboard that will show you some elements of real time and some along with elements of a from the batch processing well we don't need to train people on the set of tools for
 or patch Ross store Forest Lake if you need access if your question is this then you use this tool it's a question is that use a different tool at least there's it's a bit more crazy up there so to begin to close off I'd like to zoom out and talk some about the macro perspective you've been doing data engineering for about a decade given the trajectory where you see things going well you've already seen what's the future in this space
 honestly that's a good question it's always super hard to see the future I think for the rest of the world to follow Silicon Valley is always like a safe that right so we can see what's happening and Silicon Valley so what's happening in places like like Airbnb in all those startups and they did not so not so small startups and there's a focus on analytics and all the skills around data are extremely value right as I read an article I think it was yesterday that class or said that one of the best jobs in America this year as to be a data scientist I think I also have seen that but I think that the skills around data are extremely valued it will keep going that way at for companies to be very driven did I form reactive and too
 and to four people in meetings to argue using data you know what I think that will expand if it's not already called and Beyond right even academics are also more data driven so so date and some more day to figure a date more data solution distributed systems The Cloud of course you know all of this is happening we already see it happening there's a lot of diversions in the stock right now oh yeah that was my next question rights of the diversion and I'm sitting there should be some convergence at some point but I think in some cases will see open source solution take over some of the vendors out there right so I'm hoping that as an open source
 the song we're becoming free in the software being a collaboration after it as opposed to know build by companies so I can hand tools is there is convergent where is it convergence later where is it going to converge two words that it will converge two words a set of really good libraries that people can use to build tools and tits an end to write software I was having conversation recently with someone from Tablo Tablo is built by 200 people are buying so many Engineers right I forgot her number and it's amazing that you were able to build paramex on your own which is some someone I can substitute teacher Blow by even if it's you say it's 50 yards 20% of the core features of tableau
 that one person could tell that is outstanding but I was like wait a minute it's not just me all sorts of Frameworks in libraries that I've been written by probably more people than there are engineers at Tableau red so behind the scene there's everything that goes into making a browser there's you know everything that goes into JavaScript and different languages and standard libraries and those languages plus you know say the web framework that I use and as I use flask I use Flash Cab build a huge list of dependency a lot of people
 more open sores or four people to go more towards the solution seems like we're the future Mighty Guy actually where I hope it's me when you talk about convergence and the terms of libraries are you talking about it the level up till like 1 when he's able I see of convergence in the Big Data stack is Kaka that's like the only the only the only example of convergence like you know rabbitmq or zeromq and maybe there's some convergence in the space of spark but we can't even figure out where Spark over relate to spark overlap need to overlap with it is it over like what's playing card is it is it mutually exclusive with storm like these are things that I have trouble recognizing I guess so are you saying that this is the level where where you think things were
 converge or sort out in the future or are you taking there's like a higher level that stuff gets built on top of other areas of convergence I think like hdfs is there for to survive for instance right side distributed file system you look at you look at a vendor packages that are many many things it's that's not an area convergence a business intelligence as is complexity made out of lot of components but you look at the individual components so say it distributed file system or a messaging bus you know so virgins at that level that is pretty clear so I think we're seeing your caca horses like the big winner their spark and so I'm not sure
 Wanted still up for severe storms by streaming Sansa icomputek General data competition might be like they're going to generate but it seems like it's going so you know something like that if what is a dude while Hadoop is the sum of its parts in the is actually the definition of what is Hadoop is changing at some point they might say and I will head to work now or rights of the collection of things might change but the building blocks I think it makes sense for these building blocks to converge
 as a hdfs my reach one day the down cycle of of its of its lifetime then there might be at the virgins again until people new distributed file system since I didn't tell that it's try to reinvent all things that you know thanks so much for taking time out of your day to come onto software engineering daily I'm a huge fan of Airbnb huge fan of your open-source work so thanks for coming on the show and I'll keep up with you thank you so much is a pleasure to honor to be here thank you
