Transcription: apache-spark is replacing Matlab in the domain of computational Neuroscience the constraints of running Matlab on a single machine can't support the demands of Neuroscience which has huge collections of images and time series data sets Jeremy Freeman is a computational neuroscientist who is adopting apache-spark to be able to analyze these data sets that do not fit on a single machine but apache-spark was not designed with Neuroscience in mind for this reason Jeremy has helped to build several libraries on top of spark Thunder is a library for standard distributed representations of data lightning is an API for reproducible web visualisations these abstractions sit on top of spark and add a layer of usability as it turns out solving these problems for Neuroscience have produced tools that are useful in a variety of other domains in our discussion
Jeremy Freeman we talked about apache-spark neuroscience and the technological and cultural problems faced by traditional academic research but first a word from the sponsors that keep the lights on at software engineering daily
 I love being a software engineer because of how easy it is to build side projects and I built the countless side projects I build a Social Gambling application a dating website backend that had zero users stock trading music rhythm application for Android and I think every developer should have side projects so when I have a web app that I want to deploy and share I want to show my friends my most recent project that nobody will care about I use digitalocean to quickly spin up a server and host my projects and who knows if one day one of my apps takes off and goes viral and people actually do care I can easily scale using digital oceans flexible pricing plan companies like taskrabbit that have grown rapidly have used digitalocean for this very reason but until this happens I will happily stick with the $5 a month plan sign up with promo code SE daily to get a free $10
 is a listener of our show and start building your apps we would love to see what listeners build so send us an email showing us your project I've also interviewed moisey oretsky who is the co-founder of digitalocean and he mentioned that the ease of use and the flexibility is why they built the service in the first place that digitalocean in interview is one of my favorite episodes noisy talk about bleeding in a data center he says you don't know how hard it is to do a cloud hosting service on until you bleed in a data center is really interesting so it's speaking of which let's get on with this episode of software engineering daily
 Jeremy Freeman is a neuroscientist using computation to understand the brain Jeremy welcome to software engineering daily thanks buy beer
 it's January 2016 what is exciting at the intersection of Neuroscience and computation
 play there's a lot of exciting things happening
 one day at my group is critical excited about and I think a lot of a lot of people are excited about is what an understanding of the brain can tell us about principles of design in computational systems I'm sure your audience has heard a lot about various machine learning approaches that are popular right now and although those the techniques work well in certain situations they're all so many limitations and I think there's a lot on the Verizon in terms of learning from actual neural systems natural organisms how they work anyways that I can inform the design of ultimately intelligence having that connection be made I think it's super interesting
 we had Francois Chalet on the show at the time of this episode it it hasn't aired yet but he invented the Karis deep learning library and he said when we were talking about this brain vs computational you know machine learning stuff is it he he thought that there is not really anything particularly remarkable about the human brain or just brains of organisms relative to the ways that we can design computer system so he didn't really see it as you know we should look at that brain is this idealistic thing that we we should learn from we should more think about the first principles that that the brain exhibits and we can build your computer systems that are based on those first principles does that idea resonates with you
 I think that makes sense I do you know if I do find the brand of organisms to be pretty pretty remarkable I find organisms to be remarkable body in the whole system I think it's definitely true on the one-man there are things that we can have those computer systems to do that vastly drawer the capabilities of any organism I'll send you can build algorithms to solve problems in ways that are surely not how we are doing it because of the resources and constraints you don't need to worry about the computer system I think there are properties of intelligence a good by organisms include things like adaptability and answer the robustness the ability to have continue to operate appropriately under a wide variety of of external environments and circumstances
 face recognition recognition a general you a small child in a room full of obstacles and objects through and not bump into things or if it does it's going to get back up that kind of assertive intuitive contextual adaptability I think we don't even have the right idea to think about how to build computer systems that exhibit those times properties and then some ways drawer I can't I don't have the memory Shirley of the computer system that I could engineer
 there been some fundamental technological achievements in the past five to ten years that have really enabled some some big advancements and Neuroscience. What are those technical development send and what have the enabled I think I've been pretty transformative so one has been across the board improvements in Recording Technology so if you want to understand the brain and what is doing you have to be able to record or monitor the activity of its constituent Parts in the brain that means recording or monitoring activity of neurons there a couple different ways currently we do it in both of those ways that permits have been traumatic so you can record the activity of neurons with electric as electrical recordings and there's been improvements in the development as his ongoing of new electrical probes that let you record some okay
 Ashley from hundreds Universe tens or hundreds maybe thousands of neurons simultaneously and there's also been huge improvements and advances in being able to use a light microscopy to do recordings of neurons and this relies on the additional and ability to genetically engineer animals so I can put their case there are neurons Bud Light Up when they're active and then by combining that animal with the appropriate microscope you can literally throw watch the activity of neurons through Optical measurements and this is now enabling Us in animals like the mouse or zebrafish to record hundreds of thousands of neuron simultaneously it's not the entire brain a very large and certainly more you know
 20 years ago 30 years ago we could record the activity of one or a 5 knots at 1 so this is if you believe most of us to be able to watch it disability is enormously improved the point that you're coming at is we were at we have a ton of raw neuro scientific data but performing analysis in exploration of that data is not
 yeah trivial and can be difficult so tell me about the types of data that we have available and give me an idea of of where we are in terms of an how difficult is it I think there are there certain misconceptions actually that that are good to clear up right from the get-go so wanted is that it's not just about the sheer volume of data and also to let you know what I mean by that are in the Raw data are images or time series of various forms with microscopy you're essentially collecting images that very overtime those images are two dimensional maybe three dimensional at the volume maybe four dimensional if you have extra channels
 electrical signals you're the raw data is a waveform it's you no voltage signal coming off of your you know one or more electrical cord inside so the raw data is basil and pile of Time series or images or maybe some combination of the two
 that explain that describes a lot of that size I mean are large we're talking for Imaging anywhere from 250 GB to a terabyte for one experiment and you're doing you know hopefully multiple experiments every day or at least and that's the sort of regime that were typically in and you then need to figure out the date of the word I said before about it not just being about sizes that I think it's you know the one hand those numbers I certainly the people who are familiar with kind of industry work at large I mean it's not a thing in this area
 complexity of the kinds of things you end up needing to do and the the really complicated tension between the fact that every lab sort of has things that it thinks it needs to do with their data that's kind of unique to them for the same time we are all kind of doing similar things together and how to figure out how to build systems for for processing and working with these days in a way that they're supposed to be General but also supports all the various kind of complicated use cases that individual apps require
 so in the past you know cavitational neuroscientist would often use something like Matlab on a single box to perform their analyses or their cell but more recently you've been making a push even advocating that neuroscientist should adopt tools that offer more speed and flexibility and interactivity and this is Led You to spark why is spark unappealing tool for computational Neuroscience in a domain where you're dealing with all these images and the time series data yeah that's a good question I'm definitely characterized correctly that I am pushing us away from my way from Matlab general for really open source tools of a wide variety of which which Park was an example especially early on you know back in when we started using Spark
 what is yeah really starting to think through how to deal with some of the the large data processing problems and realizing that a lot of the things we needed to do in stages of working with these data were parallelizable in Austin fairly simple way but what the barriers were that any existing for the price of doing paralyzed computation especially for people that are used to base if it was really complex you know you want to take someone scientist who knows a little bit and try to teach them not produce and write him a producer try not some of that I didn't realize in both myself and anyone else have survey took off that would be really exciting because basically it had a python API
 really early on which man it was easy to integrate with a lot of existing work clothes in Python and if we going to try to get someone to use an open-source scientific Computing environment right now I'm not like I mean I love python I'm not I'm not a die-hard I think Julie is really cool cars cool but definitely a viable powerful with Matlab can sort of feel comfortable in has been my experience so the fact that you could be in a grating with it python workflow early on with spark and basically take more or less the same code you were using to do your average processing time series processing and then paralyzed that in Austin they're not always get very large speedups was enormously if I think the combination of yeah I really clean API python client and very appealing
 for doing some of these work clothes
 nonetheless a spark was not designed with Neuroscience in mine and to develop a set of tools on top of spark generally speaking what kinds of api's did you want to build on top of spark that were specific to the Neuroscience domain images of Time series processing at all it's really designed for basically like text files or anything you know where you were talking about binary Blobs of array data basically never been and never will be probably the perfect tool for that I think we've spent a lot of time building ati's and on top of star cuz you said and a lot of that involve just having some you need ways and simple ways of loading data from a variety of
 which include things like images and flat binary data things that are not going to be built in this part because loaders in spark for a Json data are various database connectors but you know someone is not worried about connecting to the store or something they want to load images and you need to provide data from different sources that are the kind of things being racked with and then expressing Austin by the following AJ Styles that we really like like scikit-learn offering a variety of both kind of statistical calculations as well as more complex algorithms to be run on top of data this form so you know things like I want to load a bunch of images I want a filter that I'm in various ways Maybe by Tim McGraw
 best eyesight image and then I want to you know take that collection of pixels and do some kind of model sitting on it whether you know factorization or some other kind of the results out in a way that I can render with Matt Bartlett that was the sort of workflow that we that we wanted to build come clean it guys handle Thunder is a library that you built on top of spark and thunder allows for standard distributed representation of data allows for manipulation and Analysis of data and sounds like part of the advantage of Thunder is it it allows you to attack these data sets that are not in the format that is particularly copacetic with spark and traditionally these Blobs of data that describe in more detail what Thunder does yeah it's great
 give that very recently I had some evolve actually answer this question what early on we realized we needed to do was basically two objects that were backed by distributed representations of spark which theme park land is called the rgd there but this the thing we wanted was something a lot more like an Umpire right because almost all scientific data working with you know I said before I'm serious it's usually some kind of end dimensional array time series is a collection of one day or as you know images or volumes are 2D 3D 4D they're all just dense arrays and what you no spark definitely doesn't have is a way to talk to its object rdd as though it's not pyrite and
 that's a lot of what's under did early on and when we realized probably buying fresh in front of it from Sky stuff and where will realize how General that was broken that out into a separate Library a bolt which is surely for the purpose of represent in a and Ouray like seeing that actually back under the hood by spark so lets you express computations in a way that if you're used to work with any raise or none pies rice millier but under the hood it's actually corresponding to complications that are taking place in the distributed way
 show Thunder is built for this large scale image analysis is time series data analysis it's understandable that the that you first noticed this was not particularly well suited for spark in the realm of Neuroscience but it sounds like a general useful tool the ability to process large-scale data that is in the form of images or X Series show can it be used outside of the realm of Neuroscience totally really trying to do two things one is to make it more clear how it can press I be using lots of different domains and also try to to break it apart into several smaller more composable pieces some of which are incredibly General and could be used anywhere and Summer by Design have to be a little bit specific to certain use cases inspired by a bunch of people going to know especially in the node community
 city of building something like you know what scientific tools into small modular composable pieces sum of what we built with under they were now trying to like I said break into these smaller pieces is incredibly General I have friends who do satellite imagery processing or you know analysis of the planetary data or weather data that's big one where ya fundamentally they are also doing distributed or want to do distributive operations on end dimensional raise so we are trying to yeah basically for the break out all the pieces that are really General and make it easy for people to integrate with their existing you know it will change that may be applied to a totally different data
 what what kinds of operations are particularly useful for for operating on this on this kind of data is what you might think of is filtering operations but one of the complexities is that that filtering can be at and what you're trying to do local or needs to be either local in time or local and space or local and some combination of time and space so give me an example if I have a movie of a sequence images of neurons flashing complex images that very overtime for that one day is that I might need to both do kind of image local filtering thanks for the image feature detection kinds of things but I also need to do time to main processing and they're making things I need to do that involves processing about space and time together
 and the ability to express a workflow again if this thing is a terabyte and you want to express our workload involves you know sequence of operations and then time local operations and then some combination of the two those are the kinds of things I think we've done it figured out various ways to express so you know really anything in the room and I said of filtering or extract in signals of interest from images and or time series and or both movies being obviously the combination of the two things that yeah that is kind of operation okay
 Engineers love Automation and wealthfront automate your investing as a software engineer at there are certain processes do you want to execute no matter what like integration tests during a bill you would execute integration tests manually you would use a continuous integration tool like code ship or Jenkins to automate your integration tests well front is a tool to automate investing just like a continuous integration tool runs your test automatically wealthfront can reinvest your dividends automatically and performance tax-loss harvesting automatically to get your first $15,000 managed by wealthfront for free go to wealthfront.com se daily and get started with wealthfront Slayer of automation on top of your portfolio wealthfront.com SE daily check it out it would support software engineering daily and you will get $15,000 in managed for free if you sign up
 get back to the things that you can't on me like writing code
 talking about lightning which is another library at work done so lightning is an API for reproducible web visualisations why are visualisations so important
 so many reasons especially really fur for any dumb and especially for science
 I really believe it in in science and scientific Computing what matters most and really what we try to do is just make it as easy as possible to get from an experiment to some interpretation of that experiment which can hopefully then guide the friend that you want to do the next day that making that is seamless easiest possible is it really what motivates everything we do on the computer inside and I didn't get huge part of that is is visualization yes there are certain computations you need to perform on your data but Austin the goal this complications is to essentially extract or or come up with some descriptions of your data that hopefully by looking at you can then and of gain some understanding to make a decision about what to do next and if you don't make that that step above looking at it whether it's sort of looking at the raw data or looking at other process to extract
 form of the day. If you don't make that easy you just end up slogging around with her to bits of code in various places that have inspecting things in a complicated way where is Austin the inside you might need to be burped and really just by looking at it but it says making it easy to just look at it is what I think is the most important thing capitalization look at it it's fascinating so you with the lighting visualization project you also wanted to separate the process of analysis and visualization and because I was wondering why why would you want to separate these two activities cuz it seems like the analysis of data goes hand-in-hand with deciding what type of visualization do you want to create two why did you want to separate those into explicit processes so yeah I agree you do what you want to do them side-by-side
 Queen by separate will I usually born out of a a difficulty that Mia in the main developer amazing is that right now the most exciting kind of tools for data visualization are are built sin in our web Technologies Library think like these three kinds of new up-and-coming things is really the place to be doing either activity of any kind Dynamic visualization 3D visualization incredibly powerful and we're serving a funny place right now because although I love and our lab uses does tons of work with all this crap right now. It's good to know you're not really the place that we can do all of the Computing we need to do for scientific work clothes you know building something to do at the kind of like you mentioned time.
 right now the science of the Python stock for examples way more mature quite like that and so many others are thinking a lot about this so given that we still do a lot of our analysis and python but we want to Leverage What Technologies to do visualization there has to be some kind of interfacing and ideally a clean one despite there being some separation between what's going on in Pueblo and what's going on and and python land lightning I would say is one example of a few ways that have been developed to try to sort of embrace and think about how to bridge that Gap other one called Boca there a couple of them was built into the fact that you're using two different Technologies to do the two different pieces of of what is fundamentally
 you know you are trying to do analysis and utilization but you if you are going to have to use to set a different pool stats than what we thought you really want to think carefully about what is that in your face look like how you build both sides of it in a sufficiently modular General way to to be to be effective
 just like in opposition to Matlab where you do the analysis and the visualization in the exam application yes I think everything we do is no I think it's actually it's a great is a great inside because in a way the reason that that
 you're absolutely right now that has it easy because you're doing everything in the same language just the other day we were talking about how easy it is to build a GUI in Matlab you can build these great I mean like you can build these interactive gooey is and then you can like have conditional on a GUI event trigger the execution of the Matlab code doing all of that if you're stuck inside one model a text saying yeah it's like pretty straightforward to do ultimate I think that is not the right approach to Scientific General but if you have different rules for different parts of the problem you need to think really hard about designing clean interfaces to make these kinds of things possible so I don't think it means we should go through these problems until school Technologies
 can you take us through an experiment or a data set end-to-end from the stage in which you would use Thunder through to wait when you would use lightning and like maybe you have some pretty typical experiment in mind that has been used to great success using these two libraries sure I'll highlight a bunch of other things we libraries Muses while cuz these things are never use both both really I fell for meth to be composed of other things so yeah very typical experiment might be really starts you got an animal in some kind of virtual environment is running on the phone and in the setup developed by here working with my group and the group of call somebody Nicholas the front of the system where the mouse is on a ball and other side of these walls
 and the walls move in and out lock to the movement of the ball and Nick developed this basically do the system where animals nice could Explorer virtual environments Define by tactile sensation nice use their whiskers to sense where they are so these walls moved uses the property late so mix able to monitor now the activity of neurons and various parts of the brain while in animal is in this setup it is crucial that the animal and the walls are virtual by the way because the animal needs to be stationary and are just a Jamaican D's Optical recording music by microscope over its head and it can actually be moving around at least be held held in place so the animals stationary but thinks it's moving because of the ball and walls and you're recording activity of neurons in different parts of the brain that might be
 Ogden representing the basically a large sequence of the images again this year so literally giant sequence of X by y by usually Z so not necessarily raise you know millions of pixels overtime and you also have behavioral data cuz you have time series that describes the position of the walls relative City animal you have another time series that describes the trajectory of I'm as if I'm by the movement of the ball
 alright then we got a mouse on a ball and we have a shipment of images of neural activity and we have heard of Time series of various behavioral properties of both animals world so usually now this is where we start doing what generally add call processing so we have to Ferg's ample a line all these images of time the animals brain is moving slightly while its doing this experiment hopefully not too much but a little bit and there's only so much you can crack for during the experiment sore afterwards you have to register these images of the thrall lines up and then usually we do some kind of what we call for subtraction where we want to take these images which is raw pixels and fine groups of pixels that correspond to individual neurons are you can look at one of these images you miss Lacy's little blobs that are neurons and other stuff in between
 you need to do something to try to extract out groups of pixels so those two and then once you have the time series associate with each neuron you have to do some kind of time local filtering to try to remove artifacts you know damn pass filter in a frequency domain stop total sequence of processes can type in a Time domain processing those are all things that with thunder alongside very stuff inside Pi an Umpire course since I could image you know with thunder in Independence Park under the hood paralyzing that's sort of what you get out at the end of the day basically hopefully a Time series associated with every single neuron as well as
 you know what time Sears associate with vehicle measurements and then what we do what we do really depends on depends on the kind of questions are asked in you know if we want to and I'm more kind of exploratory interactive way for example render a big collection of Time series and browse through them that's something that we can use lighting for if we want to do something where you can sort of render kind of grass like representation that shows individual neurons and and Heather correlated with each other that's something that lightning is well-suited to you know somebody's baby just want to I don't know plot you know a histogram of activity that's something we can have it or you could use or you could use you know if you want I mean you know we like to be open to lots of different schools but it's really when you want to start exploring you know usually this kind of extracted
 interactive where that we find my name to be especially powerful and then immediately and then they said Okay so this level of being able to model data on the burner on time series level I can see how useful this would be impossible without the kinds of tooling that you've built with spark or just I guess without the kind of tooling that spark provides yeah definitely it's just a question of time I wouldn't say there's anything and if it doesn't bother me you know I don't like anything that we've been able to put a fundamentally not possible with other tools what is maybe it is it when you make these things fast enough
 actually changes the way you work within the way you analyze the data I really believe that I think that if you you know some of these things and this is how it was before if you tried to do everything as described with a sequence of Matlab script you know Evan Python scripts run on a snowmachine you could do it but it be probably hard to build clean way with things that are exist and more importantly you might have a script that you set up and then it runs over night you come back in the morning and the thing is this complex sequence of operations any of the output of any of them can affect the way you want to do the other ones they might not be there till you get to the very end that's final step of looking at that rendered you know like in graph visualization that you realize you screwed up because you see Downstream there's an artifact it's actually due to some problem earlier on you know you see that
 intercorrelated and the fact that are correlated is not it's not real biology it's some weird artifact is of the way you did your image pre-processing and I have to go all the way back that whole operation the fact that you know that every time you want to do that ticks overnight it will severely limit your ability to you know sort of Chef round and try different versions of things and try different algorithms try different parameters but you know what things like flying you can yeah you can do and that just means you can try lots of different things over and over again I think there's been a similar story if you look at the Searcher directory of deep learning approaches think I've heard a lot of people say that a lot of the advances are left over yours have really been due to the fact that whether diffuser otherwise computing power just made it possible for a
 a student to in the span of an afternoon train and compare a bunch of different models and be able to do that and see the results right away as opposed to waiting overnight for every single one I think in any domain of a science or computer in it if you can make stuff faster it just makes it easier to iterate and Sciences fundamentally iterative and a lot of it is trial and error you have to try things you have to evaluate and if you can tighten that Loop then you can figure stuff out faster
 Chris Evans as you pointed out the tightening of the loop through new technologies doesn't matter as much if people aren't adopting them and she wrote this you wrote this editorial about open source tools for large-scale neuroscience and you said quote Solutions can be found in the form of modern approaches to distributed computing machine learning and interactive visualization but embracing these new technologies will require a cultural shift away from independent efforts and proprietary methods and towards an open source and collaborative version of Neuroscience and quote I'd like you to characterize this further these old methodologies that take place in research you know do things stay the same because people are stubborn and they believe that they should actually keep doing everything a single box on Excel or on Matlab or is it because people simply just don't have
 training or the breadth of understanding to use new tools like Spark
 I think this is a huge huge problem Topic in an important one I think it goes. Quote quote indicate if you know I'll be on say Sparky it affects the adoption of all kinds of Open Source open Pro Tools and technology and science Technologies phone number of issues at some of them involve education I think fundamentally there is far too little training in basic principles of scientific Computing Computing in general software engineering and the Sciences you know at a bare minimum any graduate students entering a Computing intensive field in science and should learn how to use GitHub to learn how to version their code should learn or be exposed to at least a few to know a couple different languages
 to learn what does the different approaches are they shouldn't probably definitely learn at least one open source language is supposed to learn in that lab which most of them are up really good choice I think I think every I basically everything coming back to assume so I'm just giving that rapidly importance of the web and Dupree much everything we do whether it's sharing of visualization or whatever you know students learn Matlab for about a week and then they just showed up you know figure it out from there and I going to be serious effort to properly clean a lot of people who were never supposed to be sayings after about a day you know they get it like you should have someone get hug and kiss
 and they realize I know I spent all this time like saving Matlab scripts and giving them numbers indicate what version they are I wish I had had this thing this look great and it's like it doesn't take long but you have to show people and that's really about it acacian I think the other problem is a
 it is in some of this means that stubbornness anchors there's a little bit of this there's a really strong tendency in science towards roller coaster of Monolithic problem-solving I think almost every every lab I've ever encountered in NM and work with there's always a reason the strong tendency to want her to do it yourself it's this kind of cowboy or cowgirl mentality of the Delta Pipeline and the pipeline for your lab is part of your Labs little tool kit of things to get you from point A to point B where point is usually the raw data and point B is is your fault your publication
 and every lab I think sort of feels the need to build something for them self because they really want to work for the the work that they're doing and instead of sort of looking at and being exposed to a large open source Community full of tools that could be valuable to their work and also to think about how to build and describe their workflow in terms of small modular pieces that they could build in their labs to use instead of a situation where lives are busy building the pipeline for their lab and because it's for their left for the by definition is not going to be used by other labs and then other labs are going to realize that there's nothing out there for them and they're going to build it from scratch again so you have this thing of every group basically essentially building out tools to do kind of the same thing but instead of a green on conventions and standards and sort of building small
 where is everybody from use people just end up building stuff from scratch and it's really hard really hard to the fact is a lot of times it's not done particularly well and that's not a failing again this is important about education it's really hard to do this stuff so if your if you take on the challenge of building fire software stock for your lab without using anything that anyone else is done and you better from scratch and you're not experienced you are not going to end up building something that anyone else and then the problem just repeat what are Taco little more about this idea of Neuroscience and computation intersecting
 so you said that we're not only learning ways to understand the brain further using computation but we are also learning New Perspectives for how to approach computation based on our analysis of the brain how is are changing understanding of the brain introducing us to new ideas about computation
 this is returning a little bit to it to it spread from earlier but I think there's a lot of potential to be learned by
 Heaven's organisms you know usually animals but humans in some cases solved problems and to try to have the problems they're solving the problems that are kind of computational ear itch and and hopefully at least interesting or challenging from the perspective of things were trying right now to the train computers to do and that the hope of the possibility and I think it really has yet to be for an hour is that by watching how organisms in organisms brain all those problems you know if your system to do something and you got this thing just organizing this brand it's salting that problem
 if it's actually solving a problem is interesting and important and you can watch it and understand how it solves that problem then there's there will be a potential for that that I did it translate you know I think one example that hasn't really quite work that way but it's been interesting this to watch the development of on the one hand object recognition systems and on the other hand side of the organisms as two systems that do object recognition and there's been a lot of work recently showing Ashley lot of potentially commonality between the sort of neural representation of objects in the brain and the quote unquote neural representation of objects inside of say a deep Learning System that was trained to drop Jack recognition the show that there's commonality between those it doesn't really take it to the next level of actually having what we learn about the brain inform the way we think about think about the computational system I think that
 happen and I hope it will happen if you know where should we thinking about ways of those those things might become a little more connected but I think it starts with thinking really carefully about the problems they are you know again if I wanted to build a computer system that would I don't know learn to play a game by just exhausted Lee searching through every possible solution in a tree in doing that as fast as possible very different than any animal of the game so I don't got to learn a lot about that particular algorithm by studying organisms but if you frame the problem are generally as I said before how do you have a system that can kind of add app to changes in its around it you know something about the environment 3 change the rules and the Animals kind of figured it out you know I want to and if I can
 right away or understand how brains do that then maybe we can think about how to translate that
 what are your personal goals with all this research and you're studying all the stuff at the intersection of Neuroscience and copy Tatian are you trying to become a better research are you trying to develop therapies are you just trying to explore the space or is there
 is there a definitive gold you have in mind
 I just left Kohl's I'm not sure quite a definitive they are only interested in personal how how Brandon organisms do the amazing things they do you know I want to know how is it that I can sit here and close my eyes and imagine walking through the room that I grew up in when I was 8 years old and throat recall it in Vivid detail that I can do that and I'm sure part of what drives me is just a deep inherent Fascination and how that works at the same time a lot of a lot of what motivates me now really has to do is sort of thinking about the the role that point in our lives moving forward you know
 for better for worse Tyler have been enormous successes and in using recently and using a computer to solve various complex real-world problems weather that involves pattern recognition or robotics you things are becoming very relevant to today how we how we live in a world and understand in both how to make their systems better how to think about how actual organisms interact with Computing things generally is I think very important both from the perspective of how we are going to live in the world amongst all these for computing things and to really be understanding the brain and get together and see what interfaces look like I think we'll just continue to be more and more important and I'm very committed in and to be honest little bit afraid of that happening
 I've been committed that that happened in the open and I'm afraid of the world in which really important advances instead of computing then and take place within the city closed off walls of large corporations I really I am a Scientist I believe in doing science and doing work that is shared and in the open and available to everybody and reproducible by everybody and it really matters to me that is a zit of computation plays an important Lee or increasingly important role in our lives that research about it and how it works and how to make it better and how it relates to the the human brain are the brands of any animals I really care about that taking place in the open and that that those things I didn't drive in various ways pretty much everything we do
 that sounds like a good place to close off Jeremy thanks so much for coming out to supper in jail it's been a really interesting conversation and you know I'm really interested in in what's going on in neuroscience and how spark is assisting that you know if you ever have anything else you want to discuss feel free to come back on the show with play the doc great thanks so much for having me a lot of fun
