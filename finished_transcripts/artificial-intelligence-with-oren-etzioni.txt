Transcription: research in artificial intelligence takes place mostly at universities and large corporations but both of these types of Institutions have constraints that caused the research to proceed in a certain way in the University of basic research might be hindered by lack of funding at a big Corporation the researcher might be encouraged to study a domain that is not squarely in the interest of public good so just targeted advertising Oren etzioni is the CEO of the Allen Institute for artificial intelligence and in this episode we discuss AI research from the Doom full premonitions of Nick Bostrom to the unbridled optimism of Ray Kurzweil as well as the realities of how a I research actually precedes projects at the Allen Institute are defined and structured to solve problems in an intelligent scalable fashion so the engineering can proceed steadily from the local Maxima of a problem domain to the global Maxima the Allen
226 to bridge the gap by providing ample funding for open source AI research for the common good or an SUV is also speaking at the O'Reilly artificial intelligence conference in New York September 26th thru 27th if you're interested in hearing him talk before we get to this episode a few quick announcements if you're interested in advertising on software engineering daily send me an email Jeff at software engineering daily. Com there are more than 14,000 Engineers that listen to software engineering daily on a regular basis so it's a great place to get your product out into the ears of developers or to advertise available jobs do you might have your company also if you're an engineer that's looking for an open source project to work on checkout software daily at software daily.com this is an open-source news and information site about software it's being led by Jeff AAA member of the software engineering daily community
you can also check out software engineering daily.com which is the website for this podcast you can find links to the slack Channel my Twitter account my email you can find a link to sign up for our newsletter software weekly and with that let's get to today's episode
 getting started with kubernetes can be a challenge if you don't know where to start go to aprender.com se daily there's an upcoming webinar about installing kubernetes as well as an introduction to mini Q which allows you to run kubernetes locally at a friend of. Com SE daylight you can also find past webinars about kubernetes covering microservices persistence and multiple clusters as well as the history and origins of kubernetes and if you're looking to move to a cloud made of infrastructure platform that works with your existing applications you should also check out of credit.com daily aprender provides Cloud platform software that works with your existing applications and infrastructure so whether you're looking for a guide to install and kubernetes or you're looking for a platform that will give you access to Cloud native infrastructure that works with your existing applications check out aprender.com SE daily that's a peep
 Tre nda.com SE daily thanks a friend up for being a sponsor of software engineering daily let's get back to this episode
 Oren etzioni is the CEO of the Allen Institute for artificial intelligence or and welcome to software engineering daily my pleasure to be here has come to a consensus that machine learning is extremely effective and when a machine learning application becomes polished we start to call it a i and where this point of fruition where machine learning really works it's being widely adopted in baked into our everyday applications did we get here because of some fundamental technical breakthroughs or because of evangelism and like a changing narrative about how effective machine learning is
 well let me say two things off the bat that the first one is that this has been many years in the making and I like to say that are overnight success has been 30 years in the making so very much a progression of steps and advances and iterations as we often find the case to be in software but the second thing I want to say is it's not quite as elegant and tied up as a bow in a boat as a you might think it's true that we're getting increasing success with machine learning and data mining and deep neural networks but it's also the case that a lot of Blood Sweat and Tears has to go into it before it works
 what are the most important technical breakthroughs to have been made recently in in recent years and obviously it's been many many years in the making but I get the sense that there have been some step change things even if we have been iteratively trying different things and figuring out what the step change will eventually be absolutely were there two big things that have happened really in the last 5 years or so the first one is are incredible ability to store and process data in a particular in the cloud with AWS and so on so we now off and have a more data available for these kinds of Taos than ever before and the ability to course through quickly in the second thing is because of the amount of data and because of the advances you know effectively Moore's law but perfectly Moore's law apply to
 gpus the ability to run very complex neural network algorithms and complex neural network algorithms neural networks with many layers what's called Deep neural networks or deep learning those things are relatively new and they've led to remarkable successes in machine learning applications including in speech recognition including in object detection Machine Vision and so the numbers the error rates on these tasks have a plummet and that's what's gotten people really excited and of course one of the most visible demonstrations was pretty recent which is we used or deepmind Google deepmind used deep learning to beat the world champion in go using a a learning program saw all these successes have gotten people very excited
 yeah my sense is that these the tools of deep learning are what's show useful about them in in really pragmatic fashion is that they're almost a way of form fitting machine learning to be able to take advantage of these advances in Moore's law that you know we could have predicted a long time ago you say units just barely barely in at least there's still some wonderful breakthrough in machine learning it was basically the the data processing speed and like you said the storage abilities caught up to the techniques that we've had all along maybe you could tell me if that's true and tell me how you define that term deep learning sure so first of all so we're all on the same page deep learning really refers to using a neural network
 to learn when there is more than two or three layers in in the network so these algorithms that have been so successful we really invented in a 30 or even you know depending on how complicated or even 60 years ago and I remember when I was in grad school in this is embarrassing but this was in the in the late 80s Geoff Hinton was around I was at Carnegie Mellon and he was a visiting Professor there and he was talking about these great algorithms in there was a lot of debate will these work World more symbolic methods work and when we just didn't know so the algorithms were around for a long time what's happened with Moore's Law is that in recent years they've proven themselves that when you get them deep enough now we have these things with 7 10 15 20 layers deep and when you give them enough data the other competitors start dropping out of the race so you know think of it right the Olympics
 are you know in the air these days and so think of it you know you're running a marathon and then the first mile everybody is running internet connection the same as true 10 miles in when your 15 miles then most of the runners of dropped out and you look at the runners and they're all deep learning I would rather than you say so you know these are the algorithms that are able to go the distance with massive amounts of data and massive amounts of competition in places where other algorithms are are saturated saturated means they don't improve as you give the more data so that's that's what special here
 and most of these by this many of these algorithms fall into the hospice of classification or prediction what are the limits of these techniques when were using them for the domains of classification and prediction
 well so again just to make sure that we're on the same page as far as terminology mathematically speaking right all these algorithms are approximating some function when that function is binary meaning it up yes or no 01 we call that classification so we have a loan application and we need to decide whether it's meritorious or not or we have a consonant and we need to decide whether it's b as in boy or p as in Paul those kinds of distinctions are classic is is what's called classification there's also something called regression where what we're trying to predict is not a binary distinction or classification but it's a real number for example what's the probability that this statement is true or the other statement is true or what's what are we predicting the price of this product to be a week from now
 so all these sorts of tasks the Deep learning has been quite good at the places where it has challenges is when you need to make a decision that requires more common sense more background knowledge more reasoning not everything can be reduced to these you know distinctions yes no
 is that yet another question of cramming enough data in for Rio giving enough processing power to you eventually get these characteristics of human reasoning or whatever it is that these types of classification and prediction algorithm don't capture today
 that's a really great question so that's something that researchers debate so I think the folks who believe in Concepts like end-to-end learning and scaling deep learning yeah it's ultimately have networks that are you know as big as the brain which as you know hundreds of billions of neurons and you have trillions of connections are synapses they say yeah let's just skip all the supplements for find the algorithm let's give him a lot of data and that's all we need end-to-end deep neural network learning there's others and I'm in the other Camp you say wait a minute first of all these so-called neural networks actually the neurons in them are a lot simpler than a neuron in our brain are neurons are incredibly complex and more importantly it's not enough to emulate the brain and kind of a low almost Hardware level I we really need to have a deeper under
 sending in a different sense not deep is in more layers but an understanding of of of what's going on we need to have ways to put knowledge in right we're having a conversation I may be learning things from your questions you may be learning things from my answers and those are things that are Way Beyond what neural networks today can do the the fact of the matter is they can't really even understand a single sentence let alone learn from a sentence and incorporate that into their mental model so many of us believe that the Cena work on classification and advances and deep-learning are very exciting we have a long way to go to achieve human level intelligence and I imagine that experience with Geoff Hinton Ito where you had these other algorithms aside from the deep learning techniques
 back in the day that has caught talk to you to reserve judgement without seeing data or as to how these things are going to play out
 you're right about that you know I was in grad school in the eighties so I'm in my 50s and let me tell you when I was young I knew the right answer to pretty much any question you ask me about now that I'm older and a little bit wiser and I'm kind of seeing some things play on I'm actually lesser than ever about what what the right answer is the only thing that I am certain of is some of the folks you see who you really are full of hype about AI about machine learning you know folks like hurts while or if people like Nick Bostrom a really kind of doing fear-mongering I think those folks are a really overstating the case and frankly bit with their statements are not back by any data right so they say all kinds of things like the singularity is around the corner or some such thing but they don't back it up with data so you have to be suspicious
 around them but I actually I see some practicality in both of those extremes you know Kurzweil really gets people riled up and probably that has some cheerleading effect for people at Google who are his acolytes and then on the other side Bostrom you know I'm with you that he's a little fear Monger e but then again the downside risk if he's right is essentially infinite so it doesn't it doesn't hurt to have a a Boston or two in the world will so let's let's talk about that and more details soon in the Criswell case I would contrast them to somebody like Jeff Dean who's very technically deep and is you're pursuing exciting things but then the more discipline way let me tell you right you know I know some of the folks who worked with him they're really pumped up they're excited you know he has to turn people away right Engineers who want to work on deep learning so I don't think
 I have to go to the course why level to Tina to get people excited people are excited about genuine technical advances if you go to Bostrom you make a really interesting point about well look if there's even a chance of one of a thousand then he's right then then we should think about this the problem is what's called you know Pastor is paradox right and it goes something like this you ask people do you believe in you know God and an everlasting hell and a lot of people is in no I don't think that's going to happen but then you have some looked you admit that there's a one and a thousand one in a million let's say one in a trillion chance that that's actually true a lot of people would say look I can't prove to you that there's no Everlasting help and they say aha then you have to be in a religious Catholic religious Jew or whatever it is it's a y and they said cuz look the disutility if you're wrong and you're
 I'm going to send this to an everlasting help is infinite and so if you believe this even infinitesimally small probability just do the expected value calculation and you have to be a religious person obviously that's a a paradox right then line that line of reasoning doesn't work and it doesn't work because when you have infinite this utilities it distorts the whole equation that's why it's a paradox so I think is it good that we have you know some folks like Bostrom and we have his Center in Oxford that's thinking about these conceptual and philosophical issue absolutely there's whatever 1012 there and probably as Humanity we could afford to be in a 20 25 people there are no more power to him they're doing it interesting philosophical analysis but the thing that I have ject to is the play that these rather hypothetical ideas that again or not backed by science or data there philosophical ideas the play that that's God and
 in the popular press everywhere I do see places like Newsweek Witcher frankly you're going to read but people who are not perfectly well informed saying things like around the corner and it's in a poised to take over and this could lead to nights to anti-technology feelings it could lead to a regulation where regulation is not appropriate and more than anything it could lead us to be distracted from what the real issues of a IR there's plenty of real concerns that we should have you know the impact on jobs the impact on privacy the ethical issues around self-driving cars and the kind of you know drumbeat of oh my gosh is an existential risk where unleashing the demon it isn't the frankly a distraction
 yeah I saw imagine you see that particularly cutely when you're looking at all these problems you could be tackling and we will get Andy's any projects like being able to answer basic science questions if these are these are things that are still extremely hard to do and they're nowhere nowhere nowhere near even being able to imagine how do we keep the demon in the Box as Elon Musk says we're nowhere near even being able to Envision how this type of problem would manifest itself even if it's a practical concern someplace down the line as X approaches Infinity we have no idea what are programming paradigms are going to be like we have no idea what are AP eyes are going to be like so these things are simply metaphysical discussions and there's not really any it's just not in a really practic practicality to it sound
 I guess is your position that's exactly right so we we ought to have a rational discussion of the cost the benefits the probabilities of different situations over the next five years over the next 10 25 years if we're talking about things that are maybe a hundred or even a thousand years out it's really Beyond the Horizon with which we we can predict so you know maybe we ought to be talking about the likelihood that the asteroids will will strike the Earth and ruining your brilliant professor at Stanford said that worrying about AI turning evil is like worrying about overpopulation on Mars it's too early we haven't even shown that we can get people to Mars in fashion
 Science Fiction with with science right in the movie The Martian we got some people to Mars and then do you know if we left somebody there you know kind of like home alone bye bye bye mistakes in real life that's not going to happen to be we haven't got people to Mark's stuff all day but we should talk some about gravitate towards what you are working that's what is the Allen Institute for artificial intelligence so first and foremost we were a non-profit Research Institute who's focus our mission is AI for the common good and what that means is the well we're cognizant of you know some of the issues and the risks we are exploring the part of the equation that Franklin has been under investigate and certainly hasn't gotten enough attention in the immediate which is the potential benefits of a i the most obvious example not something that we're setting but it's worth mentioning
 is the potential of self-driving cars to reduce accidents we have 3040 thousand highway deaths a year many more people were injured in a person named in these accidents and we could bring estimates are there we could bring those accidents down by as much as 80% by giving a stronger roll to the computers the machines in driving and it's something that's already happening today with Tesla with all kinds of you no Advance Warning Systems on cars that's a very real thing another thing that's much closer to all we do is what about preventable medical errors recent studies show that the third leading cause of death in American hospitals is various kinds of medical errors that could be prevented the doctors are overworked the doctors are are tired after long shifts right there under a lot of pressure they they make mistakes they can keep up
 where the latest treatments the latest literature the latest knowledge about side effects and mistakes are made of people died so the way I look at it we really have a moral imperative to to study I would the goal of saving people's lives the kinds of projects that we work on his we're going deeper into natural language processing deeper into building computers that can understand us the can understand background knowledge that can ultimately understand scientific papers and help researchers solve supertuff scientific problems and album ultimately help doctors make fewer mistakes so let's talk about the the medical example in in detail so there's plenty of podcast people can go and listen to about the surface level details of this increased human computer interaction the radiologist
 it's working in conjunction with the computer to be able to identify tumors faster or whatever faster give me a sense of the really deep internal engineering challenges of solving this domain of problems just another really important point that I want to highlights and it's the kind of thing where as soon as I say it's right near your audience's technical right software Engineers F course I get that but really the discourse about this is not like that AI Technologies often perceive right it's something that's going to take over but really the manifestation that we see is a lot more like your radiologist example where it's helping somebody do a better job at a really important tasks like finding out if does this person have cancer or not so that's why the week in the human
 angle at this point exactly since the most successful Radiology systems are going to be a human radiologist who has all kinds of intuitions and experience and can ask questions and Son working hand-in-hand with a tireless system that's looked at literally millions of examples analyze the Radiology images together they're going to do better than either alone and and that's the wave of the future AI enhancing our our our abilities and I wrote an article said he's going to empower us not exterminators so then the next question to go to your question is okay then are you saying hey you know we're in a rose garden and everything is easy and good no it turns out that to get there
 we have to solve some very hard technical problems so where we are today is when you define a really narrow classification task like okay does this image depict lung cancer or not and you know maybe what stage is it in the computers are so good at making those distinctions what's remarkable is some things that are really easy for people like understanding a simple sentence those things are remarkably hard for for the machine and so would were working on at the Allen Institute for AI in in Seattle and by the way I mentioned that cuz we are hiring Engineers that were 60 people we have 20 open positions for top-notch engineers and researchers and by the way if you're strong engineer you don't have to have experience and I to work with us we're just looking for for super smart town to people sorry that was a little infomercial there but
 with with that you know in mind the fact of the matter is I could give you a simple examples of sentences that you know it ain't your old will understand in the computer won't
 so is is the way that that translates to the Radiology discussion basically that the same techniques for recognizing OK Google recognizing that a cat is in a picture those same techniques are quite effective for you know I don't know 95% of cases of recognizing some common type of cancer are some common type of other malady that would be detectable on an image some it's have them but there's some 5% of 2% it will be obvious to a human that would not be obvious to the computer
 not quite so the first part of what you said is exactly right which is right you have those kinds of techniques based on deep learning and Machine Vision will do a wonderful job making those distinctions what happens is in a situation where something is out of the ordinary and you have to you know result you have to use more common sense let me give you an example what if suddenly you see two images that are completely identical maybe that was error in putting data into the machine the machine is just going to analyze them say here I'll analyze image of the time the person we see hate a minute hey wait a minute something went wrong here or what if is another situation where I know there's a smudge on the picture and he just literally can see if there's all kinds of unusual cases where's the computer is the master of taking what's happened in the past right and finding the patterns in literally unit
 tens of millions of examples and then looking at new examples when there's something out of the ordinary that's when when when Things Fall Apart the computer will never say hey wait a minute let me ask a question let's have a chat about this let's clarify and that's why when you have a situation like go we're literally right the board is is black and white both literally and figuratively when you have all these examples and all you have to do at the end of the day is make a move right then the computer is going to shine right this really an artificial situation if you think about it what's amazing is not that alphago beat the world champion what's amazing is the people can play go at a high level in the first place it's a game if you think about it design for a machine but what when you have something like a sentence let me give you a concrete example time flies like an arrow is like a famous example in a national language
 we instantaneously unconsciously understand that sentence in a certain way in a sitz is the idiom time flies like an arrow will the the computer really struggles with that pressure what does it even mean to understand that sentence right we need to map that to some internal representation well we're not even sure what that representation should be also there's a ton of ambiguity that we don't think about what if it's actually an imperative sentence that says Timeflies meaning you Jeff should you use a stopwatch to measure flies and do it quickly do it like an arrow or what if it means there's a particular species of flies called the time flies and don'ts those kinds of flies are fond of a particular airoso time flies like some Arrow right in this so many crazy interpretation of descendants did you and I wouldn't even think of initially but the computer has to cuz the computer doesn't have common sense and I can give you a lot
 more different examples where when the problem is more ill structured more nuanced when are Human Experience needs to come to Bear suddenly the computer falls apart conducting a high-quality interview of creating a podcast that's very popular you can't give that to some neural network because you can't even get a create label data for it very effectively what are you going to do take all the podcast in the world feed them to a neural network and say learn that doesn't work
 well you you burst my bubble for the day that was my tire plan with this podcast job security in the sense that it's not the case that in the foreseeable future we can replace you with a machine yeah I know you're talking about hiring there's there's there's all kinds of places where a machine learning researcher could go these days you can go to MIT you can go to Google you could go to the Allen Institute what is driving the different machine learning researchers to go in these different directions when you're interviewing people when you're bringing people to the Allen Institute what are you finding are their motivations and what what drives them
 well I'll tell you what one person that we hired from Google set and I thought it was really quite brilliant he said look Google has pardon me Google has 30,000 very strong Engineers but they don't have 30,000 interesting technical problems so I'm often what you're working on in one of these bigger companies weather is Google or Microsoft but I want to pick up on Google it's a great company you're still a cog in a very big company and when people want more of a sense of ownership more of a kind of Broad and Aiden purview disability to build bigger things they naturally gravitate to smaller smaller companies to startups and son that's number 1 number 2 is Jeff hammerbacher right who was the one of the founders of Cloudera and then an early employee at Facebook he left all that behind and now he's doing
 data science at Mount Sinai Hospital in New York working on in a using big data and they are techniques going to help solve your thorny problems about diseases he said look the the best minds of my generation are working on getting people to click more frequently on ads and frankly that sucks and now again I don't want to put anybody down but I do think that some of us feel like we want the technical work that we do to to make the world a better place not just to contribute to clicking on ads or unit to the bottom line of of of some Corporation and people who are selfishly motivated by that naturally you know check us out in a and we don't have a number on Monopoly on this by any means but but they don't want to work as part of the of the ad industry is part of
 analyzing people stayed on and then selling them things absolutely
 wealthfront is an automated investing service that saves you time is an engineer your time is valuable if you want to invest but you don't want to spend significant time evaluating your portfolio in allocating assets take a look at wealthfront go to wealthfront.com se daily to open an account today and get a special offer for software engineering daily listeners $15,000 manage for free when you open your account with traditional Investment Services there are many humans in the loop that are doing things that well front automate away when you pay the commission's an account fees of these traditional Investment Services you're paying for work that could be done by a computer so don't pay commissions and account fees maximize your gains with wealthfront set-it-and-forget-it investment automation check out well front.com SE daily it would support software engineering daily and it would introduce you to the world of automated investing
 wealthfront.com SE daily thanks to wealthfront for being a continue to sponsor of the show now let's get on with the show
 Mike sense though is that a place like Google or Microsoft has realized that that is the case and they have started to give researchers who show a lot of Promise essentially independent latitude like you can if you're a great researcher you can go to Google and say hey I want to research X it has no immediate bearing on your bottom line but you know you're interested Moon shots did you know maybe this will pan out maybe this'll this will be something that turns into your next two business idea is that accurate or am I just totally off know you're not off at all. That's a very fair point and you're absolutely right you know I have no I was at the University of Washington computer science department for many years I'm I'm still on the faculty there and I've had
 I got some more than a hundred students of our students probably several hundred by now you've gone to Google and other companies of course it is really a wide variability and there are some people Google axe or at other places who are working on incredibly Innovative things and on on moonshot projects and and there are those opportunities that's not the boss of what people do right Google is God you know Gmail and Google Maps and you know products to maintain they do make billions of billions of dollars with targeted ads and they have thousands and thousands of Engineers supporting that so I think it's important not to confuse what most people they are doing with what some people there are getting to do but it is absolutely the case that a particular Google but at any of these places there's some people are working on an incredibly cool
 things with incredibly cruel datasets you know if you want to build the future of cloud infrastructure and dealing with mind-boggling amounts of data right being at a w s in there in Seattle at that Amazon is a fantastic opportunity in the same with you know that the cloud infrastructure is at the other companies we we don't have any Monopoly on on the exciting problems I do think that in terms of Cutting Edge work in a i and Cutting Edge work that's directly aimed at you know a guy for the common good we have a great a great place to work but we're definitely not the only game I even in Seattle let alone in that in the world research the recent research papers that have been published by companies Microsoft Google whatever and there is a lot of research about ads about
 improving the click-through rates on some specific type of advertising It Anyway research for the common good is how does this differ from the type of research that gets done at an academic institution is there more latitude cuz I see some people I know who are in Academia and it was a great stuff comes out of Academia but in contrast with a place like the Allen Institute it does sound like there is a degree of cropped that comes with the traditions of Academia that would just significantly drag down your ability to to move fast or contrast with a place like the Allen Institute
 most of my career at universities am partial to them and of course we have to remember that you know companies like Google or Facebook and in a mini others came out of universal Hood they were spun out of in Google's case research in in a Mark Zuckerberg gives to the Harvard you know kind of informal research on how to meet girls you know what would have you the biggest difference is that at universities is really what's called a curiosity driven research right it's all over the map you know amazing things can happen but of course often they don't and you typically have one or two people may be a graduate student in his or her advisor working on a problem that's only you can only go so far at the Allen Institute were working on 4 or 5 Grand Challenge problem and we have teams that are bigger Tim teams of 10 to 15 people often broken into sub team
 that are smaller but those teams are working together towards a Grand Challenge whether that is developing sufficiently power powerful natural language processing so we can Bill programs that can answer scientific questions and you know pass the 8th grade science test or going to the SATs to programs like semantic scholar where we're trying to use AI the combat information overload in his I said ultimately help medical researchers and doctors do better research make better decisions and ultimately save lives so to do those things you do need a bigger teams you do need more sustained investment off of the code at universities right it's it's rapid prototyping that you write a quick prototype you do an experiment you publish your paper and you move on that's that's the right thing to do in Academia but if you want to go further here's another famous African saying if you want to move
 fast go alone if you want to go far go together right so at the biggest contrast between the Allen Institute at what happens at universities is that we're trying to go further and we believe the way to do that is to go together to have these stronger teams the other point of course is as a professor there is a lot of stuff you have to deal with which is a distraction grant writing nobody in the entire planet I've never met anybody in over 25 years is a professor who like writing grants in a you're right they get rejected you have to rewrite them eventually they get funded but the research sponsor wants you to do something else at the El and so did we have a huge privileges which were back by Paul Allen who's you know how to passion for this field for decades and his marching orders the US is go have a major impact and I know that that takes time I know that a breakthrough takes time I'm going to back
 so that's that's a huge luxury really interesting there it sounds like these problems that are being solved at the Allen Street New got these listed on the website some of these probably work on for example Aristo as an effort to answer basic science questions like you know 8th grade biology questions you've got semantic scholar which is a literature search engine that index of scientific research papers you got Play-Doh which is extracting Knowledge from images and diagrams and videos it sounds like what you're trying to do with each of these projects is you take a really big problem of really big canonical problem in machine learning and then you find a base case of that problem that you can diffuse more approachable and the scent is that by attacking the base case you're going to make meaningful progress towards solving the canoe
 Michael machine learning problem is that accurate that's really a great articulation that I have to save this podcast thing does not work out we should talk about we need somebody to help us crap this what you said your last goodbye so brilliantly the issue is how can we tell if we're making progress and given to there so many problems in a technical puzzles research possibilities how can we assess both for ourselves and for others if we're making progress and so what we've done is we've identified problems likes an eighth grade science test where there's a graduated scale and we can measure ourselves and exhort ourselves to keep making forward progress and we try different things and we iterate through algorithms and through data sets like everybody else
 but we've been very proud that over the last three years or so we've been able to continually raise the scores on things and really this methodologies is relatively unique or try to bring together the best of Academia which is an informal brainstorming creative research you know smart people working together with minimal hierarchy minimal BS with some of the best things of from industry which is you know more professionalism around our software around architecture then what is the average grad student can muster and a clear set of metric and gold so that we can track and make progress on
 so give me give me example of one of those projects and what is the short-term goal of the project and what is the long-term goals of project sure so I'll give you the two examples the first one which again is really easy is in the case of the safe grade science task for this SATs were we have these goals we have annual goals of scores that we want to exceed those are Benchmark tasks right there's no no kind of like a Hardware in a spec mark for a chip it's not that we necessarily want another this will be a huge thing if if a computer program can do well on 8th grade science test is that we believe that in order to do that we're going to have to solve difficult problems in natural language processing in Envision in machine learning etc etc so here in this case
 the metric is is really serving as a as a as a benchmark is it as a score in the case of semantic scholar which is our program by the way is available free of charge anybody who wants to use it at semantic scholar. Org that program we we've invested a lot into building what we think is the best Search tool for a computer science academic papers and we're broadening you know to neuroscience and two other areas of biology right we're heading in that direction but we don't want to build a white elephant we don't we don't want to build a tool the world love Wiz has all kinds of fancy bells and whistles using a knife but nobody uses it so we've challenged herself with traffic goes to say look if this thing is so great if I really helps you in the search people should start using this in our goal for this year was to have at least 500,000 people check it out and we're very proud that we've
 already exceeded we have over a million visitors who come to the side even though it's currently just computer science papers and the number of repeat users keeps going up as well as people find Value in it and that also forces us to ask the hard questions okay how do we get to 10 million users what is it that the people really need in the search tool not just what we feel like putting in there
 it's yours early sounds like you have a focus on key performance indicators for these different projects and I'm curious about how management of The Institute differs from management of your different companies you've started several companies for listen to don't know what ways does managing the AI Institute differ from the management of the companies that you've started in a couple of important ways and I have had the privilege to start a few companies perfectly in the kind of e-commerce space and I should point out the all those Comer companies were always on the side of consumers they're always ones that were trying to find a better price for consumers we had the first comparison shopping search engine back in the in the mid-90s OR ones that tell you went to buy your airline ticket so that you know.
 the airlines don't trick you into overpaying so I have always been kind of a little bit on the side of the are The Underdogs I think one of the biggest differences is that when you have a start up until a very late stage you always raising money for the next unit 12 and most 18 months right it doesn't make sense to raise more than that cuz your valuation should keep increasing and that does put you on a roller coaster ride ride you said ambitious goals money starts to run out you're looking for the next funding around sometimes that can cause in a major shift in directions it's it's pretty nerve-wracking it's pretty exciting too but it's definitely a roller coaster ride here because we're back by Paul Allen and he has this long-term Vision we're not on a roller coaster right we have Ambitions goals as we talked about a metrics but we're not on that kind of roller coaster ride of
 of constantly seeking funding in and potentially in a radically change in direction or having to be acquired there are actually hired because some assumptions didn't work out that's one thing and then the second thing of course as a start-up right you have to have a business model that's often one of the trick is things we've built in in the various companies have been very very cool products for where users really love them but the challenge was how do you get users to pay for them and most of us are reluctant right to to part with her wallet and pay even you know 599 for ad for some for some piece of software and so the search for a business model can often be challenging and sometimes even though you have a great product you don't have a great business model Again by 2 because we're non-profit we explicitly say ahead of time we're not trying to find her a business model what we're trying to do is have him
 on the technology and make the world a better place and you know having done the other one for you no more than 20 years frankly it's a relief not not not to worry about then just focus on the on the intellectual content on on the technical problems so I really try to create an environment for kind of the younger and you know at this point in a smarter more technical people on on the team that we have to just Shield them from distraction as much as possible and say let's go do what you're you know your best and don't worry about all that other stuff
 Paul Allen has started a number of these institutions I know of at least two AIS to attend the institute for brain science does he have some overlapping Mission between these different organizations of the brain Science Institute being more biologically focused
 so he is a tremendous Visionary and he signed the Warren Buffett pledge which means that he's committed to giving away billions and billions of dollars and he's is the net with ebola he's done that in and fighting homelessness but a key part of his vision as you said is to create a series of scientific research institute there's the Allen Institute for brain science and it's broadening the scope where we call ourselves a i to both because where the Allen Institute for artificial intelligence or ai ai but also because we were number 2 and since we were founded as already the Allen Institute for for cell research number three and he's continuing to grow that kind of set of research institutes in the case of the brain science one and ours he's been in a fascinated with the questions of how do we figure out intelligence and in some sense
 I think at the very high-level I he's kind of hedging his bets he says well does this methodology of Neuroscience which is in some sense investigating the hardware really looking at the brain very closely it up at a sub cellular level and then does this more software methodology nobody knows which is the right one why don't I going to try to back a high-quality institutes in each and make sure that they talk to each other so the CEO of the Allen Institute for brain science is on our board of directors we often talk to Christophe was their Chief scientist were exploring where this potential synergies as well
 and what is your sense for where that border is going where we going to find or what are we going to find at that interface between the human brain and the systems we use to interface with it like as a machine learning researcher if you're trying to build systems with reasoning as robust as a human you know it's a practical to assume that the human brain is always just going to be this black box be on some level of abstraction we should just try to find where the border of that black boxes and then just figure out some virtual machine that satisfies the characteristics of that black black box it just seems like we're never going to actually figure out you know that that the dab of the the human brain and therefore we should try to figure out like where is the where is the minimum border that we can Define so that we can make an interface over
 that word I don't know maybe you could it's a jumble of thoughts there but maybe you could tell me where you what you think we're going to find at this this interface never say never you know I don't know if you'll never understand their brain but Rhapsody ride your intuition that this is a long road is is a very good intuition and if you look at the questions just like us they have their own metrics and their own road maps and if you're looking what they're predicting Bill discover in the next 5 years in the next 10 years it's still very basic almost home I called him Geographic questions what is this cell type and what does this brain region do what is really kind of a map even of of of the human brain very very basic things in an ALICE you would be imagine that
 we took a you know a laptop and we sent it you know back I don't have to the 19th century and people are maybe lots of laptops and people were trying to figure them out they really looking at the chip level and if the wire level I'm trying to connect measure electrical pulses in different areas that's a level of abstraction that can tell you something but it's not the whole story so there is an analogy there and there is a concern that looking at things at the very low level is challenging would the the good news would be is if we were able to generate some constraints from the study of artificial intelligence there were able to generate some constraints from the study of the brain and we're able to put the pieces together and come up with a better faster progress towards and understanding of intelligence I love to give the analogy to win we as
 humans were first studying flight and some people said look we got to build a bird let's study how birds flap their wings and are very light and that's what we're going to do and other people said no we're not we're going to focus on airplanes with fix Wings right in that technology ultimately after many you know Falls turns tenant to went out and of course that technology was based on aerodynamic some things like in at the Bernoulli principle so from all these studies did emerge some general principles of of of of flight and of motion that would that were extremely important we haven't yet discovered the Bernoulli principle of intelligence we still don't understand some very very basic things and that's why we're still in the early days of these fields and the different methodologies are all doing their best
 at what degree is this analogous to how deep learning algorithms developed because my sense I'm not ignoring expert my senses that oftentimes these algorithms the way they develop as we don't know why they work as effectively as they do we just know that they are effective but you know is is that is that an Alex to this model of drawing constraints for the human brain in the drawing constraints for the machine learning model and fitting those constraints together
 in a very very high level yes but if you look at the day-to-day research and we certainly have plenty of people here who working on neuralnetworksanddeeplearning often the questions that are investigated are our mathematical you know about the hyperparameter optimisation or their software engineering questions how do we build a you know good tool kit to experiment with different things there about particular girl technical aspects that have to do with the particular neural network unit do we use a s Office Max here do we do pooling here how do we do regular ization I'm throwing a bunch of jargon there but these are you know various statistical questions or kind of almost in a Black Card questions of The Craft of these particular tools it's not the case that people are saying I'm trying to get a raise my performance on this tax by 10
 oh I know let me take this idea that see no you find in the brain of monkeys that's that's not how it works it's just those are just still too far apart right we've done a bunch of shows about software architecture how to scale a typical application we've also done shows about machine learning what is it the intersection of those two things what makes scaling a production application that heavily uses machine learning what makes that difficult
 well you know the most difficult thing is the fact that even with these neural networks most of the decisions most of the work is still human engineering so when Alpha go one or when alphago was winning in the matching the inner some reporters ask me you know what do you think of all this I pointed out to them that this is not man against machine this is a team of brilliant a software Engineers that researchers at Google deepmind against you know a brilliant go player named Lisa at all most the hardest thing is the fact that quote a quote machine learning is 99% human manual engineering and even with normal hours it's okay you're doing less feature engineering your building less of the representation by hand that's true but you're still doing network engineering you're still choosing how many layers
 in which architecture and are you using you know and lstm or not I don't want to throw a bunch of jogging but there are many many architectural decisions and algorithm make decisions and representational decisions they're all timidly made by the human engineer in in any of these quote-unquote machine learning applications and for that reason that's why it takes years to field a new machine learning application and that's why we need better software tool to facilitate that process
 what are the tools are you using these days mostly as a cycad learner tensorflow
 oh sew in in the case of a deep learning a lot of people are using tensorflow at the same time right there's plenty Envision right people are also using a torch and other thing it's really a grab bag and again it's a little bit you know like you know how are using Java using cplusplus or using scholar we actually are our main programming language is scallop you can get the job done and any of these languages pretty much as it's in part a question of of of tasting a good night I hope I'm not offending anybody who's a complete you know officially out of one language to another I think most people recognize Okay this may be my favorite language and it's got some features and salsa got some drawbacks and you can get the job done right now of course you tutoring University ality and all these things tell you that of course mathematically speaking you can definitely get the job done
 any language in the case of non neural networks in a natural language processing released an open source project called Ike which is an interactive knowledge extraction tool that that we develop and at the same time we rely on in a stanford-nlp they're very strong open source project I would say that the biggest thing I can tell you is that they were in Scala be we do sit on top of AWS which we found a very helpful and see that we use open source projects whenever we can obviously because then we're effectively collaborating collaborating with the community
 okay orang well this is been a real treat thanks for coming out of software engineering daily it's been a real pleasure I appreciate the questions and I hope everybody checks out semantic scholar and considers a job at the Allen Institute of a i l a i. Org in Seattle thank you very much Jeff for the opportunity
 thanks to symphonic for sponsoring software engineering daily symphonica is a custom engineering shop where senior Engineers tackled big Tech challenges while learning from each other check it out its symphony.com SE daily that's s y m p h o n o. Com SE daily thanks again Stefano
